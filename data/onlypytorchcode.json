[
    {
        "Answer": ">>> a = torch.randn(4).uniform_(-1, 1)\n>>> a\ntensor([ -0.9385, 0.2968, -0.8591, -0.1871 ])\n>>> torch.atanh(a)\ntensor([ -1.7253, 0.3060, -1.2899, -0.1893 ])\n",
        "Question": "How to use torch.atanh, give an example?",
        "Id": 1,
        "source": "https://pytorch.org/docs/stable/generated/torch.atanh.html#torch.atanh",
        "context": " "
    },
    {
        "Answer": ">>> torch.logaddexp(torch.tensor([-1.0]), torch.tensor([-1.0, -2, -3]))\ntensor([-0.3069, -0.6867, -0.8731])\n>>> torch.logaddexp(torch.tensor([-100.0, -200, -300]), torch.tensor([-1.0, -2, -3]))\ntensor([-1., -2., -3.])\n>>> torch.logaddexp(torch.tensor([1.0, 2000, 30000]), torch.tensor([-1.0, -2, -3]))\ntensor([1.1269e+00, 2.0000e+03, 3.0000e+04])\n",
        "Question": "How to use torch.logaddexp, give an example?",
        "Id": 2,
        "source": "https://pytorch.org/docs/stable/generated/torch.logaddexp.html#torch.logaddexp",
        "context": " This op should be disambiguated withtorch.logsumexp()which performs a\nreduction on a single tensor."
    },
    {
        "Answer": ">>> # tensor to tensor comparison\n>>> expected = torch.tensor([1e0, 1e-1, 1e-2])\n>>> actual = torch.acos(torch.cos(expected))\n>>> torch.testing.assert_close(actual, expected)\n",
        "Question": "How to use torch.testing.assert_close, give an example?",
        "Id": 3,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> # scalar to scalar comparison\n>>> import math\n>>> expected = math.sqrt(2.0)\n>>> actual = 2.0 / math.sqrt(2.0)\n>>> torch.testing.assert_close(actual, expected)\n",
        "Question": "How  Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs., give an example?",
        "Id": 4,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> # numpy array to numpy array comparison\n>>> import numpy as np\n>>> expected = np.array([1e0, 1e-1, 1e-2])\n>>> actual = np.arccos(np.cos(expected))\n>>> torch.testing.assert_close(actual, expected)\n",
        "Question": "How  Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs., give an example?",
        "Id": 5,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> # sequence to sequence comparison\n>>> import numpy as np\n>>> # The types of the sequences do not have to match. They only have to have the same\n>>> # length and their elements have to match.\n>>> expected = [torch.tensor([1.0]), 2.0, np.array(3.0)]\n>>> actual = tuple(expected)\n>>> torch.testing.assert_close(actual, expected)\n",
        "Question": "How  Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs., give an example?",
        "Id": 6,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> # mapping to mapping comparison\n>>> from collections import OrderedDict\n>>> import numpy as np\n>>> foo = torch.tensor(1.0)\n>>> bar = 2.0\n>>> baz = np.array(3.0)\n>>> # The types and a possible ordering of mappings do not have to match. They only\n>>> # have to have the same set of keys and their elements have to match.\n>>> expected = OrderedDict([(\"foo\", foo), (\"bar\", bar), (\"baz\", baz)])\n>>> actual = {\"baz\": baz, \"bar\": bar, \"foo\": foo}\n>>> torch.testing.assert_close(actual, expected)\n",
        "Question": "How  Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs., give an example?",
        "Id": 7,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> # Different input types are never considered close.\n>>> expected = torch.tensor([1.0, 2.0, 3.0])\n>>> actual = expected.numpy()\n>>> torch.testing.assert_close(actual, expected)\nAssertionError: Except for scalars, type equality is required, but got\n<class 'numpy.ndarray'> and <class 'torch.Tensor'> instead.\n>>> # Scalars of different types are an exception and can be compared with\n>>> # check_dtype=False.\n>>> torch.testing.assert_close(1.0, 1, check_dtype=False)\n",
        "Question": "How  Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs., give an example?",
        "Id": 8,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> # NaN != NaN by default.\n>>> expected = torch.tensor(float(\"Nan\"))\n>>> actual = expected.clone()\n>>> torch.testing.assert_close(actual, expected)\nAssertionError: Tensors are not close!\n>>> torch.testing.assert_close(actual, expected, equal_nan=True)\n",
        "Question": "How  Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs., give an example?",
        "Id": 9,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> # If equal_nan=True, the real and imaginary NaN's of complex inputs have to match.\n>>> expected = torch.tensor(complex(float(\"NaN\"), 0))\n>>> actual = torch.tensor(complex(0, float(\"NaN\")))\n>>> torch.testing.assert_close(actual, expected, equal_nan=True)\nAssertionError: Tensors are not close!\n>>> # If equal_nan=\"relaxed\", however, then complex numbers are treated as NaN if any\n>>> # of the real or imaginary component is NaN.\n>>> torch.testing.assert_close(actual, expected, equal_nan=\"relaxed\")\n",
        "Question": "How  Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs., give an example?",
        "Id": 10,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> expected = torch.tensor([1.0, 2.0, 3.0])\n>>> actual = torch.tensor([1.0, 4.0, 5.0])\n>>> # The default mismatch message can be overwritten.\n>>> torch.testing.assert_close(actual, expected, msg=\"Argh, the tensors are not close!\")\nAssertionError: Argh, the tensors are not close!\n>>> # The error message can also created at runtime by passing a callable.\n>>> def custom_msg(actual, expected, diagnostic_info):\n...     return (\n...         f\"Argh, we found {diagnostic_info.total_mismatches} mismatches! \"\n...         f\"That is {diagnostic_info.mismatch_ratio:.1%}!\"\n...     )\n>>> torch.testing.assert_close(actual, expected, msg=custom_msg)\nAssertionError: Argh, we found 2 mismatches! That is 66.7%!\n",
        "Question": "How  Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs., give an example?",
        "Id": 11,
        "source": "https://pytorch.org/docs/stable/testing.html",
        "context": " Formax_abs_diffandmax_rel_diffthe type depends on thedtypeof the inputs."
    },
    {
        "Answer": ">>> a = torch.randn(3)\n>>> a\ntensor([ 0.5950,-0.0872, 2.3298])\n>>> torch.diag(a)\ntensor([[ 0.5950, 0.0000, 0.0000],\n        [ 0.0000,-0.0872, 0.0000],\n        [ 0.0000, 0.0000, 2.3298]])\n>>> torch.diag(a, 1)\ntensor([[ 0.0000, 0.5950, 0.0000, 0.0000],\n        [ 0.0000, 0.0000,-0.0872, 0.0000],\n        [ 0.0000, 0.0000, 0.0000, 2.3298],\n        [ 0.0000, 0.0000, 0.0000, 0.0000]])\n",
        "Question": "How to use torch.diag, give an example?",
        "Id": 12,
        "source": "https://pytorch.org/docs/stable/generated/torch.diag.html#torch.diag",
        "context": " Get the square matrix where the input vector is the diagonal:"
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a\ntensor([[-0.4264, 0.0255,-0.1064],\n        [ 0.8795,-0.2429, 0.1374],\n        [ 0.1029,-0.6482,-1.6300]])\n>>> torch.diag(a, 0)\ntensor([-0.4264,-0.2429,-1.6300])\n>>> torch.diag(a, 1)\ntensor([ 0.0255, 0.1374])\n",
        "Question": "How  Get the square matrix where the input vector is the diagonal:Get the k-th diagonal of a given matrix:, give an example?",
        "Id": 13,
        "source": "https://pytorch.org/docs/stable/generated/torch.diag.html#torch.diag",
        "context": " Get the square matrix where the input vector is the diagonal:Get the k-th diagonal of a given matrix:"
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How to use The context managerstorch.no_grad(),torch.enable_grad(), andtorch.set_grad_enabled()are helpful for locally disabling and enabling\ngradient computation. SeeLocally disabling gradient computationfor more details on\ntheir usage.  These context managers are thread local, so they won\u2019t\nwork if you send work to another thread using thethreadingmodule, etc., give an example?",
        "Id": 14,
        "source": "https://pytorch.org/docs/stable/torch.html#math-operations",
        "context": " "
    },
    {
        "Answer": ">>> torch.Tensor.as_subclass in torch.overrides.get_ignored_functions()\nTrue\n>>> torch.add in torch.overrides.get_ignored_functions()\nFalse\n",
        "Question": "How to use torch.overrides.get_ignored_functions, give an example?",
        "Id": 15,
        "source": "https://pytorch.org/docs/stable/torch.overrides.html",
        "context": " "
    },
    {
        "Answer": ">>> import inspect\n>>> my_add = torch.overrides.get_testing_overrides()[torch.add]\n>>> inspect.signature(my_add)\n<Signature (input, other, out=None)>\n",
        "Question": "How to use torch.overrides.get_testing_overrides, give an example?",
        "Id": 16,
        "source": "https://pytorch.org/docs/stable/torch.overrides.html",
        "context": " "
    },
    {
        "Answer": ">>> def func(a):\n...     if type(a) is not torch.Tensor:  # This will make func dispatchable by __torch_function__\n...         return handle_torch_function(func, (a,), a)\n...     return a + 0\n",
        "Question": "How to use torch.overrides.handle_torch_function, give an example?",
        "Id": 17,
        "source": "https://pytorch.org/docs/stable/torch.overrides.html",
        "context": " :raises TypeError : if no implementation is found.:"
    },
    {
        "Answer": ">>> class SubTensor(torch.Tensor): ...\n>>> is_tensor_like(SubTensor([0]))\nTrue\n",
        "Question": "How to use torch.overrides.is_tensor_like, give an example?",
        "Id": 18,
        "source": "https://pytorch.org/docs/stable/torch.overrides.html",
        "context": " A subclass of tensor is generally a Tensor-like."
    },
    {
        "Answer": ">>> is_tensor_like(6)\nFalse\n>>> is_tensor_like(None)\nFalse\n>>> class NotATensor: ...\n>>> is_tensor_like(NotATensor())\nFalse\n",
        "Question": "How  A subclass of tensor is generally a Tensor-like.Built-in or user types aren\u2019t usually Tensor-like., give an example?",
        "Id": 19,
        "source": "https://pytorch.org/docs/stable/torch.overrides.html",
        "context": " A subclass of tensor is generally a Tensor-like.Built-in or user types aren\u2019t usually Tensor-like."
    },
    {
        "Answer": ">>> class TensorLike:\n...     def __torch_function__(self, func, types, args, kwargs):\n...         return -1\n>>> is_tensor_like(TensorLike())\nTrue\n",
        "Question": "How  Built-in or user types aren\u2019t usually Tensor-like.But, they can be made Tensor-like by implementing __torch_function__., give an example?",
        "Id": 20,
        "source": "https://pytorch.org/docs/stable/torch.overrides.html",
        "context": " Built-in or user types aren\u2019t usually Tensor-like.But, they can be made Tensor-like by implementing __torch_function__."
    },
    {
        "Answer": ">>> is_tensor_method_or_property(torch.Tensor.add)\nTrue\n>>> is_tensor_method_or_property(torch.add)\nFalse\n",
        "Question": "How to use torch.overrides.is_tensor_method_or_property, give an example?",
        "Id": 21,
        "source": "https://pytorch.org/docs/stable/torch.overrides.html",
        "context": " This may be needed, in particular, for the following reasons:"
    },
    {
        "Answer": ">>> def dispatcher(a): # Must have the same signature as func\n...     return (a,)\n>>> @torch.overrides.wrap_torch_function(dispatcher)\n>>> def func(a): # This will make func dispatchable by __torch_function__\n...     return a + 0\n",
        "Question": "How to use torch.overrides.wrap_torch_function, give an example?",
        "Id": 22,
        "source": "https://pytorch.org/docs/stable/torch.overrides.html",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.empty(2, 3).uniform_(1, 2)\n>>> a\ntensor([[1.6835, 1.8474, 1.1929],\n        [1.0475, 1.7162, 1.4180]])\n>>> torch.mvlgamma(a, 2)\ntensor([[0.3928, 0.4007, 0.7586],\n        [1.0311, 0.3901, 0.5049]])\n",
        "Question": "How to use torch.mvlgamma, give an example?",
        "Id": 23,
        "source": "https://pytorch.org/docs/stable/generated/torch.mvlgamma.html#torch.mvlgamma",
        "context": " All elements must be greater thanp\u221212\\frac{p - 1}{2}2p\u22121\u200b, otherwise an error would be thrown."
    },
    {
        "Answer": ">>> x = torch.randn(2, 2, 2)\n>>> x\ntensor([[[-0.2525, -0.0466],\n         [ 0.3491, -0.2168]],\n\n        [[-0.5906,  1.6258],\n         [ 0.6444, -0.0542]]])\n>>> scales = (torch.randn(2) + 1) * 0.05\n>>> scales\ntensor([0.0475, 0.0486])\n>>> zero_points = torch.zeros(2).to(torch.long)\n>>> zero_points\ntensor([0, 0])\n>>> torch.fake_quantize_per_channel_affine(x, scales, zero_points, 1, 0, 255)\ntensor([[[0.0000, 0.0000],\n         [0.3405, 0.0000]],\n\n        [[0.0000, 1.6134],\n        [0.6323, 0.0000]]])\n",
        "Question": "How to use torch.fake_quantize_per_channel_affine, give an example?",
        "Id": 24,
        "source": "https://pytorch.org/docs/stable/generated/torch.fake_quantize_per_channel_affine.html#torch.fake_quantize_per_channel_affine",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.randn(2)\n>>> x\ntensor([1.4584, 0.7583])\n>>> torch.atleast_1d(x)\ntensor([1.4584, 0.7583])\n>>> x = torch.tensor(1.)\n>>> x\ntensor(1.)\n>>> torch.atleast_1d(x)\ntensor([1.])\n>>> x = torch.tensor(0.5)\n>>> y = torch.tensor(1.)\n>>> torch.atleast_1d((x,y))\n(tensor([0.5000]), tensor([1.]))\n",
        "Question": "How to use torch.atleast_1d, give an example?",
        "Id": 25,
        "source": "https://pytorch.org/docs/stable/generated/torch.atleast_1d.html#torch.atleast_1d",
        "context": " "
    },
    {
        "Answer": ">>> input = torch.tensor([-1.5, 0, 2.0])\n>>> values = torch.tensor([0.5])\n>>> torch.heaviside(input, values)\ntensor([0.0000, 0.5000, 1.0000])\n>>> values = torch.tensor([1.2, -2.0, 3.5])\n>>> torch.heaviside(input, values)\ntensor([0., -2., 1.])\n",
        "Question": "How to use torch.heaviside, give an example?",
        "Id": 26,
        "source": "https://pytorch.org/docs/stable/generated/torch.heaviside.html#torch.heaviside",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor(1.)\n>>> x\ntensor(1.)\n>>> torch.atleast_2d(x)\ntensor([[1.]])\n>>> x = torch.randn(2,2)\n>>> x\ntensor([[2.2086, 2.5165],\n        [0.1757, 0.5194]])\n>>> torch.atleast_2d(x)\ntensor([[2.2086, 2.5165],\n        [0.1757, 0.5194]])\n>>> x = torch.tensor(0.5)\n>>> y = torch.tensor(1.)\n>>> torch.atleast_2d((x,y))\n(tensor([[0.5000]]), tensor([[1.]]))\n",
        "Question": "How to use torch.atleast_2d, give an example?",
        "Id": 27,
        "source": "https://pytorch.org/docs/stable/generated/torch.atleast_2d.html#torch.atleast_2d",
        "context": " "
    },
    {
        "Answer": ">>> torch.ldexp(torch.tensor([1.]), torch.tensor([1]))\ntensor([2.])\n>>> torch.ldexp(torch.tensor([1.0]), torch.tensor([1, 2, 3, 4]))\ntensor([ 2.,  4.,  8., 16.])\n",
        "Question": "How to use torch.ldexp, give an example?",
        "Id": 28,
        "source": "https://pytorch.org/docs/stable/generated/torch.ldexp.html#torch.ldexp",
        "context": " Typically this function is used to construct floating point numbers by multiplying\nmantissas ininputwith integral powers of two created from the exponents\nin :attr:\u2019other\u2019."
    },
    {
        "Answer": ">>> torch.promote_types(torch.int32, torch.float32)\ntorch.float32\n>>> torch.promote_types(torch.uint8, torch.long)\ntorch.long\n",
        "Question": "How to use torch.promote_types, give an example?",
        "Id": 29,
        "source": "https://pytorch.org/docs/stable/generated/torch.promote_types.html#torch.promote_types",
        "context": " "
    },
    {
        "Answer": ">>> eps = torch.finfo(torch.float32).eps\n>>> torch.nextafter(torch.tensor([1.0, 2.0]), torch.tensor([2.0, 1.0])) == torch.tensor([eps + 1, 2 - eps])\ntensor([True, True])\n",
        "Question": "How to use torch.nextafter, give an example?",
        "Id": 30,
        "source": "https://pytorch.org/docs/stable/generated/torch.nextafter.html#torch.nextafter",
        "context": " The shapes ofinputandothermust bebroadcastable."
    },
    {
        "Answer": ">>> torch.tensor([1.2, 3]).dtype    # initial default for floating point is torch.float32\ntorch.float32\n>>> torch.set_default_tensor_type(torch.DoubleTensor)\n>>> torch.tensor([1.2, 3]).dtype    # a new floating point tensor\ntorch.float64\n",
        "Question": "How to use torch.set_default_tensor_type, give an example?",
        "Id": 31,
        "source": "https://pytorch.org/docs/stable/generated/torch.set_default_tensor_type.html#torch.set_default_tensor_type",
        "context": " The default floating point tensor type is initiallytorch.FloatTensor."
    },
    {
        "Answer": ">>> a = torch.randn(3)\n>>> a\ntensor([-0.2956, -0.9068,  0.1695])\n>>> torch.diagflat(a)\ntensor([[-0.2956,  0.0000,  0.0000],\n        [ 0.0000, -0.9068,  0.0000],\n        [ 0.0000,  0.0000,  0.1695]])\n>>> torch.diagflat(a, 1)\ntensor([[ 0.0000, -0.2956,  0.0000,  0.0000],\n        [ 0.0000,  0.0000, -0.9068,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  0.1695],\n        [ 0.0000,  0.0000,  0.0000,  0.0000]])\n\n>>> a = torch.randn(2, 2)\n>>> a\ntensor([[ 0.2094, -0.3018],\n        [-0.1516,  1.9342]])\n>>> torch.diagflat(a)\ntensor([[ 0.2094,  0.0000,  0.0000,  0.0000],\n        [ 0.0000, -0.3018,  0.0000,  0.0000],\n        [ 0.0000,  0.0000, -0.1516,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  1.9342]])\n",
        "Question": "How to use torch.diagflat, give an example?",
        "Id": 32,
        "source": "https://pytorch.org/docs/stable/generated/torch.diagflat.html#torch.diagflat",
        "context": " "
    },
    {
        "Answer": ">>> A = torch.randn(2, 3, 3)\n>>> A_LU, pivots = A.lu()\n>>> P, A_L, A_U = torch.lu_unpack(A_LU, pivots)\n>>>\n>>> # can recover A from factorization\n>>> A_ = torch.bmm(P, torch.bmm(A_L, A_U))\n\n>>> # LU factorization of a rectangular matrix:\n>>> A = torch.randn(2, 3, 2)\n>>> A_LU, pivots = A.lu()\n>>> P, A_L, A_U = torch.lu_unpack(A_LU, pivots)\n>>> P\ntensor([[[1., 0., 0.],\n         [0., 1., 0.],\n         [0., 0., 1.]],\n\n        [[0., 0., 1.],\n         [0., 1., 0.],\n         [1., 0., 0.]]])\n>>> A_L\ntensor([[[ 1.0000,  0.0000],\n         [ 0.4763,  1.0000],\n         [ 0.3683,  0.1135]],\n\n        [[ 1.0000,  0.0000],\n         [ 0.2957,  1.0000],\n         [-0.9668, -0.3335]]])\n>>> A_U\ntensor([[[ 2.1962,  1.0881],\n         [ 0.0000, -0.8681]],\n\n        [[-1.0947,  0.3736],\n         [ 0.0000,  0.5718]]])\n>>> A_ = torch.bmm(P, torch.bmm(A_L, A_U))\n>>> torch.norm(A_ - A)\ntensor(2.9802e-08)\n",
        "Question": "How to use torch.lu_unpack, give an example?",
        "Id": 33,
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_unpack.html#torch.lu_unpack",
        "context": " Returns a tuple of tensors as(thePtensor(permutationmatrix),theLtensor,theUtensor)."
    },
    {
        "Answer": ">>> M = torch.randn(2)\n>>> mat = torch.randn(2, 3)\n>>> vec = torch.randn(3)\n>>> torch.addmv(M, mat, vec)\ntensor([-0.3768, -5.5565])\n",
        "Question": "How to use torch.addmv, give an example?",
        "Id": 34,
        "source": "https://pytorch.org/docs/stable/generated/torch.addmv.html#torch.addmv",
        "context": " For inputs of typeFloatTensororDoubleTensor, argumentsbetaandalphamust be real numbers, otherwise they should be integers"
    },
    {
        "Answer": ">>> a = torch.tensor([1, float('nan'), 3, 2])\n>>> a.median()\ntensor(nan)\n>>> a.nanmedian()\ntensor(2.)\n",
        "Question": "How to use torch.nanmedian, give an example?",
        "Id": 35,
        "source": "https://pytorch.org/docs/stable/generated/torch.nanmedian.html#torch.nanmedian",
        "context": " This function is identical totorch.median()when there are noNaNvalues ininput.\nWheninputhas one or moreNaNvalues,torch.median()will always returnNaN,\nwhile this function will return the median of the non-NaNelements ininput.\nIf all the elements ininputareNaNit will also returnNaN."
    },
    {
        "Answer": ">>> a = torch.tensor([[2, 3, 1], [float('nan'), 1, float('nan')]])\n>>> a\ntensor([[2., 3., 1.],\n        [nan, 1., nan]])\n>>> a.median(0)\ntorch.return_types.median(values=tensor([nan, 1., nan]), indices=tensor([1, 1, 1]))\n>>> a.nanmedian(0)\ntorch.return_types.nanmedian(values=tensor([2., 1., 1.]), indices=tensor([0, 1, 0]))\n",
        "Question": "How  This function is identical totorch.median()when there are noNaNvalues in a reduced row. When a reduced row has\none or moreNaNvalues,torch.median()will always reduce it toNaN, while this function will reduce it to the\nmedian of the non-NaNelements. If all the elements in a reduced row areNaNthen it will be reduced toNaN, too., give an example?",
        "Id": 36,
        "source": "https://pytorch.org/docs/stable/generated/torch.nanmedian.html#torch.nanmedian",
        "context": " This function is identical totorch.median()when there are noNaNvalues in a reduced row. When a reduced row has\none or moreNaNvalues,torch.median()will always reduce it toNaN, while this function will reduce it to the\nmedian of the non-NaNelements. If all the elements in a reduced row areNaNthen it will be reduced toNaN, too."
    },
    {
        "Answer": ">>> a = torch.empty_strided((2, 3), (1, 2))\n>>> a\ntensor([[8.9683e-44, 4.4842e-44, 5.1239e+07],\n        [0.0000e+00, 0.0000e+00, 3.0705e-41]])\n>>> a.stride()\n(1, 2)\n>>> a.size()\ntorch.Size([2, 3])\n",
        "Question": "How to use torch.empty_strided, give an example?",
        "Id": 37,
        "source": "https://pytorch.org/docs/stable/generated/torch.empty_strided.html#torch.empty_strided",
        "context": " "
    },
    {
        "Answer": ">>> torch.isnan(torch.tensor([1, float('nan'), 2]))\ntensor([False, True, False])\n",
        "Question": "How to use torch.isnan, give an example?",
        "Id": 38,
        "source": "https://pytorch.org/docs/stable/generated/torch.isnan.html#torch.isnan",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor(0.5)\n>>> x\ntensor(0.5000)\n>>> torch.atleast_3d(x)\ntensor([[[0.5000]]])\n>>> y = torch.randn(2,2)\n>>> y\ntensor([[-0.8079,  0.7460],\n        [-1.1647,  1.4734]])\n>>> torch.atleast_3d(y)\ntensor([[[-0.8079],\n        [ 0.7460]],\n\n        [[-1.1647],\n        [ 1.4734]]])\n>>> x = torch.randn(1,1,1)\n>>> x\ntensor([[[-1.5689]]])\n>>> torch.atleast_3d(x)\ntensor([[[-1.5689]]])\n>>> x = torch.tensor(0.5)\n>>> y = torch.tensor(1.)\n>>> torch.atleast_3d((x,y))\n(tensor([[[0.5000]]]), tensor([[[1.]]]))\n",
        "Question": "How to use torch.atleast_3d, give an example?",
        "Id": 39,
        "source": "https://pytorch.org/docs/stable/generated/torch.atleast_3d.html#torch.atleast_3d",
        "context": " "
    },
    {
        "Answer": ">>> torch.bitwise_xor(torch.tensor([-1, -2, 3], dtype=torch.int8), torch.tensor([1, 0, 3], dtype=torch.int8))\ntensor([-2, -2,  0], dtype=torch.int8)\n>>> torch.bitwise_xor(torch.tensor([True, True, False]), torch.tensor([False, True, False]))\ntensor([ True, False, False])\n",
        "Question": "How to use torch.bitwise_xor, give an example?",
        "Id": 40,
        "source": "https://pytorch.org/docs/stable/generated/torch.bitwise_xor.html#torch.bitwise_xor",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.5380, -0.8632, -0.1265,  0.9399])\n>>> torch.sinh(a)\ntensor([ 0.5644, -0.9744, -0.1268,  1.0845])\n",
        "Question": "How to use torch.sinh, give an example?",
        "Id": 41,
        "source": "https://pytorch.org/docs/stable/generated/torch.sinh.html#torch.sinh",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8]).view(4, 2)\n>>> x\ntensor([[1, 2],\n        [3, 4],\n        [5, 6],\n        [7, 8]])\n>>> torch.roll(x, 1, 0)\ntensor([[7, 8],\n        [1, 2],\n        [3, 4],\n        [5, 6]])\n>>> torch.roll(x, -1, 0)\ntensor([[3, 4],\n        [5, 6],\n        [7, 8],\n        [1, 2]])\n>>> torch.roll(x, shifts=(2, 1), dims=(0, 1))\ntensor([[6, 5],\n        [8, 7],\n        [2, 1],\n        [4, 3]])\n",
        "Question": "How to use torch.roll, give an example?",
        "Id": 42,
        "source": "https://pytorch.org/docs/stable/generated/torch.roll.html#torch.roll",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([1, 2, 3])\n>>> x.tile((2,))\ntensor([1, 2, 3, 1, 2, 3])\n>>> y = torch.tensor([[1, 2], [3, 4]])\n>>> torch.tile(y, (2, 2))\ntensor([[1, 2, 1, 2],\n        [3, 4, 3, 4],\n        [1, 2, 1, 2],\n        [3, 4, 3, 4]])\n",
        "Question": "How to use torch.tile, give an example?",
        "Id": 43,
        "source": "https://pytorch.org/docs/stable/generated/torch.tile.html#torch.tile",
        "context": " Analogously, ifinputhas fewer dimensions thanrepsspecifies, theninputis treated as if it were unsqueezed at\ndimension zero until it has as many dimensions asrepsspecifies.\nFor example, ifinputhas shape (4, 2) andrepsis (3, 3, 2, 2), theninputis treated as if it had the\nshape (1, 1, 4, 2)."
    },
    {
        "Answer": ">>> x = torch.arange(1., 6.)\n>>> x\ntensor([ 1.,  2.,  3.,  4.,  5.])\n>>> torch.topk(x, 3)\ntorch.return_types.topk(values=tensor([5., 4., 3.]), indices=tensor([4, 3, 2]))\n",
        "Question": "How to use torch.topk, give an example?",
        "Id": 44,
        "source": "https://pytorch.org/docs/stable/generated/torch.topk.html#torch.topk",
        "context": " The boolean optionsortedifTrue, will make sure that the returnedkelements are themselves sorted"
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-2.0755,  1.0226,  0.0831,  0.4806])\n>>> torch.sqrt(a)\ntensor([    nan,  1.0112,  0.2883,  0.6933])\n",
        "Question": "How to use torch.sqrt, give an example?",
        "Id": 45,
        "source": "https://pytorch.org/docs/stable/generated/torch.sqrt.html#torch.sqrt",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor((1, 2, -1))\n>>> b = torch.tensor((3, 0, 4))\n>>> torch.minimum(a, b)\ntensor([1, 0, -1])\n",
        "Question": "How to use torch.minimum, give an example?",
        "Id": 46,
        "source": "https://pytorch.org/docs/stable/generated/torch.minimum.html#torch.minimum",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([4.0, 3.0])\n>>> b = torch.tensor([2.0, 2.0])\n>>> torch.floor_divide(a, b)\ntensor([2.0, 1.0])\n>>> torch.floor_divide(a, 1.4)\ntensor([2.0, 2.0])\n",
        "Question": "How to use torch.floor_divide, give an example?",
        "Id": 47,
        "source": "https://pytorch.org/docs/stable/generated/torch.floor_divide.html#torch.floor_divide",
        "context": " Supports broadcasting to a common shape, type promotion, and integer and float inputs."
    },
    {
        "Answer": ">>> t = torch.tensor([3+4j, 7-24j, 0, 1+2j])\n>>> t.sgn()\ntensor([0.6000+0.8000j, 0.2800-0.9600j, 0.0000+0.0000j, 0.4472+0.8944j])\n",
        "Question": "How to use torch.sgn, give an example?",
        "Id": 48,
        "source": "https://pytorch.org/docs/stable/generated/torch.sgn.html#torch.sgn",
        "context": " "
    },
    {
        "Answer": ">>> input = torch.empty(2, 3)\n>>> torch.ones_like(input)\ntensor([[ 1.,  1.,  1.],\n        [ 1.,  1.,  1.]])\n",
        "Question": "How to use torch.ones_like, give an example?",
        "Id": 49,
        "source": "https://pytorch.org/docs/stable/generated/torch.ones_like.html#torch.ones_like",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([1], requires_grad=True)\n>>> with torch.no_grad():\n...   y = x * 2\n>>> y.requires_grad\nFalse\n>>> @torch.no_grad()\n... def doubler(x):\n...     return x * 2\n>>> z = doubler(x)\n>>> z.requires_grad\nFalse\n",
        "Question": "How to use torch.no_grad, give an example?",
        "Id": 50,
        "source": "https://pytorch.org/docs/stable/generated/torch.no_grad.html#torch.no_grad",
        "context": " Also functions as a decorator. (Make sure to instantiate with parenthesis.)"
    },
    {
        "Answer": ">>> x=torch.randn(4, 2)\n>>> x\ntensor([[ 1.6116, -0.5772],\n        [-1.4606, -0.9120],\n        [ 0.0786, -1.7497],\n        [-0.6561, -1.6623]])\n>>> torch.view_as_complex(x)\ntensor([(1.6116-0.5772j), (-1.4606-0.9120j), (0.0786-1.7497j), (-0.6561-1.6623j)])\n",
        "Question": "How to use torch.view_as_complex, give an example?",
        "Id": 51,
        "source": "https://pytorch.org/docs/stable/generated/torch.view_as_complex.html#torch.view_as_complex",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n>>> x\ntensor([[[0, 1],\n        [2, 3]],\n\n        [[4, 5],\n        [6, 7]]])\n>>> torch.swapaxes(x, 0, 1)\ntensor([[[0, 1],\n        [4, 5]],\n\n        [[2, 3],\n        [6, 7]]])\n>>> torch.swapaxes(x, 0, 2)\ntensor([[[0, 4],\n        [2, 6]],\n\n        [[1, 5],\n        [3, 7]]])\n",
        "Question": "How to use torch.swapaxes, give an example?",
        "Id": 52,
        "source": "https://pytorch.org/docs/stable/generated/torch.swapaxes.html#torch.swapaxes",
        "context": " This function is equivalent to NumPy\u2019s swapaxes function."
    },
    {
        "Answer": ">>> torch.logical_xor(torch.tensor([True, False, True]), torch.tensor([True, False, False]))\ntensor([False, False,  True])\n>>> a = torch.tensor([0, 1, 10, 0], dtype=torch.int8)\n>>> b = torch.tensor([4, 0, 1, 0], dtype=torch.int8)\n>>> torch.logical_xor(a, b)\ntensor([ True,  True, False, False])\n>>> torch.logical_xor(a.double(), b.double())\ntensor([ True,  True, False, False])\n>>> torch.logical_xor(a.double(), b)\ntensor([ True,  True, False, False])\n>>> torch.logical_xor(a, b, out=torch.empty(4, dtype=torch.bool))\ntensor([ True,  True, False, False])\n",
        "Question": "How to use torch.logical_xor, give an example?",
        "Id": 53,
        "source": "https://pytorch.org/docs/stable/generated/torch.logical_xor.html#torch.logical_xor",
        "context": " "
    },
    {
        "Answer": ">>> float_tensor = torch.ones(1, dtype=torch.float)\n>>> double_tensor = torch.ones(1, dtype=torch.double)\n>>> complex_float_tensor = torch.ones(1, dtype=torch.complex64)\n>>> complex_double_tensor = torch.ones(1, dtype=torch.complex128)\n>>> int_tensor = torch.ones(1, dtype=torch.int)\n>>> long_tensor = torch.ones(1, dtype=torch.long)\n>>> uint_tensor = torch.ones(1, dtype=torch.uint8)\n>>> double_tensor = torch.ones(1, dtype=torch.double)\n>>> bool_tensor = torch.ones(1, dtype=torch.bool)\n# zero-dim tensors\n>>> long_zerodim = torch.tensor(1, dtype=torch.long)\n>>> int_zerodim = torch.tensor(1, dtype=torch.int)\n\n>>> torch.add(5, 5).dtype\ntorch.int64\n# 5 is an int64, but does not have higher category than int_tensor so is not considered.\n>>> (int_tensor + 5).dtype\ntorch.int32\n>>> (int_tensor + long_zerodim).dtype\ntorch.int32\n>>> (long_tensor + int_tensor).dtype\ntorch.int64\n>>> (bool_tensor + long_tensor).dtype\ntorch.int64\n>>> (bool_tensor + uint_tensor).dtype\ntorch.uint8\n>>> (float_tensor + double_tensor).dtype\ntorch.float64\n>>> (complex_float_tensor + complex_double_tensor).dtype\ntorch.complex128\n>>> (bool_tensor + int_tensor).dtype\ntorch.int32\n# Since long is a different kind than float, result dtype only needs to be large enough\n# to hold the float.\n>>> torch.add(long_tensor, float_tensor).dtype\ntorch.float32\n",
        "Question": "How to use A floating point scalar operand has dtypetorch.get_default_dtype()and an integral\nnon-boolean scalar operand has dtypetorch.int64. Unlike numpy, we do not inspect\nvalues when determining the minimumdtypesof an operand.  Quantized and complex types\nare not yet supported., give an example?",
        "Id": 54,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " A floating point scalar operand has dtypetorch.get_default_dtype()and an integral\nnon-boolean scalar operand has dtypetorch.int64. Unlike numpy, we do not inspect\nvalues when determining the minimumdtypesof an operand.  Quantized and complex types\nare not yet supported."
    },
    {
        "Answer": "# allowed:\n>>> float_tensor *= float_tensor\n>>> float_tensor *= int_tensor\n>>> float_tensor *= uint_tensor\n>>> float_tensor *= bool_tensor\n>>> float_tensor *= double_tensor\n>>> int_tensor *= long_tensor\n>>> int_tensor *= uint_tensor\n>>> uint_tensor *= int_tensor\n\n# disallowed (RuntimeError: result type can't be cast to the desired output type):\n>>> int_tensor *= float_tensor\n>>> bool_tensor *= int_tensor\n>>> bool_tensor *= uint_tensor\n>>> float_tensor *= complex_float_tensor\n",
        "Question": "How to use torch dtype, give an example?",
        "Id": 55,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " "
    },
    {
        "Answer": ">>> torch.device('cuda:0')\ndevice(type='cuda', index=0)\n\n>>> torch.device('cpu')\ndevice(type='cpu')\n\n>>> torch.device('cuda')  # current cuda device\ndevice(type='cuda')\n",
        "Question": "How to use Atorch.devicecan be constructed via a string or via a string and device ordinalVia a string:, give an example?",
        "Id": 56,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " Atorch.devicecan be constructed via a string or via a string and device ordinalVia a string:"
    },
    {
        "Answer": ">>> torch.device('cuda', 0)\ndevice(type='cuda', index=0)\n\n>>> torch.device('cpu', 0)\ndevice(type='cpu', index=0)\n",
        "Question": "How to use Via a string:Via a string and device ordinal:, give an example?",
        "Id": 57,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " Via a string:Via a string and device ordinal:"
    },
    {
        "Answer": ">>> # Example of a function that takes in a torch.device\n>>> cuda1 = torch.device('cuda:1')\n>>> torch.randn((2,3), device=cuda1)\n",
        "Question": "How to use NoteThetorch.deviceargument in functions can generally be substituted with a string.\nThis allows for fast prototyping of code., give an example?",
        "Id": 58,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " Thetorch.deviceargument in functions can generally be substituted with a string.\nThis allows for fast prototyping of code."
    },
    {
        "Answer": ">>> # You can substitute the torch.device with a string\n>>> torch.randn((2,3), device='cuda:1')\n",
        "Question": "How  Thetorch.deviceargument in functions can generally be substituted with a string.\nThis allows for fast prototyping of code., give an example?",
        "Id": 59,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " Thetorch.deviceargument in functions can generally be substituted with a string.\nThis allows for fast prototyping of code."
    },
    {
        "Answer": ">>> torch.device(1)\ndevice(type='cuda', index=1)\n",
        "Question": "How to use NoteFor legacy reasons, a device can be constructed via a single device ordinal, which is treated\nas a cuda device.  This matchesTensor.get_device(), which returns an ordinal for cuda\ntensors and is not supported for cpu tensors., give an example?",
        "Id": 60,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " For legacy reasons, a device can be constructed via a single device ordinal, which is treated\nas a cuda device.  This matchesTensor.get_device(), which returns an ordinal for cuda\ntensors and is not supported for cpu tensors."
    },
    {
        "Answer": ">>> torch.randn((2,3), device=torch.device('cuda:1'))\n>>> torch.randn((2,3), device='cuda:1')\n>>> torch.randn((2,3), device=1)  # legacy\n",
        "Question": "How to use NoteMethods which take a device will generally accept a (properly formatted) string\nor (legacy) integer device ordinal, i.e. the following are all equivalent:, give an example?",
        "Id": 61,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " Methods which take a device will generally accept a (properly formatted) string\nor (legacy) integer device ordinal, i.e. the following are all equivalent:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n>>> x.stride()\n(5, 1)\n\n>>> x.t().stride()\n(1, 5)\n",
        "Question": "How to use torch.stridedrepresents dense Tensors and is the memory layout that\nis most commonly used. Each strided tensor has an associatedtorch.Storage, which holds its data. These tensors provide\nmulti-dimensional,stridedview of a storage. Strides are a list of integers: the k-th stride\nrepresents the jump in the memory necessary to go from one element to the\nnext one in the k-th dimension of the Tensor. This concept makes it possible\nto perform many tensor operations efficiently., give an example?",
        "Id": 62,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#torch.torch.dtype",
        "context": " torch.stridedrepresents dense Tensors and is the memory layout that\nis most commonly used. Each strided tensor has an associatedtorch.Storage, which holds its data. These tensors provide\nmulti-dimensional,stridedview of a storage. Strides are a list of integers: the k-th stride\nrepresents the jump in the memory necessary to go from one element to the\nnext one in the k-th dimension of the Tensor. This concept makes it possible\nto perform many tensor operations efficiently."
    },
    {
        "Answer": ">>> a = torch.randn(1, 3)\n>>> a\ntensor([[ 1.5219, -1.5212,  0.2202]])\n>>> torch.median(a)\ntensor(0.2202)\n",
        "Question": "How to use torch.median, give an example?",
        "Id": 63,
        "source": "https://pytorch.org/docs/stable/generated/torch.median.html#torch.median",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4, 5)\n>>> a\ntensor([[ 0.2505, -0.3982, -0.9948,  0.3518, -1.3131],\n        [ 0.3180, -0.6993,  1.0436,  0.0438,  0.2270],\n        [-0.2751,  0.7303,  0.2192,  0.3321,  0.2488],\n        [ 1.0778, -1.9510,  0.7048,  0.4742, -0.7125]])\n>>> torch.median(a, 1)\ntorch.return_types.median(values=tensor([-0.3982,  0.2270,  0.2488,  0.4742]), indices=tensor([1, 4, 4, 3]))\n",
        "Question": "How  IfkeepdimisTrue, the output tensors are of the same size\nasinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe outputs tensor having 1 fewer dimension thaninput., give an example?",
        "Id": 64,
        "source": "https://pytorch.org/docs/stable/generated/torch.median.html#torch.median",
        "context": " IfkeepdimisTrue, the output tensors are of the same size\nasinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe outputs tensor having 1 fewer dimension thaninput."
    },
    {
        "Answer": "import torch\nimport torchvision\n\ndummy_input = torch.randn(10, 3, 224, 224, device='cuda')\nmodel = torchvision.models.alexnet(pretrained=True).cuda()\n\n# Providing input and output names sets the display names for values\n# within the model's graph. Setting these does not change the semantics\n# of the graph; it is only for readability.\n#\n# The inputs to the network consist of the flat list of inputs (i.e.\n# the values you would pass to the forward() method) followed by the\n# flat list of parameters. You can partially specify names, i.e. provide\n# a list here shorter than the number of inputs to the model, and we will\n# only set that subset of names, starting from the beginning.\ninput_names = [ \"actual_input_1\" ] + [ \"learned_%d\" % i for i in range(16) ]\noutput_names = [ \"output1\" ]\n\ntorch.onnx.export(model, dummy_input, \"alexnet.onnx\", verbose=True, input_names=input_names, output_names=output_names)\n",
        "Question": "How to use Here is a simple script which exports a pretrained AlexNet as defined in\ntorchvision into ONNX.  It runs a single round of inference and then\nsaves the resulting traced model toalexnet.onnx:, give an example?",
        "Id": 65,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Here is a simple script which exports a pretrained AlexNet as defined in\ntorchvision into ONNX.  It runs a single round of inference and then\nsaves the resulting traced model toalexnet.onnx:"
    },
    {
        "Answer": "# These are the inputs and parameters to the network, which have taken on\n# the names we specified earlier.\ngraph(%actual_input_1 : Float(10, 3, 224, 224)\n      %learned_0 : Float(64, 3, 11, 11)\n      %learned_1 : Float(64)\n      %learned_2 : Float(192, 64, 5, 5)\n      %learned_3 : Float(192)\n      # ---- omitted for brevity ----\n      %learned_14 : Float(1000, 4096)\n      %learned_15 : Float(1000)) {\n  # Every statement consists of some output tensors (and their types),\n  # the operator to be run (with its attributes, e.g., kernels, strides,\n  # etc.), its input tensors (%actual_input_1, %learned_0, %learned_1)\n  %17 : Float(10, 64, 55, 55) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[11, 11], pads=[2, 2, 2, 2], strides=[4, 4]](%actual_input_1, %learned_0, %learned_1), scope: AlexNet/Sequential[features]/Conv2d[0]\n  %18 : Float(10, 64, 55, 55) = onnx::Relu(%17), scope: AlexNet/Sequential[features]/ReLU[1]\n  %19 : Float(10, 64, 27, 27) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%18), scope: AlexNet/Sequential[features]/MaxPool2d[2]\n  # ---- omitted for brevity ----\n  %29 : Float(10, 256, 6, 6) = onnx::MaxPool[kernel_shape=[3, 3], pads=[0, 0, 0, 0], strides=[2, 2]](%28), scope: AlexNet/Sequential[features]/MaxPool2d[12]\n  # Dynamic means that the shape is not known. This may be because of a\n  # limitation of our implementation (which we would like to fix in a\n  # future release) or shapes which are truly dynamic.\n  %30 : Dynamic = onnx::Shape(%29), scope: AlexNet\n  %31 : Dynamic = onnx::Slice[axes=[0], ends=[1], starts=[0]](%30), scope: AlexNet\n  %32 : Long() = onnx::Squeeze[axes=[0]](%31), scope: AlexNet\n  %33 : Long() = onnx::Constant[value={9216}](), scope: AlexNet\n  # ---- omitted for brevity ----\n  %output1 : Float(10, 1000) = onnx::Gemm[alpha=1, beta=1, broadcast=1, transB=1](%45, %learned_14, %learned_15), scope: AlexNet/Sequential[classifier]/Linear[6]\n  return (%output1);\n}\n",
        "Question": "How to use Here is a simple script which exports a pretrained AlexNet as defined in\ntorchvision into ONNX.  It runs a single round of inference and then\nsaves the resulting traced model toalexnet.onnx:The resultingalexnet.onnxis a binary protobuf file which contains both\nthe network structure and parameters of the model you exported\n(in this case, AlexNet).  The keyword argumentverbose=Truecauses the\nexporter to print out a human-readable representation of the network:, give an example?",
        "Id": 66,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " The resultingalexnet.onnxis a binary protobuf file which contains both\nthe network structure and parameters of the model you exported\n(in this case, AlexNet).  The keyword argumentverbose=Truecauses the\nexporter to print out a human-readable representation of the network:"
    },
    {
        "Answer": "conda install -c conda-forge onnx\n",
        "Question": "How to use The resultingalexnet.onnxis a binary protobuf file which contains both\nthe network structure and parameters of the model you exported\n(in this case, AlexNet).  The keyword argumentverbose=Truecauses the\nexporter to print out a human-readable representation of the network:You can also verify the protobuf using theONNXlibrary.\nYou can installONNXwith conda:, give an example?",
        "Id": 67,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " The resultingalexnet.onnxis a binary protobuf file which contains both\nthe network structure and parameters of the model you exported\n(in this case, AlexNet).  The keyword argumentverbose=Truecauses the\nexporter to print out a human-readable representation of the network:You can also verify the protobuf using theONNXlibrary.\nYou can installONNXwith conda:"
    },
    {
        "Answer": "import onnx\n\n# Load the ONNX model\nmodel = onnx.load(\"alexnet.onnx\")\n\n# Check that the IR is well formed\nonnx.checker.check_model(model)\n\n# Print a human readable representation of the graph\nonnx.helper.printable_graph(model.graph)\n",
        "Question": "How to use You can also verify the protobuf using theONNXlibrary.\nYou can installONNXwith conda:Then, you can run:, give an example?",
        "Id": 68,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " You can also verify the protobuf using theONNXlibrary.\nYou can installONNXwith conda:Then, you can run:"
    },
    {
        "Answer": "# ...continuing from above\nimport caffe2.python.onnx.backend as backend\nimport numpy as np\n\nrep = backend.prepare(model, device=\"CUDA:0\") # or \"CPU\"\n# For the Caffe2 backend:\n#     rep.predict_net is the Caffe2 protobuf for the network\n#     rep.workspace is the Caffe2 workspace for the network\n#       (see the class caffe2.python.onnx.backend.Workspace)\noutputs = rep.run(np.random.randn(10, 3, 224, 224).astype(np.float32))\n# To run networks with more than one input, pass a tuple\n# rather than a single numpy ndarray.\nprint(outputs[0])\n",
        "Question": "How to use To run the exported script withcaffe2, you will need to installcaffe2: If you don\u2019t have one already, Pleasefollow the install instructions.Once these are installed, you can use the backend for Caffe2:, give an example?",
        "Id": 69,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " To run the exported script withcaffe2, you will need to installcaffe2: If you don\u2019t have one already, Pleasefollow the install instructions.Once these are installed, you can use the backend for Caffe2:"
    },
    {
        "Answer": "# ...continuing from above\nimport onnxruntime as ort\n\nort_session = ort.InferenceSession('alexnet.onnx')\n\noutputs = ort_session.run(None, {'actual_input_1': np.random.randn(10, 3, 224, 224).astype(np.float32)})\n\nprint(outputs[0])\n",
        "Question": "How to use You can also run the exported model withONNX Runtime,\nyou will need to installONNX Runtime: pleasefollow these instructions.Once these are installed, you can use the backend for ONNX Runtime:, give an example?",
        "Id": 70,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " You can also run the exported model withONNX Runtime,\nyou will need to installONNX Runtime: pleasefollow these instructions.Once these are installed, you can use the backend for ONNX Runtime:"
    },
    {
        "Answer": "import torch\n\n# Trace-based only\n\nclass LoopModel(torch.nn.Module):\n    def forward(self, x, y):\n        for i in range(y):\n            x = x + i\n        return x\n\nmodel = LoopModel()\ndummy_input = torch.ones(2, 3, dtype=torch.long)\nloop_count = torch.tensor(5, dtype=torch.long)\n\ntorch.onnx.export(model, (dummy_input, loop_count), 'loop.onnx', verbose=True)\n",
        "Question": "How to use The ONNX exporter can be bothtrace-basedandscript-basedexporter.We allow mixing tracing and scripting. You can compose tracing and scripting to suit the particular requirements\nof a part of a model.  Checkout this example:, give an example?",
        "Id": 71,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " We allow mixing tracing and scripting. You can compose tracing and scripting to suit the particular requirements\nof a part of a model.  Checkout this example:"
    },
    {
        "Answer": "graph(%0 : Long(2, 3),\n      %1 : Long()):\n  %2 : Tensor = onnx::Constant[value={1}]()\n  %3 : Tensor = onnx::Add(%0, %2)\n  %4 : Tensor = onnx::Constant[value={2}]()\n  %5 : Tensor = onnx::Add(%3, %4)\n  %6 : Tensor = onnx::Constant[value={3}]()\n  %7 : Tensor = onnx::Add(%5, %6)\n  %8 : Tensor = onnx::Constant[value={4}]()\n  %9 : Tensor = onnx::Add(%7, %8)\n  return (%9)\n",
        "Question": "How to use We allow mixing tracing and scripting. You can compose tracing and scripting to suit the particular requirements\nof a part of a model.  Checkout this example:Withtrace-basedexporter, we get the result ONNX graph which unrolls the for loop:, give an example?",
        "Id": 72,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " We allow mixing tracing and scripting. You can compose tracing and scripting to suit the particular requirements\nof a part of a model.  Checkout this example:Withtrace-basedexporter, we get the result ONNX graph which unrolls the for loop:"
    },
    {
        "Answer": "# Mixing tracing and scripting\n\n@torch.jit.script\ndef loop(x, y):\n    for i in range(int(y)):\n        x = x + i\n    return x\n\nclass LoopModel2(torch.nn.Module):\n    def forward(self, x, y):\n        return loop(x, y)\n\nmodel = LoopModel2()\ndummy_input = torch.ones(2, 3, dtype=torch.long)\nloop_count = torch.tensor(5, dtype=torch.long)\ntorch.onnx.export(model, (dummy_input, loop_count), 'loop.onnx', verbose=True,\n                  input_names=['input_data', 'loop_range'])\n",
        "Question": "How to use Withtrace-basedexporter, we get the result ONNX graph which unrolls the for loop:To utilizescript-basedexporter for capturing the dynamic loop,\nwe can write the loop in script, and call it from the regular nn.Module:, give an example?",
        "Id": 73,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Withtrace-basedexporter, we get the result ONNX graph which unrolls the for loop:To utilizescript-basedexporter for capturing the dynamic loop,\nwe can write the loop in script, and call it from the regular nn.Module:"
    },
    {
        "Answer": "graph(%input_data : Long(2, 3),\n      %loop_range : Long()):\n  %2 : Long() = onnx::Constant[value={1}](), scope: LoopModel2/loop\n  %3 : Tensor = onnx::Cast[to=9](%2)\n  %4 : Long(2, 3) = onnx::Loop(%loop_range, %3, %input_data), scope: LoopModel2/loop\n    block0(%i.1 : Long(), %cond : bool, %x.6 : Long(2, 3)):\n      %8 : Long(2, 3) = onnx::Add(%x.6, %i.1), scope: LoopModel2/loop\n      %9 : Tensor = onnx::Cast[to=9](%2)\n      -> (%9, %8)\n  return (%4)\n",
        "Question": "How to use To utilizescript-basedexporter for capturing the dynamic loop,\nwe can write the loop in script, and call it from the regular nn.Module:Now the exported ONNX graph becomes:, give an example?",
        "Id": 74,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " To utilizescript-basedexporter for capturing the dynamic loop,\nwe can write the loop in script, and call it from the regular nn.Module:Now the exported ONNX graph becomes:"
    },
    {
        "Answer": "import caffe2.python.onnx.backend as backend\nimport numpy as np\nimport onnx\nmodel = onnx.load('loop.onnx')\n\nrep = backend.prepare(model)\noutputs = rep.run((dummy_input.numpy(), np.array(9).astype(np.int64)))\nprint(outputs[0])\n#[[37 37 37]\n# [37 37 37]]\n\n\nimport onnxruntime as ort\nort_sess = ort.InferenceSession('loop.onnx')\noutputs = ort_sess.run(None, {'input_data': dummy_input.numpy(),\n                              'loop_range': np.array(9).astype(np.int64)})\nprint(outputs)\n#[array([[37, 37, 37],\n#       [37, 37, 37]], dtype=int64)]\n",
        "Question": "How to use Now the exported ONNX graph becomes:The dynamic control flow is captured correctly. We can verify in backends with different loop range., give an example?",
        "Id": 75,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Now the exported ONNX graph becomes:The dynamic control flow is captured correctly. We can verify in backends with different loop range."
    },
    {
        "Answer": "class LoopModel(torch.nn.Module):\n    def forward(self, x, y):\n        res = []\n        arr = x.split(2, 0)\n        for i in range(int(y)):\n            res += [arr[i].sum(0, False)]\n        return torch.stack(res)\n\nmodel = torch.jit.script(LoopModel())\ninputs = (torch.randn(16), torch.tensor(8))\n\nout = model(*inputs)\ntorch.onnx.export(model, inputs, 'loop_and_list.onnx', opset_version=11, example_outputs=out)\n",
        "Question": "How to use The dynamic control flow is captured correctly. We can verify in backends with different loop range.To avoid exporting a variable scalar tensor as a fixed value constant as part of the ONNX model, please\navoid use oftorch.Tensor.item(). Torch supports implicit cast of single-element tensors to numbers.\nE.g.:, give an example?",
        "Id": 76,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " The dynamic control flow is captured correctly. We can verify in backends with different loop range.To avoid exporting a variable scalar tensor as a fixed value constant as part of the ONNX model, please\navoid use oftorch.Tensor.item(). Torch supports implicit cast of single-element tensors to numbers.\nE.g.:"
    },
    {
        "Answer": "import torch\n\nclass Module(torch.nn.Module):\n    def forward(self, x, tup):\n        # type: (int, Tuple[Tensor, Tensor]) -> Tensor\n        t0, t1 = tup\n        return t0 + t1 + x\n",
        "Question": "How to use TorchScript only supports a subset of Python types. You can find more details about type annotationhere.Due to optimization purposes, TorchScript only supports variables with single static types for script functions.\nBy default, each variable is assumed to be Tensor. If an argument to a ScriptModule function is not Tensor,\nits type should be specified using MyPy-style annotations., give an example?",
        "Id": 77,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Due to optimization purposes, TorchScript only supports variables with single static types for script functions.\nBy default, each variable is assumed to be Tensor. If an argument to a ScriptModule function is not Tensor,\nits type should be specified using MyPy-style annotations."
    },
    {
        "Answer": "RuntimeError:\nTensor (inferred) cannot be used as a tuple:\n  File <filename>\n        def forward(self, x, tup):\n            t0, t1 = tup\n                     ~~~ <--- HERE\n            return t0 + t1 + x\n",
        "Question": "How to use Due to optimization purposes, TorchScript only supports variables with single static types for script functions.\nBy default, each variable is assumed to be Tensor. If an argument to a ScriptModule function is not Tensor,\nits type should be specified using MyPy-style annotations.If the type annotation is not specified, TorchScript compiler fails with the runtime error below., give an example?",
        "Id": 78,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Due to optimization purposes, TorchScript only supports variables with single static types for script functions.\nBy default, each variable is assumed to be Tensor. If an argument to a ScriptModule function is not Tensor,\nits type should be specified using MyPy-style annotations.If the type annotation is not specified, TorchScript compiler fails with the runtime error below."
    },
    {
        "Answer": "np.concatenate((x, y, z), axis=1)\n",
        "Question": "How to use PyTorch models can be written using numpy manipulations, but this is not proper when we convert to the ONNX model.\nFor the trace-based exporter, tracing treats the numpy values as the constant node,\ntherefore it calculates the wrong result if we change the input.\nSo the PyTorch model need implement using torch operators.\nFor example, do not use numpy operators on numpy tensors:, give an example?",
        "Id": 79,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " PyTorch models can be written using numpy manipulations, but this is not proper when we convert to the ONNX model.\nFor the trace-based exporter, tracing treats the numpy values as the constant node,\ntherefore it calculates the wrong result if we change the input.\nSo the PyTorch model need implement using torch operators.\nFor example, do not use numpy operators on numpy tensors:"
    },
    {
        "Answer": "y = x.astype(np.int)\n",
        "Question": "How to use PyTorch models can be written using numpy manipulations, but this is not proper when we convert to the ONNX model.\nFor the trace-based exporter, tracing treats the numpy values as the constant node,\ntherefore it calculates the wrong result if we change the input.\nSo the PyTorch model need implement using torch operators.\nFor example, do not use numpy operators on numpy tensors:do not convert to numpy types:, give an example?",
        "Id": 80,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " do not convert to numpy types:"
    },
    {
        "Answer": "class MyModule(nn.Module):\n    def __init__(self):\n        self.dropout = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.dropout(x)\n",
        "Question": "How to use do not convert to numpy types:Always use torch tensors and torch operators: torch.concat, etc.\nIn addition, Dropout layer need defined in init function so that inferencing can handle it properly, i.e.,, give an example?",
        "Id": 81,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " do not convert to numpy types:Always use torch tensors and torch operators: torch.concat, etc.\nIn addition, Dropout layer need defined in init function so that inferencing can handle it properly, i.e.,"
    },
    {
        "Answer": "class Model(torch.nn.Module):\n  def forward(self, x, y=None, z=None):\n    if y is not None:\n      return x + y\n    if z is not None:\n      return x + z\n    return x\nm = Model()\nx = torch.randn(2, 3)\nz = torch.randn(2, 3)\n",
        "Question": "How to use There are two ways to handle models which consist of named parameters or keyword arguments as inputs:For example, in the model:, give an example?",
        "Id": 82,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " For example, in the model:"
    },
    {
        "Answer": "torch.onnx.export(model, (x, None, z), \u2018test.onnx\u2019)\n",
        "Question": "How to use Not using a dictionary for the keyword arguments and passing all the inputs in the same order\nas required by the model, give an example?",
        "Id": 83,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Not using a dictionary for the keyword arguments and passing all the inputs in the same order\nas required by the model"
    },
    {
        "Answer": "torch.onnx.export(model, (x, {'y': None, 'z': z}), \u2018test.onnx\u2019)\n",
        "Question": "How to use Using a dictionary to represent the keyword arguments. This dictionary is always passed in\naddition to the non-keyword arguments and is always the last argument in the args tuple., give an example?",
        "Id": 84,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Using a dictionary to represent the keyword arguments. This dictionary is always passed in\naddition to the non-keyword arguments and is always the last argument in the args tuple."
    },
    {
        "Answer": "torch.onnx.export(model, (x, {}), \u2018test.onnx\u2019)\nor\ntorch.onnx.export(model, (x, ), \u2018test.onnx\u2019)\n",
        "Question": "How to use There are two ways of exporting the model:For cases in which there are no keyword arguments, models can be exported with either an\nempty or no dictionary. For example,, give an example?",
        "Id": 85,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " There are two ways of exporting the model:For cases in which there are no keyword arguments, models can be exported with either an\nempty or no dictionary. For example,"
    },
    {
        "Answer": "class Model(torch.nn.Module):\n  def forward(self, k, x):\n    ...\n    return x\nm = Model()\nk =\u202ftorch.randn(2, 3)\nx = {torch.tensor(1.):\u202ftorch.randn(2, 3)}\n",
        "Question": "How to use For cases in which there are no keyword arguments, models can be exported with either an\nempty or no dictionary. For example,An exception to this rule are cases in which the last input is also of a dictionary type.\nIn these cases it is mandatory to have an empty dictionary as the last argument in the\nargs tuple. For example,, give an example?",
        "Id": 86,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " For cases in which there are no keyword arguments, models can be exported with either an\nempty or no dictionary. For example,An exception to this rule are cases in which the last input is also of a dictionary type.\nIn these cases it is mandatory to have an empty dictionary as the last argument in the\nargs tuple. For example,"
    },
    {
        "Answer": "torch.onnx.export(model, (k, x, {}), \u2018test.onnx\u2019)\n",
        "Question": "How to use An exception to this rule are cases in which the last input is also of a dictionary type.\nIn these cases it is mandatory to have an empty dictionary as the last argument in the\nargs tuple. For example,Without the presence of the empty dictionary, the export call assumes that the\n\u2018x\u2019 input is intended to represent the optional dictionary consisting of named arguments.\nIn order to prevent this from being an issue a constraint is placed to provide an empty\ndictionary as the last input in the tuple args in such cases.\nThe new call would look like this., give an example?",
        "Id": 87,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " An exception to this rule are cases in which the last input is also of a dictionary type.\nIn these cases it is mandatory to have an empty dictionary as the last argument in the\nargs tuple. For example,Without the presence of the empty dictionary, the export call assumes that the\n\u2018x\u2019 input is intended to represent the optional dictionary consisting of named arguments.\nIn order to prevent this from being an issue a constraint is placed to provide an empty\ndictionary as the last input in the tuple args in such cases.\nThe new call would look like this."
    },
    {
        "Answer": "data = torch.randn(3, 4)\nindex = torch.tensor([1, 2])\n\n# RHS indexing is supported in ONNX opset >= 11.\nclass RHSIndexing(torch.nn.Module):\n    def forward(self, data, index):\n        return data[index]\n\nout = RHSIndexing()(data, index)\n\ntorch.onnx.export(RHSIndexing(), (data, index), 'indexing.onnx', opset_version=9)\n\n# onnxruntime\nimport onnxruntime\nsess = onnxruntime.InferenceSession('indexing.onnx')\nout_ort = sess.run(None, {\n    sess.get_inputs()[0].name: data.numpy(),\n    sess.get_inputs()[1].name: index.numpy(),\n})\n\nassert torch.all(torch.eq(out, torch.tensor(out_ort)))\n",
        "Question": "How to use This type of indexing occurs on the RHS. Export is supported for ONNX opset version >= 9. E.g.:, give an example?",
        "Id": 88,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " This type of indexing occurs on the RHS. Export is supported for ONNX opset version >= 9. E.g.:"
    },
    {
        "Answer": "# Scalar indices\ndata[0, 1]\n\n# Slice indices\ndata[:3]\n\n# Tensor indices\ndata[torch.tensor([[1, 2], [2, 3]])]\ndata[torch.tensor([2, 3]), torch.tensor([1, 2])]\ndata[torch.tensor([[1, 2], [2, 3]]), torch.tensor([2, 3])]\ndata[torch.tensor([2, 3]), :, torch.tensor([1, 2])]\n\n# Ellipsis followed by tensor indexing\n# Not supported in scripting\n# i.e. torch.jit.script(model) will fail if model contains this pattern.\n# Export is supported under tracing\n# i.e. torch.onnx.export(model)\ndata[..., torch.tensor([2, 1])]\n\n# The combination of above\ndata[2, ..., torch.tensor([2, 1, 3]), 2:4, torch.tensor([[1], [2]])]\n\n# Boolean mask (supported for ONNX opset version >= 11)\ndata[data != 1]\n",
        "Question": "How to use This type of indexing occurs on the RHS. Export is supported for ONNX opset version >= 9. E.g.:Below is the list of supported patterns for RHS indexing., give an example?",
        "Id": 89,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Below is the list of supported patterns for RHS indexing."
    },
    {
        "Answer": "# Tensor indices that includes negative values.\ndata[torch.tensor([[1, 2], [2, -3]]), torch.tensor([-2, 3])]\n",
        "Question": "How to use Below is the list of supported patterns for RHS indexing.And below is the list of unsupported patterns for RHS indexing., give an example?",
        "Id": 90,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Below is the list of supported patterns for RHS indexing.And below is the list of unsupported patterns for RHS indexing."
    },
    {
        "Answer": "data = torch.zeros(3, 4)\nnew_data = torch.arange(4).to(torch.float32)\n\n# LHS indexing is supported in ONNX opset >= 11.\nclass LHSIndexing(torch.nn.Module):\n    def forward(self, data, new_data):\n        data[1] = new_data\n        return data\n\nout = LHSIndexing()(data, new_data)\n\ndata = torch.zeros(3, 4)\nnew_data = torch.arange(4).to(torch.float32)\ntorch.onnx.export(LHSIndexing(), (data, new_data), 'inplace_assign.onnx', opset_version=11)\n\n# onnxruntime\nimport onnxruntime\nsess = onnxruntime.InferenceSession('inplace_assign.onnx')\nout_ort = sess.run(None, {\n    sess.get_inputs()[0].name: torch.zeros(3, 4).numpy(),\n    sess.get_inputs()[1].name: new_data.numpy(),\n})\n\nassert torch.all(torch.eq(out, torch.tensor(out_ort)))\n",
        "Question": "How to use In code, this type of indexing occurs on the LHS.\nExport is supported for ONNX opset version >= 11. E.g.:, give an example?",
        "Id": 91,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " In code, this type of indexing occurs on the LHS.\nExport is supported for ONNX opset version >= 11. E.g.:"
    },
    {
        "Answer": "# Scalar indices\ndata[0, 1] = new_data\n\n# Slice indices\ndata[:3] = new_data\n\n# Tensor indices\n# If more than one tensor are used as indices, only consecutive 1-d tensor indices are supported.\ndata[torch.tensor([[1, 2], [2, 3]])] = new_data\ndata[torch.tensor([2, 3]), torch.tensor([1, 2])] = new_data\n\n# Ellipsis followed by tensor indexing\n# Not supported to export in script modules\n# i.e. torch.onnx.export(torch.jit.script(model)) will fail if model contains this pattern.\n# Export is supported under tracing\n# i.e. torch.onnx.export(model)\ndata[..., torch.tensor([2, 1])] = new_data\n\n# The combination of above\ndata[2, ..., torch.tensor([2, 1, 3]), 2:4] += update\n\n# Boolean mask\ndata[data != 1] = new_data\n",
        "Question": "How to use In code, this type of indexing occurs on the LHS.\nExport is supported for ONNX opset version >= 11. E.g.:Below is the list of supported patterns for LHS indexing., give an example?",
        "Id": 92,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Below is the list of supported patterns for LHS indexing."
    },
    {
        "Answer": "# Multiple tensor indices if any has rank >= 2\ndata[torch.tensor([[1, 2], [2, 3]]), torch.tensor([2, 3])] = new_data\n\n# Multiple tensor indices that are not consecutive\ndata[torch.tensor([2, 3]), :, torch.tensor([1, 2])] = new_data\n\n# Tensor indices that includes negative values.\ndata[torch.tensor([1, -2]), torch.tensor([-2, 3])] = new_data\n",
        "Question": "How to use Below is the list of supported patterns for LHS indexing.And below is the list of unsupported patterns for LHS indexing., give an example?",
        "Id": 93,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Below is the list of supported patterns for LHS indexing.And below is the list of unsupported patterns for LHS indexing."
    },
    {
        "Answer": "def operator/symbolic(g, *inputs):\n  \"\"\"\n  Modifies Graph (e.g., using \"op\"), adding the ONNX operations representing\n  this PyTorch function, and returning a Value or tuple of Values specifying the\n  ONNX outputs whose values correspond to the original PyTorch return values\n  of the autograd Function (or None if an output is not supported by ONNX).\n\n  Args:\n    g (Graph): graph to write the ONNX representation into\n    inputs (Value...): list of values representing the variables which contain\n        the inputs for this function\n  \"\"\"\n\nclass Value(object):\n  \"\"\"Represents an intermediate tensor value computed in ONNX.\"\"\"\n  def type(self):\n    \"\"\"Returns the Type of the value.\"\"\"\n\nclass Type(object):\n  def sizes(self):\n    \"\"\"Returns a tuple of ints representing the shape of a tensor this describes.\"\"\"\n\nclass Graph(object):\n  def op(self, opname, *inputs, **attrs):\n    \"\"\"\n    Create an ONNX operator 'opname', taking 'args' as inputs\n    and attributes 'kwargs' and add it as a node to the current graph,\n    returning the value representing the single output of this\n    operator (see the `outputs` keyword argument for multi-return\n    nodes).\n\n    The set of operators and the inputs/attributes they take\n    is documented at https://github.com/onnx/onnx/blob/master/docs/Operators.md\n\n    Args:\n        opname (string): The ONNX operator name, e.g., `Abs` or `Add`.\n        args (Value...): The inputs to the operator; usually provided\n            as arguments to the `symbolic` definition.\n        kwargs: The attributes of the ONNX operator, with keys named\n            according to the following convention: `alpha_f` indicates\n            the `alpha` attribute with type `f`.  The valid type specifiers are\n            `f` (float), `i` (int), `s` (string) or `t` (Tensor).  An attribute\n            specified with type float accepts either a single float, or a\n            list of floats (e.g., you would say `dims_i` for a `dims` attribute\n            that takes a list of integers).\n        outputs (int, optional):  The number of outputs this operator returns;\n            by default an operator is assumed to return a single output.\n            If `outputs` is greater than one, this functions returns a tuple\n            of output `Value`, representing each output of the ONNX operator\n            in positional.\n    \"\"\"\n",
        "Question": "How to use If the operator is a non-ATen operator, the symbolic function has to be\nadded in the corresponding PyTorch Function class. Please read the following\ninstructions:Symbolic functions should be implemented in Python. All of these functions interact\nwith Python methods which are implemented via C++-Python bindings,\nbut intuitively the interface they provide looks like this:, give an example?",
        "Id": 94,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Symbolic functions should be implemented in Python. All of these functions interact\nwith Python methods which are implemented via C++-Python bindings,\nbut intuitively the interface they provide looks like this:"
    },
    {
        "Answer": "UserWarning: ONNX export failed on elu because torch.onnx.symbolic_opset9.elu does not exist\nRuntimeError: ONNX export failed: Couldn't export operator elu\n",
        "Question": "How to use The ONNX graph C++ definition is intorch/csrc/jit/ir/ir.h.Here is an example of handling missing symbolic function foreluoperator.\nWe try to export the model and see the error message as below:, give an example?",
        "Id": 95,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " The ONNX graph C++ definition is intorch/csrc/jit/ir/ir.h.Here is an example of handling missing symbolic function foreluoperator.\nWe try to export the model and see the error message as below:"
    },
    {
        "Answer": "def elu(g, input, alpha, inplace=False):\n    return g.op(\"Elu\", input, alpha_f=_scalar(alpha))\n",
        "Question": "How to use Here is an example of handling missing symbolic function foreluoperator.\nWe try to export the model and see the error message as below:The export fails because PyTorch does not support exportingeluoperator.\nWe findvirtualTensorelu(constTensor&input,Scalaralpha,boolinplace)constoverride;inVariableType.h. This meanseluis an ATen operator.\nWe check theONNX operator list,\nand confirm thatEluis standardized in ONNX.\nWe add the following lines tosymbolic_opset9.py:, give an example?",
        "Id": 96,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Here is an example of handling missing symbolic function foreluoperator.\nWe try to export the model and see the error message as below:The export fails because PyTorch does not support exportingeluoperator.\nWe findvirtualTensorelu(constTensor&input,Scalaralpha,boolinplace)constoverride;inVariableType.h. This meanseluis an ATen operator.\nWe check theONNX operator list,\nand confirm thatEluis standardized in ONNX.\nWe add the following lines tosymbolic_opset9.py:"
    },
    {
        "Answer": "# Create custom symbolic function\nfrom torch.onnx.symbolic_helper import parse_args\n@parse_args('v', 'v', 'f', 'i')\ndef symbolic_foo_forward(g, input1, input2, attr1, attr2):\n    return g.op(\"Foo\", input1, input2, attr1_f=attr1, attr2_i=attr2)\n\n# Register custom symbolic function\nfrom torch.onnx import register_custom_op_symbolic\nregister_custom_op_symbolic('custom_ops::foo_forward', symbolic_foo_forward, 9)\n\nclass FooModel(torch.nn.Module):\n    def __init__(self, attr1, attr2):\n        super(FooModule, self).__init__()\n        self.attr1 = attr1\n        self.attr2 = attr2\n\n    def forward(self, input1, input2):\n        # Calling custom op\n        return torch.ops.custom_ops.foo_forward(input1, input2, self.attr1, self.attr2)\n\nmodel = FooModel(attr1, attr2)\ntorch.onnx.export(model, (dummy_input1, dummy_input2), 'model.onnx', custom_opsets={\"custom_domain\": 2})\n",
        "Question": "How to use Following this tutorialExtending TorchScript with Custom C++ Operators,\nyou can create and register your own custom ops implementation in PyTorch. Here\u2019s how to export such model to ONNX.:, give an example?",
        "Id": 97,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Following this tutorialExtending TorchScript with Custom C++ Operators,\nyou can create and register your own custom ops implementation in PyTorch. Here\u2019s how to export such model to ONNX.:"
    },
    {
        "Answer": "Example torch ir graph:\n\n  graph(%0 : Float(2, 3, 4, strides=[12, 4, 1])):\n    %3 : Float(2, 3, 4, strides=[12, 4, 1]) = aten:exp(%0)\n    %4 : Float(2, 3, 4, strides=[12, 4, 1]) = aten:div(%0, %3)\n    return (%4)\n\nIs exported as:\n\n  graph(%0 : Float(2, 3, 4, strides=[12, 4, 1])):\n    %1 : Float(2, 3, 4, strides=[12, 4, 1]) = onnx:Exp(%0)\n    %2 : Float(2, 3, 4, strides=[12, 4, 1]) = onnx:Div(%0, %1)\n    return (%2)\n",
        "Question": "How to use This mode is used to export all operators as regular ONNX operators. This is the defaultoperator_export_typemode., give an example?",
        "Id": 98,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " This mode is used to export all operators as regular ONNX operators. This is the defaultoperator_export_typemode."
    },
    {
        "Answer": "Example torch ir graph:\n\n  graph(%0 : Float(2, 3, 4, strides=[12, 4, 1])):\n    %3 : Float(2, 3, 4, strides=[12, 4, 1]) = aten::exp(%0)\n    %4 : Float(2, 3, 4, strides=[12, 4, 1]) = aten::div(%0, %3)\n    return (%4)\n\nIs exported as:\n\n  graph(%0 : Float(2, 3, 4, strides=[12, 4, 1])):\n    %1 : Float(2, 3, 4, strides=[12, 4, 1]) = aten::ATen[operator=\"exp\"](%0)\n    %2 : Float(2, 3, 4, strides=[12, 4, 1]) = aten::ATen[operator=\"div\"](%0, %1)\n    return (%2)\n",
        "Question": "How to use This mode is used to export all operators as ATen ops, and avoid conversion to ONNX., give an example?",
        "Id": 99,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " This mode is used to export all operators as ATen ops, and avoid conversion to ONNX."
    },
    {
        "Answer": "Example torch ir graph:\n\n  graph(%0 : Float):\n    %3 : int = prim::Constant[value=0]()\n    %4 : Float = aten::triu(%0, %3) # unsupported op\n    %5 : Float = aten::mul(%4, %0) # registered op\n    return (%5)\n\nis exported as:\n\n  graph(%0 : Float):\n    %1 : Long() = onnx::Constant[value={0}]()\n    %2 : Float = aten::ATen[operator=\"triu\"](%0, %1) # unsupported op\n    %3 : Float = onnx::Mul(%2, %0) # registered op\n    return (%3)\n",
        "Question": "How to use To fallback on unsupported ATen operators in ONNX. Supported operators are exported to ONNX regularly.\nIn the following example, aten::triu is not supported in ONNX. Exporter falls back on this operator., give an example?",
        "Id": 100,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " To fallback on unsupported ATen operators in ONNX. Supported operators are exported to ONNX regularly.\nIn the following example, aten::triu is not supported in ONNX. Exporter falls back on this operator."
    },
    {
        "Answer": "Example torch ir graph:\n\n  graph(%x.1 : Float(1, strides=[1])):\n    %1 : Tensor = aten::exp(%x.1)\n    %2 : Tensor = aten::div(%x.1, %1)\n    %y.1 : Tensor[] = prim::ListConstruct(%2)\n    return (%y.1)\n\nis exported as:\n\n  graph(%x.1 : Float(1, strides=[1])):\n    %1 : Tensor = aten::exp(%x.1)\n    %2 : Tensor = aten::div(%x.1, %1)\n    %y.1 : Tensor[] = prim::ListConstruct(%2)\n    return (%y.1)\n",
        "Question": "How to use To export a raw ir., give an example?",
        "Id": 101,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " To export a raw ir."
    },
    {
        "Answer": "Example torch ir graph:\n\n  graph(%0 : Float(2, 3, 4, strides=[12, 4, 1]),\n        %1 : Float(2, 3, 4, strides=[12, 4, 1])):\n    %6 : Float(2, 3, 4, strides=[12, 4, 1]) = foo_namespace::bar(%0, %1) # custom op\n    %7 : Float(2, 3, 4, strides=[12, 4, 1]) = aten::div(%6, %0) # registered op\n    return (%7))\n\nis exported as:\n\n  graph(%0 : Float(2, 3, 4, strides=[12, 4, 1]),\n        %1 : Float(2, 3, 4, strides=[12, 4, 1])):\n    %2 : Float(2, 3, 4, strides=[12, 4, 1]) = foo_namespace::bar(%0, %1) # custom op\n    %3 : Float(2, 3, 4, strides=[12, 4, 1]) = onnx::Div(%2, %0) # registered op\n    return (%3\n",
        "Question": "How to use This mode can be used to export any operator (ATen or non-ATen) that is not registered and supported in ONNX.\nExported falls through and exports the operator as is, as custom op. Exporting custom operators\nenables users to register and implement the operator as part of their runtime backend., give an example?",
        "Id": 102,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " This mode can be used to export any operator (ATen or non-ATen) that is not registered and supported in ONNX.\nExported falls through and exports the operator as is, as custom op. Exporting custom operators\nenables users to register and implement the operator as part of their runtime backend."
    },
    {
        "Answer": "layer_count = 4\n\nmodel = nn.LSTM(10, 20, num_layers=layer_count, bidirectional=True)\nmodel.eval()\n\nwith torch.no_grad():\n    input = torch.randn(5, 3, 10)\n    h0 = torch.randn(layer_count * 2, 3, 20)\n    c0 = torch.randn(layer_count * 2, 3, 20)\n    output, (hn, cn) = model(input, (h0, c0))\n\n    # default export\n    torch.onnx.export(model, (input, (h0, c0)), 'lstm.onnx')\n    onnx_model = onnx.load('lstm.onnx')\n    # input shape [5, 3, 10]\n    print(onnx_model.graph.input[0])\n\n    # export with `dynamic_axes`\n    torch.onnx.export(model, (input, (h0, c0)), 'lstm.onnx',\n                    input_names=['input', 'h0', 'c0'],\n                    output_names=['output', 'hn', 'cn'],\n                    dynamic_axes={'input': {0: 'sequence'}, 'output': {0: 'sequence'}})\n    onnx_model = onnx.load('lstm.onnx')\n    # input shape ['sequence', 3, 10]\n    print(onnx_model.graph.input[0])\n",
        "Question": "How to use The tracer records the example inputs shape in the graph. In case the model should accept\ninputs of dynamic shape, you can utilize the parameterdynamic_axesin export api., give an example?",
        "Id": 103,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " The tracer records the example inputs shape in the graph. In case the model should accept\ninputs of dynamic shape, you can utilize the parameterdynamic_axesin export api."
    },
    {
        "Answer": "class ImplicitCastType(torch.jit.ScriptModule):\n    @torch.jit.script_method\n    def forward(self, x):\n        # Exporter knows x is float32, will export '2' as float32 as well.\n        y = x + 2\n        # Without type propagation, exporter doesn't know the datatype of y.\n        # Thus '3' is exported as int64 by default.\n        return y + 3\n        # The following will export correctly.\n        # return y + torch.tensor([3], dtype=torch.float32)\n\nx = torch.tensor([1.0], dtype=torch.float32)\ntorch.onnx.export(ImplicitCastType(), x, 'models/implicit_cast.onnx',\n                  example_outputs=ImplicitCastType()(x))\n",
        "Question": "How to use No, but the exporter will try to handle that part.  Scalars are converted to constant tensors in ONNX.\nThe exporter will try to figure out the right datatype for scalars.  However for cases that it failed\nto do so, you will need to manually provide the datatype information.  This often happens with scripted models,\nwhere the datatypes are not recorded.  We are trying to improve the datatype\npropagation in the exporter such that manual changes are not required in the future., give an example?",
        "Id": 104,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " No, but the exporter will try to handle that part.  Scalars are converted to constant tensors in ONNX.\nThe exporter will try to figure out the right datatype for scalars.  However for cases that it failed\nto do so, you will need to manually provide the datatype information.  This often happens with scripted models,\nwhere the datatypes are not recorded.  We are trying to improve the datatype\npropagation in the exporter such that manual changes are not required in the future."
    },
    {
        "Answer": "class ListLoopModel(torch.nn.Module):\n    def forward(self, x):\n        res = []\n        res1 = []\n        arr = x.split(2, 0)\n        res2 = torch.zeros(3, 4, dtype=torch.long)\n        for i in range(len(arr)):\n            res += [arr[i].sum(0, False)]\n            res1 += [arr[-1 - i].sum(0, False)]\n            res2 += 1\n        return torch.stack(res), torch.stack(res1), res2\n\nmodel = torch.jit.script(ListLoopModel())\ninputs = torch.randn(16)\n\nout = model(inputs)\ntorch.onnx.export(model, (inputs, ), 'loop_and_list.onnx', opset_version=11, example_outputs=out)\n\n# onnxruntime\nimport onnxruntime\nsess = onnxruntime.InferenceSession('loop_and_list.onnx')\nout_ort = sess.run(None, {\n    sess.get_inputs()[0].name: inputs.numpy(),\n})\n\nassert [torch.allclose(o, torch.tensor(o_ort)) for o, o_ort in zip(out, out_ort)]\n",
        "Question": "How to use Yes, this is supported now for ONNX opset version >= 11. ONNX introduced the concept of Sequence in opset 11.\nSimilar to list, Sequence is a data type that contains arbitrary number of Tensors.\nAssociated operators are also introduced in ONNX, such as SequenceInsert, SequenceAt, etc.\nHowever, in-place list append within loops is not exportable to ONNX. To implement this, please use inplace\nadd operator.\nE.g.:, give an example?",
        "Id": 105,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " Yes, this is supported now for ONNX opset version >= 11. ONNX introduced the concept of Sequence in opset 11.\nSimilar to list, Sequence is a data type that contains arbitrary number of Tensors.\nAssociated operators are also introduced in ONNX, such as SequenceInsert, SequenceAt, etc.\nHowever, in-place list append within loops is not exportable to ONNX. To implement this, please use inplace\nadd operator.\nE.g.:"
    },
    {
        "Answer": "model = torchvision.models.mobilenet_v2(pretrained=True)\ninput = torch.randn(2, 3, 224, 224, requires_grad=True)\ntorch.onnx.export(model, (input, ), './large_model.onnx', use_external_data_format=True)\n",
        "Question": "How to use use_external_data_formatargument in export API enables export of models in ONNX external\ndata format. With this option enabled, the exporter stores some model parameters in external\nbinary files, rather than the ONNX file itself. These external binary files are stored in the\nsame location as the ONNX file. Argument \u2018f\u2019 must be a string specifying the location of the model., give an example?",
        "Id": 106,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " use_external_data_formatargument in export API enables export of models in ONNX external\ndata format. With this option enabled, the exporter stores some model parameters in external\nbinary files, rather than the ONNX file itself. These external binary files are stored in the\nsame location as the ONNX file. Argument \u2018f\u2019 must be a string specifying the location of the model."
    },
    {
        "Answer": "\"args = (x, y, z)\"\n",
        "Question": "How to use torch.onnx.export, give an example?",
        "Id": 107,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " ONLY A TUPLE OF ARGUMENTS or torch.Tensor:"
    },
    {
        "Answer": "\"args = (x,\n        {\n        'y': input_y,\n        'z': input_z\n        })\"\n",
        "Question": "How  A TUPLE OF ARGUEMENTS WITH A DICTIONARY OF NAMED PARAMETERS:, give an example?",
        "Id": 108,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " A TUPLE OF ARGUEMENTS WITH A DICTIONARY OF NAMED PARAMETERS:"
    },
    {
        "Answer": "graph(%0 : Float)::\n  %3 : int = prim::Constant[value=0]()\n  %4 : Float = aten::triu(%0, %3) # missing op\n  %5 : Float = aten::mul(%4, %0) # registered op\n  return (%5)\n",
        "Question": "How  , give an example?",
        "Id": 109,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " "
    },
    {
        "Answer": "graph(%0 : Float)::\n  %1 : Long() = onnx::Constant[value={0}]()\n  %2 : Float = aten::ATen[operator=\"triu\"](%0, %1)  # missing op\n  %3 : Float = onnx::Mul(%2, %0) # registered op\n  return (%3)\n",
        "Question": "How  is exported as:, give an example?",
        "Id": 110,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " is exported as:"
    },
    {
        "Answer": "graph(%x.1 : Long(1, strides=[1]))::\n  %1 : None = prim::Constant()\n  %2 : Tensor = aten::sum(%x.1, %1)\n  %y.1 : Tensor[] = prim::ListConstruct(%2)\n  return (%y.1)\n",
        "Question": "How  is exported as:, give an example?",
        "Id": 111,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " is exported as:"
    },
    {
        "Answer": "graph(%x.1 : Long(1, strides=[1]))::\n  %1 : Tensor = onnx::ReduceSum[keepdims=0](%x.1)\n  %y.1 : Long() = prim::ListConstruct(%1)\n  return (%y.1)\n",
        "Question": "How  is exported as:, give an example?",
        "Id": 112,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " is exported as:"
    },
    {
        "Answer": "shape(input_1) = ('b', 3, 'w', 'h')\nand shape(input_2) = ('b', 4)\nand shape(output)  = ('b', 'd', 5)\n",
        "Question": "How to use Functions, give an example?",
        "Id": 113,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " "
    },
    {
        "Answer": "``dynamic_axes = {'input_1':[0, 2, 3],\n                  'input_2':[0],\n                  'output':[0, 1]}``\nwhere automatic names will be generated for exported dynamic axes\n",
        "Question": "How  ONLY INDICES:, give an example?",
        "Id": 114,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " ONLY INDICES:"
    },
    {
        "Answer": "``dynamic_axes = {'input_1':{0:'batch',\n                             1:'width',\n                             2:'height'},\n                  'input_2':{0:'batch'},\n                  'output':{0:'batch',\n                            1:'detections'}}``\nwhere provided names will be applied to exported dynamic axes\n",
        "Question": "How  INDICES WITH CORRESPONDING NAMES:, give an example?",
        "Id": 115,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " INDICES WITH CORRESPONDING NAMES:"
    },
    {
        "Answer": "``dynamic_axes = {'input_1':[0, 2, 3],\n                  'input_2':{0:'batch'},\n                  'output':[0,1]}``\n",
        "Question": "How  MIXED MODE OF (1) and (2):, give an example?",
        "Id": 116,
        "source": "https://pytorch.org/docs/stable/onnx.html",
        "context": " MIXED MODE OF (1) and (2):"
    },
    {
        "Answer": ">>> a = torch.tril_indices(3, 3)\n>>> a\ntensor([[0, 1, 1, 2, 2, 2],\n        [0, 0, 1, 0, 1, 2]])\n\n>>> a = torch.tril_indices(4, 3, -1)\n>>> a\ntensor([[1, 2, 2, 3, 3, 3],\n        [0, 0, 1, 0, 1, 2]])\n\n>>> a = torch.tril_indices(4, 3, 1)\n>>> a\ntensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3],\n        [0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
        "Question": "How to use torch.tril_indices, give an example?",
        "Id": 117,
        "source": "https://pytorch.org/docs/stable/generated/torch.tril_indices.html#torch.tril_indices",
        "context": " The argumentoffsetcontrols which diagonal to consider. Ifoffset= 0, all elements on and below the main diagonal are\nretained. A positive value includes just as many diagonals above the main\ndiagonal, and similarly a negative value excludes just as many diagonals below\nthe main diagonal. The main diagonal are the set of indices{(i,i)}\\lbrace (i, i) \\rbrace{(i,i)}fori\u2208[0,min\u2061{d1,d2}\u22121]i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]i\u2208[0,min{d1\u200b,d2\u200b}\u22121]whered1,d2d_{1}, d_{2}d1\u200b,d2\u200bare the dimensions of the matrix."
    },
    {
        "Answer": ">>> a = torch.tensor((1, 2))\n>>> b = torch.tensor((0, 1))\n>>> torch.sub(a, b, alpha=2)\ntensor([1, 0])\n",
        "Question": "How to use torch.sub, give an example?",
        "Id": 118,
        "source": "https://pytorch.org/docs/stable/generated/torch.sub.html#torch.sub",
        "context": " Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs."
    },
    {
        "Answer": "# Creates model and optimizer in default precision\nmodel = Net().cuda()\noptimizer = optim.SGD(model.parameters(), ...)\n\nfor input, target in data:\n    optimizer.zero_grad()\n\n    # Enables autocasting for the forward pass (model + loss)\n    with autocast():\n        output = model(input)\n        loss = loss_fn(output, target)\n\n    # Exits the context manager before backward()\n    loss.backward()\n    optimizer.step()\n",
        "Question": "How to use torch.cuda.amp.autocast, give an example?",
        "Id": 119,
        "source": "https://pytorch.org/docs/stable/amp.html",
        "context": " autocastshould wrap only the forward pass(es) of your network, including the loss\ncomputation(s).  Backward passes under autocast are not recommended.\nBackward ops run in the same type that autocast used for corresponding forward ops."
    },
    {
        "Answer": "class AutocastModel(nn.Module):\n    ...\n    @autocast()\n    def forward(self, input):\n        ...\n",
        "Question": "How to use autocastcan also be used as a decorator, e.g., on theforwardmethod of your model:, give an example?",
        "Id": 120,
        "source": "https://pytorch.org/docs/stable/amp.html",
        "context": " See theAutomatic Mixed Precision examplesfor usage (along with gradient scaling)\nin more complex scenarios (e.g., gradient penalty, multiple models/losses, custom autograd functions).autocastcan also be used as a decorator, e.g., on theforwardmethod of your model:"
    },
    {
        "Answer": "# Creates some tensors in default dtype (here assumed to be float32)\na_float32 = torch.rand((8, 8), device=\"cuda\")\nb_float32 = torch.rand((8, 8), device=\"cuda\")\nc_float32 = torch.rand((8, 8), device=\"cuda\")\nd_float32 = torch.rand((8, 8), device=\"cuda\")\n\nwith autocast():\n    # torch.mm is on autocast's list of ops that should run in float16.\n    # Inputs are float32, but the op runs in float16 and produces float16 output.\n    # No manual casts are required.\n    e_float16 = torch.mm(a_float32, b_float32)\n    # Also handles mixed input types\n    f_float16 = torch.mm(d_float32, e_float16)\n\n# After exiting autocast, calls f_float16.float() to use with d_float32\ng_float32 = torch.mm(d_float32, f_float16.float())\n",
        "Question": "How to use Floating-point Tensors produced in an autocast-enabled region may befloat16.\nAfter returning to an autocast-disabled region, using them with floating-point\nTensors of different dtypes may cause type mismatch errors.  If so, cast the Tensor(s)\nproduced in the autocast region back tofloat32(or other dtype if desired).\nIf a Tensor from the autocast region is alreadyfloat32, the cast is a no-op,\nand incurs no additional overhead.  Example:, give an example?",
        "Id": 121,
        "source": "https://pytorch.org/docs/stable/amp.html",
        "context": " autocastcan also be used as a decorator, e.g., on theforwardmethod of your model:"
    },
    {
        "Answer": "# Creates some tensors in default dtype (here assumed to be float32)\na_float32 = torch.rand((8, 8), device=\"cuda\")\nb_float32 = torch.rand((8, 8), device=\"cuda\")\nc_float32 = torch.rand((8, 8), device=\"cuda\")\nd_float32 = torch.rand((8, 8), device=\"cuda\")\n\nwith autocast():\n    e_float16 = torch.mm(a_float32, b_float32)\n\n    with autocast(enabled=False):\n        # Calls e_float16.float() to ensure float32 execution\n        # (necessary because e_float16 was created in an autocasted region)\n        f_float32 = torch.mm(c_float32, e_float16.float())\n\n    # No manual casts are required when re-entering the autocast-enabled region.\n    # torch.mm again runs in float16 and produces float16 output, regardless of input types.\n    g_float16 = torch.mm(d_float32, f_float32)\n",
        "Question": "How to use autocast(enabled=False)subregions can be nested in autocast-enabled regions.\nLocally disabling autocast can be useful, for example, if you want to force a subregion\nto run in a particulardtype.  Disabling autocast gives you explicit control over\nthe execution type.  In the subregion, inputs from the surrounding region\nshould be cast todtypebefore use:, give an example?",
        "Id": 122,
        "source": "https://pytorch.org/docs/stable/amp.html",
        "context": " Type mismatch errorsinan autocast-enabled region are a bug; if this is what you observe,\nplease file an issue.autocast(enabled=False)subregions can be nested in autocast-enabled regions.\nLocally disabling autocast can be useful, for example, if you want to force a subregion\nto run in a particulardtype.  Disabling autocast gives you explicit control over\nthe execution type.  In the subregion, inputs from the surrounding region\nshould be cast todtypebefore use:"
    },
    {
        "Answer": "...\nscaler.scale(loss).backward()\nscaler.unscale_(optimizer)\ntorch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\nscaler.step(optimizer)\nscaler.update()\n",
        "Question": "How to use torch.cuda.amp.GradScaler.unscale_, give an example?",
        "Id": 123,
        "source": "https://pytorch.org/docs/stable/amp.html",
        "context": " unscale_()is optional, serving cases where you need tomodify or inspect gradientsbetween the backward pass(es) andstep().\nIfunscale_()is not called explicitly,  gradients will be unscaled  automatically duringstep().Simple example, usingunscale_()to enable clipping of unscaled gradients:"
    },
    {
        "Answer": ">>> A = torch.randn(3, 3)\n>>> torch.det(A)\ntensor(0.2611)\n>>> torch.logdet(A)\ntensor(-1.3430)\n>>> A\ntensor([[[ 0.9254, -0.6213],\n         [-0.5787,  1.6843]],\n\n        [[ 0.3242, -0.9665],\n         [ 0.4539, -0.0887]],\n\n        [[ 1.1336, -0.4025],\n         [-0.7089,  0.9032]]])\n>>> A.det()\ntensor([1.1990, 0.4099, 0.7386])\n>>> A.det().log()\ntensor([ 0.1815, -0.8917, -0.3031])\n",
        "Question": "How to use torch.logdet, give an example?",
        "Id": 124,
        "source": "https://pytorch.org/docs/stable/generated/torch.logdet.html#torch.logdet",
        "context": " "
    },
    {
        "Answer": ">>> torch.lt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[False, False], [True, False]])\n",
        "Question": "How to use torch.lt, give an example?",
        "Id": 125,
        "source": "https://pytorch.org/docs/stable/generated/torch.lt.html#torch.lt",
        "context": " The second argument can be a number or a tensor whose shape isbroadcastablewith the first argument."
    },
    {
        "Answer": ">>> torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8)\ntensor([-1.,  0.,  1.,  2.], size=(4,), dtype=torch.quint8,\n       quantization_scheme=torch.per_tensor_affine, scale=0.1, zero_point=10)\n>>> torch.quantize_per_tensor(torch.tensor([-1.0, 0.0, 1.0, 2.0]), 0.1, 10, torch.quint8).int_repr()\ntensor([ 0, 10, 20, 30], dtype=torch.uint8)\n",
        "Question": "How to use torch.quantize_per_tensor, give an example?",
        "Id": 126,
        "source": "https://pytorch.org/docs/stable/generated/torch.quantize_per_tensor.html#torch.quantize_per_tensor",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-2.0755,  1.0226,  0.0831,  0.4806])\n>>> torch.square(a)\ntensor([ 4.3077,  1.0457,  0.0069,  0.2310])\n",
        "Question": "How to use torch.square, give an example?",
        "Id": 127,
        "source": "https://pytorch.org/docs/stable/generated/torch.square.html#torch.square",
        "context": " "
    },
    {
        "Answer": ">>> src = torch.tensor([[4, 3, 5],\n...                     [6, 7, 8]])\n>>> torch.take(src, torch.tensor([0, 2, 5]))\ntensor([ 4,  5,  8])\n",
        "Question": "How to use torch.take, give an example?",
        "Id": 128,
        "source": "https://pytorch.org/docs/stable/generated/torch.take.html#torch.take",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 129,
        "source": "https://pytorch.org/docs/stable/torch.html#torch.torch.default_generator",
        "context": " "
    },
    {
        "Answer": ">>> torch.normal(mean=torch.arange(1., 11.), std=torch.arange(1, 0, -0.1))\ntensor([  1.0425,   3.5672,   2.7969,   4.2925,   4.7229,   6.2134,\n          8.0505,   8.1408,   9.0563,  10.0566])\n",
        "Question": "How to use torch.normal, give an example?",
        "Id": 130,
        "source": "https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal",
        "context": " The shapes ofmeanandstddon\u2019t need to match, but the\ntotal number of elements in each tensor need to be the same."
    },
    {
        "Answer": ">>> torch.normal(mean=0.5, std=torch.arange(1., 6.))\ntensor([-1.2793, -1.0732, -2.0687,  5.1177, -1.2303])\n",
        "Question": "How  Similar to the function above, but the means are shared among all drawn\nelements., give an example?",
        "Id": 131,
        "source": "https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal",
        "context": " Similar to the function above, but the means are shared among all drawn\nelements."
    },
    {
        "Answer": ">>> torch.normal(mean=torch.arange(1., 6.))\ntensor([ 1.1552,  2.6148,  2.6535,  5.8318,  4.2361])\n",
        "Question": "How  Similar to the function above, but the standard deviations are shared among\nall drawn elements., give an example?",
        "Id": 132,
        "source": "https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal",
        "context": " Similar to the function above, but the standard deviations are shared among\nall drawn elements."
    },
    {
        "Answer": ">>> torch.normal(2, 3, size=(1, 4))\ntensor([[-1.3987, -1.9544,  3.6048,  0.7909]])\n",
        "Question": "How  Similar to the function above, but the means and standard deviations are shared\namong all drawn elements. The resulting tensor has size given bysize., give an example?",
        "Id": 133,
        "source": "https://pytorch.org/docs/stable/generated/torch.normal.html#torch.normal",
        "context": " Similar to the function above, but the means and standard deviations are shared\namong all drawn elements. The resulting tensor has size given bysize."
    },
    {
        "Answer": ">>> a = torch.tensor([[-0.8166, -1.3802, -0.3560]])\n>>> torch.std_mean(a, unbiased=False)\n(tensor(0.4188), tensor(-0.8509))\n",
        "Question": "How to use torch.std_mean, give an example?",
        "Id": 134,
        "source": "https://pytorch.org/docs/stable/generated/torch.std_mean.html#torch.std_mean",
        "context": " IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction."
    },
    {
        "Answer": ">>> x = torch.tensor([[[0,1],[2,3]],[[4,5],[6,7]]])\n>>> x\ntensor([[[0, 1],\n        [2, 3]],\n\n        [[4, 5],\n        [6, 7]]])\n>>> torch.swapdims(x, 0, 1)\ntensor([[[0, 1],\n        [4, 5]],\n\n        [[2, 3],\n        [6, 7]]])\n>>> torch.swapdims(x, 0, 2)\ntensor([[[0, 4],\n        [2, 6]],\n\n        [[1, 5],\n        [3, 7]]])\n",
        "Question": "How to use torch.swapdims, give an example?",
        "Id": 135,
        "source": "https://pytorch.org/docs/stable/generated/torch.swapdims.html#torch.swapdims",
        "context": " This function is equivalent to NumPy\u2019s swapaxes function."
    },
    {
        "Answer": ">>> a = torch.tensor([1, 2, 3])\n>>> b = torch.tensor([4, 5, 6])\n>>> torch.dstack((a,b))\ntensor([[[1, 4],\n         [2, 5],\n         [3, 6]]])\n>>> a = torch.tensor([[1],[2],[3]])\n>>> b = torch.tensor([[4],[5],[6]])\n>>> torch.dstack((a,b))\ntensor([[[1, 4]],\n        [[2, 5]],\n        [[3, 6]]])\n",
        "Question": "How to use torch.dstack, give an example?",
        "Id": 136,
        "source": "https://pytorch.org/docs/stable/generated/torch.dstack.html#torch.dstack",
        "context": " This is equivalent to concatenation along the third axis after 1-D and 2-D tensors have been reshaped bytorch.atleast_3d()."
    },
    {
        "Answer": ">>> a = torch.arange(-0.5, 1, 0.5)\n>>> a\ntensor([-0.5000,  0.0000,  0.5000])\n>>> torch.special.entr(a)\ntensor([  -inf, 0.0000, 0.3466])\n",
        "Question": "How to use torch.special.entr, give an example?",
        "Id": 137,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erf(torch.tensor([0, -1., 10.]))\ntensor([ 0.0000, -0.8427,  1.0000])\n",
        "Question": "How to use torch.special.erf, give an example?",
        "Id": 138,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n",
        "Question": "How to use torch.special.erfc, give an example?",
        "Id": 139,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n",
        "Question": "How to use torch.special.erfinv, give an example?",
        "Id": 140,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(4)\n>>> t\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n>>> torch.special.expit(t)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
        "Question": "How to use torch.special.expit, give an example?",
        "Id": 141,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n",
        "Question": "How to use torch.special.expm1, give an example?",
        "Id": 142,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\ntensor([ 1.,  2.,  8., 16.])\n",
        "Question": "How to use torch.special.exp2, give an example?",
        "Id": 143,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.special.gammaln(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How to use torch.special.gammaln, give an example?",
        "Id": 144,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.i0e(torch.arange(5, dtype=torch.float32))\ntensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])\n",
        "Question": "How to use torch.special.i0e, give an example?",
        "Id": 145,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n>>> torch.special.logit(a, eps=1e-6)\ntensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
        "Question": "How to use torch.special.logit, give an example?",
        "Id": 146,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.special.xlog1py(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.special.xlog1py(x, y)\ntensor([1.3863, 2.1972, 2.0794])\n>>> torch.special.xlog1py(x, 4)\ntensor([1.6094, 3.2189, 4.8283])\n>>> torch.special.xlog1py(2, y)\ntensor([2.7726, 2.1972, 1.3863])\n",
        "Question": "How to use torch.special.xlog1py, give an example?",
        "Id": 147,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfinv",
        "context": " Similar to SciPy\u2019sscipy.special.xlog1py."
    },
    {
        "Answer": ">>> a = torch.tensor([-float('inf'), float('inf'), 1.2])\n>>> torch.isneginf(a)\ntensor([ True, False, False])\n",
        "Question": "How to use torch.isneginf, give an example?",
        "Id": 148,
        "source": "https://pytorch.org/docs/stable/generated/torch.isneginf.html#torch.isneginf",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(60.).reshape(3, 4, 5)\n>>> b = torch.arange(24.).reshape(4, 3, 2)\n>>> torch.tensordot(a, b, dims=([1, 0], [0, 1]))\ntensor([[4400., 4730.],\n        [4532., 4874.],\n        [4664., 5018.],\n        [4796., 5162.],\n        [4928., 5306.]])\n\n>>> a = torch.randn(3, 4, 5, device='cuda')\n>>> b = torch.randn(4, 5, 6, device='cuda')\n>>> c = torch.tensordot(a, b, dims=2).cpu()\ntensor([[ 8.3504, -2.5436,  6.2922,  2.7556, -1.0732,  3.2741],\n        [ 3.3161,  0.0704,  5.0187, -0.4079, -4.3126,  4.8744],\n        [ 0.8223,  3.9445,  3.2168, -0.2400,  3.4117,  1.7780]])\n\n>>> a = torch.randn(3, 5, 4, 6)\n>>> b = torch.randn(6, 4, 5, 3)\n>>> torch.tensordot(a, b, dims=([2, 1, 3], [1, 2, 0]))\ntensor([[  7.7193,  -2.4867, -10.3204],\n        [  1.5513, -14.4737,  -6.5113],\n        [ -0.2850,   4.2573,  -3.5997]])\n",
        "Question": "How to use torch.tensordot, give an example?",
        "Id": 149,
        "source": "https://pytorch.org/docs/stable/generated/torch.tensordot.html#torch.tensordot",
        "context": " When called withdimsof the list form, the given dimensions will be contracted\nin place of the lastdddofaand the firstdddofbbb. The sizes\nin these dimensions must match, buttensordot()will deal with broadcasted\ndimensions."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-1.7120,  0.1734, -0.0478, -0.0922])\n>>> torch.clamp(a, min=-0.5, max=0.5)\ntensor([-0.5000,  0.1734, -0.0478, -0.0922])\n\n>>> min = torch.linspace(-1, 1, steps=4)\n>>> torch.clamp(a, min=min)\ntensor([-1.0000,  0.1734,  0.3333,  1.0000])\n",
        "Question": "How to use torch.clamp, give an example?",
        "Id": 150,
        "source": "https://pytorch.org/docs/stable/generated/torch.clamp.html#torch.clamp",
        "context": " IfminisNone, there is no lower bound.\nOr, ifmaxisNonethere is no upper bound."
    },
    {
        "Answer": ">>> x = torch.ones(3, 3)\n>>> x[1].fill_(2)\ntensor([ 2.,  2.,  2.])\n>>> x[2].fill_(3)\ntensor([ 3.,  3.,  3.])\n>>> x\ntensor([[ 1.,  1.,  1.],\n        [ 2.,  2.,  2.],\n        [ 3.,  3.,  3.]])\n>>> torch.renorm(x, 1, 0, 5)\ntensor([[ 1.0000,  1.0000,  1.0000],\n        [ 1.6667,  1.6667,  1.6667],\n        [ 1.6667,  1.6667,  1.6667]])\n",
        "Question": "How to use torch.renorm, give an example?",
        "Id": 151,
        "source": "https://pytorch.org/docs/stable/generated/torch.renorm.html#torch.renorm",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(10)\n>>> torch.logcumsumexp(a, dim=0)\ntensor([-0.42296738, -0.04462666,  0.86278635,  0.94622083,  1.05277811,\n         1.39202815,  1.83525007,  1.84492621,  2.06084887,  2.06844475]))\n",
        "Question": "How to use torch.logcumsumexp, give an example?",
        "Id": 152,
        "source": "https://pytorch.org/docs/stable/generated/torch.logcumsumexp.html#torch.logcumsumexp",
        "context": " For summation indexjjjgiven bydimand other indicesiii, the result is"
    },
    {
        "Answer": ">>> x = torch.randn(2, 3)\n>>> x\ntensor([[ 0.6580, -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497]])\n>>> torch.cat((x, x, x), 0)\ntensor([[ 0.6580, -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497],\n        [ 0.6580, -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497],\n        [ 0.6580, -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497]])\n>>> torch.cat((x, x, x), 1)\ntensor([[ 0.6580, -1.0969, -0.4614,  0.6580, -1.0969, -0.4614,  0.6580,\n         -1.0969, -0.4614],\n        [-0.1034, -0.5790,  0.1497, -0.1034, -0.5790,  0.1497, -0.1034,\n         -0.5790,  0.1497]])\n",
        "Question": "How to use torch.cat, give an example?",
        "Id": 153,
        "source": "https://pytorch.org/docs/stable/generated/torch.cat.html#torch.cat",
        "context": " torch.cat()can be best understood via examples."
    },
    {
        "Answer": ">>> a = torch.tensor([[0.9041,  0.0196], [-0.3108, -2.4423], [-0.4821,  1.059]])\n>>> a\ntensor([[ 0.9041,  0.0196],\n        [-0.3108, -2.4423],\n        [-0.4821,  1.0590]])\n>>> b = torch.tensor([[-2.1763, -0.4713], [-0.6986,  1.3702]])\n>>> b\ntensor([[-2.1763, -0.4713],\n        [-0.6986,  1.3702]])\n>>> torch.cdist(a, b, p=2)\ntensor([[3.1193, 2.0959],\n        [2.7138, 3.8322],\n        [2.2830, 0.3791]])\n",
        "Question": "How to use torch.cdist, give an example?",
        "Id": 154,
        "source": "https://pytorch.org/docs/stable/generated/torch.cdist.html#torch.cdist",
        "context": " This function is equivalent toscipy.spatial.distance.cdist(input,\u2019minkowski\u2019, p=p)ifp\u2208(0,\u221e)p \\in (0, \\infty)p\u2208(0,\u221e). Whenp=0p = 0p=0it is equivalent toscipy.spatial.distance.cdist(input, \u2018hamming\u2019) * M. Whenp=\u221ep = \\inftyp=\u221e, the closest\nscipy function isscipy.spatial.distance.cdist(xn, lambda x, y: np.abs(x - y).max())."
    },
    {
        "Answer": ">>> x = torch.randn(3, 4)\n>>> x\ntensor([[ 0.1427,  0.0231, -0.5414, -1.0009],\n        [-0.4664,  0.2647, -0.1228, -1.1068],\n        [-1.1734, -0.6571,  0.7230, -0.6004]])\n>>> indices = torch.tensor([0, 2])\n>>> torch.index_select(x, 0, indices)\ntensor([[ 0.1427,  0.0231, -0.5414, -1.0009],\n        [-1.1734, -0.6571,  0.7230, -0.6004]])\n>>> torch.index_select(x, 1, indices)\ntensor([[ 0.1427, -0.5414],\n        [-0.4664, -0.1228],\n        [-1.1734,  0.7230]])\n",
        "Question": "How to use torch.index_select, give an example?",
        "Id": 155,
        "source": "https://pytorch.org/docs/stable/generated/torch.index_select.html#torch.index_select",
        "context": " The returned tensor has the same number of dimensions as the original tensor\n(input).  Thedimth dimension has the same size as the length\nofindex; other dimensions have the same size as in the original tensor."
    },
    {
        "Answer": ">>> float_tensor = torch.ones(1, dtype=torch.float)\n>>> double_tensor = torch.ones(1, dtype=torch.double)\n>>> complex_float_tensor = torch.ones(1, dtype=torch.complex64)\n>>> complex_double_tensor = torch.ones(1, dtype=torch.complex128)\n>>> int_tensor = torch.ones(1, dtype=torch.int)\n>>> long_tensor = torch.ones(1, dtype=torch.long)\n>>> uint_tensor = torch.ones(1, dtype=torch.uint8)\n>>> double_tensor = torch.ones(1, dtype=torch.double)\n>>> bool_tensor = torch.ones(1, dtype=torch.bool)\n# zero-dim tensors\n>>> long_zerodim = torch.tensor(1, dtype=torch.long)\n>>> int_zerodim = torch.tensor(1, dtype=torch.int)\n\n>>> torch.add(5, 5).dtype\ntorch.int64\n# 5 is an int64, but does not have higher category than int_tensor so is not considered.\n>>> (int_tensor + 5).dtype\ntorch.int32\n>>> (int_tensor + long_zerodim).dtype\ntorch.int32\n>>> (long_tensor + int_tensor).dtype\ntorch.int64\n>>> (bool_tensor + long_tensor).dtype\ntorch.int64\n>>> (bool_tensor + uint_tensor).dtype\ntorch.uint8\n>>> (float_tensor + double_tensor).dtype\ntorch.float64\n>>> (complex_float_tensor + complex_double_tensor).dtype\ntorch.complex128\n>>> (bool_tensor + int_tensor).dtype\ntorch.int32\n# Since long is a different kind than float, result dtype only needs to be large enough\n# to hold the float.\n>>> torch.add(long_tensor, float_tensor).dtype\ntorch.float32\n",
        "Question": "How  A floating point scalar operand has dtypetorch.get_default_dtype()and an integral\nnon-boolean scalar operand has dtypetorch.int64. Unlike numpy, we do not inspect\nvalues when determining the minimumdtypesof an operand.  Quantized and complex types\nare not yet supported., give an example?",
        "Id": 156,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " A floating point scalar operand has dtypetorch.get_default_dtype()and an integral\nnon-boolean scalar operand has dtypetorch.int64. Unlike numpy, we do not inspect\nvalues when determining the minimumdtypesof an operand.  Quantized and complex types\nare not yet supported."
    },
    {
        "Answer": "# allowed:\n>>> float_tensor *= float_tensor\n>>> float_tensor *= int_tensor\n>>> float_tensor *= uint_tensor\n>>> float_tensor *= bool_tensor\n>>> float_tensor *= double_tensor\n>>> int_tensor *= long_tensor\n>>> int_tensor *= uint_tensor\n>>> uint_tensor *= int_tensor\n\n# disallowed (RuntimeError: result type can't be cast to the desired output type):\n>>> int_tensor *= float_tensor\n>>> bool_tensor *= int_tensor\n>>> bool_tensor *= uint_tensor\n>>> float_tensor *= complex_float_tensor\n",
        "Question": "How  , give an example?",
        "Id": 157,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " "
    },
    {
        "Answer": ">>> torch.device('cuda:0')\ndevice(type='cuda', index=0)\n\n>>> torch.device('cpu')\ndevice(type='cpu')\n\n>>> torch.device('cuda')  # current cuda device\ndevice(type='cuda')\n",
        "Question": "How  Atorch.devicecan be constructed via a string or via a string and device ordinalVia a string:, give an example?",
        "Id": 158,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " Atorch.devicecan be constructed via a string or via a string and device ordinalVia a string:"
    },
    {
        "Answer": ">>> torch.device('cuda', 0)\ndevice(type='cuda', index=0)\n\n>>> torch.device('cpu', 0)\ndevice(type='cpu', index=0)\n",
        "Question": "How  Via a string:Via a string and device ordinal:, give an example?",
        "Id": 159,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " Via a string:Via a string and device ordinal:"
    },
    {
        "Answer": ">>> # Example of a function that takes in a torch.device\n>>> cuda1 = torch.device('cuda:1')\n>>> torch.randn((2,3), device=cuda1)\n",
        "Question": "How  Thetorch.deviceargument in functions can generally be substituted with a string.\nThis allows for fast prototyping of code., give an example?",
        "Id": 160,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " Thetorch.deviceargument in functions can generally be substituted with a string.\nThis allows for fast prototyping of code."
    },
    {
        "Answer": ">>> # You can substitute the torch.device with a string\n>>> torch.randn((2,3), device='cuda:1')\n",
        "Question": "How  Thetorch.deviceargument in functions can generally be substituted with a string.\nThis allows for fast prototyping of code., give an example?",
        "Id": 161,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " Thetorch.deviceargument in functions can generally be substituted with a string.\nThis allows for fast prototyping of code."
    },
    {
        "Answer": ">>> torch.device(1)\ndevice(type='cuda', index=1)\n",
        "Question": "How  For legacy reasons, a device can be constructed via a single device ordinal, which is treated\nas a cuda device.  This matchesTensor.get_device(), which returns an ordinal for cuda\ntensors and is not supported for cpu tensors., give an example?",
        "Id": 162,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " For legacy reasons, a device can be constructed via a single device ordinal, which is treated\nas a cuda device.  This matchesTensor.get_device(), which returns an ordinal for cuda\ntensors and is not supported for cpu tensors."
    },
    {
        "Answer": ">>> torch.randn((2,3), device=torch.device('cuda:1'))\n>>> torch.randn((2,3), device='cuda:1')\n>>> torch.randn((2,3), device=1)  # legacy\n",
        "Question": "How  Methods which take a device will generally accept a (properly formatted) string\nor (legacy) integer device ordinal, i.e. the following are all equivalent:, give an example?",
        "Id": 163,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " Methods which take a device will generally accept a (properly formatted) string\nor (legacy) integer device ordinal, i.e. the following are all equivalent:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n>>> x.stride()\n(5, 1)\n\n>>> x.t().stride()\n(1, 5)\n",
        "Question": "How  torch.stridedrepresents dense Tensors and is the memory layout that\nis most commonly used. Each strided tensor has an associatedtorch.Storage, which holds its data. These tensors provide\nmulti-dimensional,stridedview of a storage. Strides are a list of integers: the k-th stride\nrepresents the jump in the memory necessary to go from one element to the\nnext one in the k-th dimension of the Tensor. This concept makes it possible\nto perform many tensor operations efficiently., give an example?",
        "Id": 164,
        "source": "https://pytorch.org/docs/stable/tensor_attributes.html#type-promotion-doc",
        "context": " torch.stridedrepresents dense Tensors and is the memory layout that\nis most commonly used. Each strided tensor has an associatedtorch.Storage, which holds its data. These tensors provide\nmulti-dimensional,stridedview of a storage. Strides are a list of integers: the k-th stride\nrepresents the jump in the memory necessary to go from one element to the\nnext one in the k-th dimension of the Tensor. This concept makes it possible\nto perform many tensor operations efficiently."
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a = torch.mm(a, a.t()) # make symmetric positive definite\n>>> u = torch.cholesky(a)\n>>> a\ntensor([[ 0.7747, -1.9549,  1.3086],\n        [-1.9549,  6.7546, -5.4114],\n        [ 1.3086, -5.4114,  4.8733]])\n>>> b = torch.randn(3, 2)\n>>> b\ntensor([[-0.6355,  0.9891],\n        [ 0.1974,  1.4706],\n        [-0.4115, -0.6225]])\n>>> torch.cholesky_solve(b, u)\ntensor([[ -8.1625,  19.6097],\n        [ -5.8398,  14.2387],\n        [ -4.3771,  10.4173]])\n>>> torch.mm(a.inverse(), b)\ntensor([[ -8.1626,  19.6097],\n        [ -5.8398,  14.2387],\n        [ -4.3771,  10.4173]])\n",
        "Question": "How to use torch.cholesky_solve, give an example?",
        "Id": 165,
        "source": "https://pytorch.org/docs/stable/generated/torch.cholesky_solve.html#torch.cholesky_solve",
        "context": " Supports real-valued and complex-valued inputs.\nFor the complex-valued inputs the transpose operator above is the conjugate transpose."
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[ 0.1139,  0.2254, -0.1381,  0.3687],\n        [ 1.0100, -1.1975, -0.0102, -0.4732],\n        [-0.9240,  0.1207, -0.7506, -1.0213],\n        [ 1.7809, -1.2960,  0.9384,  0.1438]])\n>>> torch.argmin(a)\ntensor(13)\n>>> torch.argmin(a, dim=1)\ntensor([ 2,  1,  3,  1])\n>>> torch.argmin(a, dim=1, keepdim=True)\ntensor([[2],\n        [1],\n        [3],\n        [1]])\n",
        "Question": "How to use torch.argmin, give an example?",
        "Id": 166,
        "source": "https://pytorch.org/docs/stable/generated/torch.argmin.html#torch.argmin",
        "context": " This is the second value returned bytorch.min(). See its\ndocumentation for the exact semantics of this method."
    },
    {
        "Answer": "probs = policy_network(state)\n# Note that this is equivalent to what used to be called multinomial\nm = Categorical(probs)\naction = m.sample()\nnext_state, reward = env.step(action)\nloss = -m.log_prob(action) * reward\nloss.backward()\n",
        "Question": "How to use where\u03b8\\theta\u03b8are the parameters,\u03b1\\alpha\u03b1is the learning rate,rrris the reward andp(a\u2223\u03c0\u03b8(s))p(a|\\pi^\\theta(s))p(a\u2223\u03c0\u03b8(s))is the probability of\ntaking actionaaain statesssgiven policy\u03c0\u03b8\\pi^\\theta\u03c0\u03b8.In practice we would sample an action from the output of a network, apply this\naction in an environment, and then uselog_probto construct an equivalent\nloss function. Note that we use a negative because optimizers use gradient\ndescent, whilst the rule above assumes gradient ascent. With a categorical\npolicy, the code for implementing REINFORCE would be as follows:, give an example?",
        "Id": 167,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " where\u03b8\\theta\u03b8are the parameters,\u03b1\\alpha\u03b1is the learning rate,rrris the reward andp(a\u2223\u03c0\u03b8(s))p(a|\\pi^\\theta(s))p(a\u2223\u03c0\u03b8(s))is the probability of\ntaking actionaaain statesssgiven policy\u03c0\u03b8\\pi^\\theta\u03c0\u03b8.In practice we would sample an action from the output of a network, apply this\naction in an environment, and then uselog_probto construct an equivalent\nloss function. Note that we use a negative because optimizers use gradient\ndescent, whilst the rule above assumes gradient ascent. With a categorical\npolicy, the code for implementing REINFORCE would be as follows:"
    },
    {
        "Answer": "params = policy_network(state)\nm = Normal(*params)\n# Any distribution with .has_rsample == True could work based on the application\naction = m.rsample()\nnext_state, reward = env.step(action)  # Assuming that reward is differentiable\nloss = -reward\nloss.backward()\n",
        "Question": "How to use The other way to implement these stochastic/policy gradients would be to use the\nreparameterization trick from thersample()method, where the\nparameterized random variable can be constructed via a parameterized\ndeterministic function of a parameter-free random variable. The reparameterized\nsample therefore becomes differentiable. The code for implementing the pathwise\nderivative would be as follows:, give an example?",
        "Id": 168,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " The other way to implement these stochastic/policy gradients would be to use the\nreparameterization trick from thersample()method, where the\nparameterized random variable can be constructed via a parameterized\ndeterministic function of a parameter-free random variable. The reparameterized\nsample therefore becomes differentiable. The code for implementing the pathwise\nderivative would be as follows:"
    },
    {
        "Answer": ">>> m = Bernoulli(torch.tensor([0.3]))\n>>> m.sample()  # 30% chance 1; 70% chance 0\ntensor([ 0.])\n",
        "Question": "How to use torch.distributions.bernoulli.Bernoulli, give an example?",
        "Id": 169,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Samples are binary (0 or 1). They take the value1with probabilitypand0with probability1 - p."
    },
    {
        "Answer": ">>> m = Beta(torch.tensor([0.5]), torch.tensor([0.5]))\n>>> m.sample()  # Beta distributed with concentration concentration1 and concentration0\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.beta.Beta, give an example?",
        "Id": 170,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Beta distribution parameterized byconcentration1andconcentration0."
    },
    {
        "Answer": ">>> m = Binomial(100, torch.tensor([0 , .2, .8, 1]))\n>>> x = m.sample()\ntensor([   0.,   22.,   71.,  100.])\n\n>>> m = Binomial(torch.tensor([[5.], [10.]]), torch.tensor([0.5, 0.8]))\n>>> x = m.sample()\ntensor([[ 4.,  5.],\n        [ 7.,  6.]])\n",
        "Question": "How to use torch.distributions.binomial.Binomial, give an example?",
        "Id": 171,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a Binomial distribution parameterized bytotal_countand\neitherprobsorlogits(but not both).total_countmust be\nbroadcastable withprobs/logits."
    },
    {
        "Answer": ">>> m = Categorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n>>> m.sample()  # equal probability of 0, 1, 2, 3\ntensor(3)\n",
        "Question": "How to use torch.distributions.categorical.Categorical, give an example?",
        "Id": 172,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " See also:torch.multinomial()"
    },
    {
        "Answer": ">>> m = Cauchy(torch.tensor([0.0]), torch.tensor([1.0]))\n>>> m.sample()  # sample from a Cauchy distribution with loc=0 and scale=1\ntensor([ 2.3214])\n",
        "Question": "How to use torch.distributions.cauchy.Cauchy, give an example?",
        "Id": 173,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Samples from a Cauchy (Lorentz) distribution. The distribution of the ratio of\nindependent normally distributed random variables with means0follows a\nCauchy distribution."
    },
    {
        "Answer": ">>> m = Chi2(torch.tensor([1.0]))\n>>> m.sample()  # Chi2 distributed with shape df=1\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.chi2.Chi2, give an example?",
        "Id": 174,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a Chi2 distribution parameterized by shape parameterdf.\nThis is exactly equivalent toGamma(alpha=0.5*df,beta=0.5)"
    },
    {
        "Answer": ">>> m = ContinuousBernoulli(torch.tensor([0.3]))\n>>> m.sample()\ntensor([ 0.2538])\n",
        "Question": "How to use torch.distributions.continuous_bernoulli.ContinuousBernoulli, give an example?",
        "Id": 175,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " The distribution is supported in [0, 1] and parameterized by \u2018probs\u2019 (in\n(0,1)) or \u2018logits\u2019 (real-valued). Note that, unlike the Bernoulli, \u2018probs\u2019\ndoes not correspond to a probability and \u2018logits\u2019 does not correspond to\nlog-odds, but the same names are used due to the similarity with the\nBernoulli. See [1] for more details."
    },
    {
        "Answer": ">>> m = Dirichlet(torch.tensor([0.5, 0.5]))\n>>> m.sample()  # Dirichlet distributed with concentrarion concentration\ntensor([ 0.1046,  0.8954])\n",
        "Question": "How to use torch.distributions.dirichlet.Dirichlet, give an example?",
        "Id": 176,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a Dirichlet distribution parameterized by concentrationconcentration."
    },
    {
        "Answer": ">>> m = Exponential(torch.tensor([1.0]))\n>>> m.sample()  # Exponential distributed with rate=1\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.exponential.Exponential, give an example?",
        "Id": 177,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a Exponential distribution parameterized byrate."
    },
    {
        "Answer": ">>> m = FisherSnedecor(torch.tensor([1.0]), torch.tensor([2.0]))\n>>> m.sample()  # Fisher-Snedecor-distributed with df1=1 and df2=2\ntensor([ 0.2453])\n",
        "Question": "How to use torch.distributions.fishersnedecor.FisherSnedecor, give an example?",
        "Id": 178,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a Fisher-Snedecor distribution parameterized bydf1anddf2."
    },
    {
        "Answer": ">>> m = Gamma(torch.tensor([1.0]), torch.tensor([1.0]))\n>>> m.sample()  # Gamma distributed with concentration=1 and rate=1\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.gamma.Gamma, give an example?",
        "Id": 179,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a Gamma distribution parameterized by shapeconcentrationandrate."
    },
    {
        "Answer": ">>> m = Geometric(torch.tensor([0.3]))\n>>> m.sample()  # underlying Bernoulli has 30% chance 1; 70% chance 0\ntensor([ 2.])\n",
        "Question": "How to use torch.distributions.geometric.Geometric, give an example?",
        "Id": 180,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Samples are non-negative integers [0,inf\u2061\\infinf)."
    },
    {
        "Answer": ">>> m = Gumbel(torch.tensor([1.0]), torch.tensor([2.0]))\n>>> m.sample()  # sample from Gumbel distribution with loc=1, scale=2\ntensor([ 1.0124])\n",
        "Question": "How to use torch.distributions.gumbel.Gumbel, give an example?",
        "Id": 181,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Samples from a Gumbel Distribution."
    },
    {
        "Answer": "X ~ Cauchy(0, scale)\nY = |X| ~ HalfCauchy(scale)\n",
        "Question": "How to use Creates a half-Cauchy distribution parameterized byscalewhere:, give an example?",
        "Id": 182,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a half-Cauchy distribution parameterized byscalewhere:"
    },
    {
        "Answer": ">>> m = HalfCauchy(torch.tensor([1.0]))\n>>> m.sample()  # half-cauchy distributed with scale=1\ntensor([ 2.3214])\n",
        "Question": "How to use torch.distributions.half_cauchy.HalfCauchy, give an example?",
        "Id": 183,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a half-Cauchy distribution parameterized byscalewhere:"
    },
    {
        "Answer": "X ~ Normal(0, scale)\nY = |X| ~ HalfNormal(scale)\n",
        "Question": "How to use Creates a half-normal distribution parameterized byscalewhere:, give an example?",
        "Id": 184,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a half-normal distribution parameterized byscalewhere:"
    },
    {
        "Answer": ">>> m = HalfNormal(torch.tensor([1.0]))\n>>> m.sample()  # half-normal distributed with scale=1\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.half_normal.HalfNormal, give an example?",
        "Id": 185,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a half-normal distribution parameterized byscalewhere:"
    },
    {
        "Answer": ">>> loc = torch.zeros(3)\n>>> scale = torch.ones(3)\n>>> mvn = MultivariateNormal(loc, scale_tril=torch.diag(scale))\n>>> [mvn.batch_shape, mvn.event_shape]\n[torch.Size(()), torch.Size((3,))]\n>>> normal = Normal(loc, scale)\n>>> [normal.batch_shape, normal.event_shape]\n[torch.Size((3,)), torch.Size(())]\n>>> diagn = Independent(normal, 1)\n>>> [diagn.batch_shape, diagn.event_shape]\n[torch.Size(()), torch.Size((3,))]\n",
        "Question": "How to use This is mainly useful for changing the shape of the result oflog_prob(). For example to create a diagonal Normal distribution with\nthe same shape as a Multivariate Normal distribution (so they are\ninterchangeable), you can:, give an example?",
        "Id": 186,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Reinterprets some of the batch dims of a distribution as event dims.This is mainly useful for changing the shape of the result oflog_prob(). For example to create a diagonal Normal distribution with\nthe same shape as a Multivariate Normal distribution (so they are\ninterchangeable), you can:"
    },
    {
        "Answer": ">>> m = Kumaraswamy(torch.tensor([1.0]), torch.tensor([1.0]))\n>>> m.sample()  # sample from a Kumaraswamy distribution with concentration alpha=1 and beta=1\ntensor([ 0.1729])\n",
        "Question": "How to use torch.distributions.kumaraswamy.Kumaraswamy, give an example?",
        "Id": 187,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Samples from a Kumaraswamy distribution."
    },
    {
        "Answer": ">>> l = LKJCholesky(3, 0.5)\n>>> l.sample()  # l @ l.T is a sample of a correlation 3x3 matrix\ntensor([[ 1.0000,  0.0000,  0.0000],\n        [ 0.3516,  0.9361,  0.0000],\n        [-0.1899,  0.4748,  0.8593]])\n",
        "Question": "How to use torch.distributions.lkj_cholesky.LKJCholesky, give an example?",
        "Id": 188,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " LKJ distribution for lower Cholesky factor of correlation matrices.\nThe distribution is controlled byconcentrationparameter\u03b7\\eta\u03b7to make the probability of the correlation matrixMMMgenerated from\na Cholesky factor propotional todet\u2061(M)\u03b7\u22121\\det(M)^{\\eta - 1}det(M)\u03b7\u22121. Because of that,\nwhenconcentration==1, we have a uniform distribution over Cholesky\nfactors of correlation matrices. Note that this distribution samples the\nCholesky factor of correlation matrices and not the correlation matrices\nthemselves and thereby differs slightly from the derivations in [1] for\ntheLKJCorrdistribution. For sampling, this uses the Onion method from\n[1] Section 3."
    },
    {
        "Answer": ">>> m = Laplace(torch.tensor([0.0]), torch.tensor([1.0]))\n>>> m.sample()  # Laplace distributed with loc=0, scale=1\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.laplace.Laplace, give an example?",
        "Id": 189,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a Laplace distribution parameterized bylocandscale."
    },
    {
        "Answer": "X ~ Normal(loc, scale)\nY = exp(X) ~ LogNormal(loc, scale)\n",
        "Question": "How to use Creates a log-normal distribution parameterized bylocandscalewhere:, give an example?",
        "Id": 190,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a log-normal distribution parameterized bylocandscalewhere:"
    },
    {
        "Answer": ">>> m = LogNormal(torch.tensor([0.0]), torch.tensor([1.0]))\n>>> m.sample()  # log-normal distributed with mean=0 and stddev=1\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.log_normal.LogNormal, give an example?",
        "Id": 191,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a log-normal distribution parameterized bylocandscalewhere:"
    },
    {
        "Answer": "covariance_matrix = cov_factor @ cov_factor.T + cov_diag\n",
        "Question": "How to use Creates a multivariate normal distribution with covariance matrix having a low-rank form\nparameterized bycov_factorandcov_diag:, give an example?",
        "Id": 192,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a multivariate normal distribution with covariance matrix having a low-rank form\nparameterized bycov_factorandcov_diag:"
    },
    {
        "Answer": ">>> m = LowRankMultivariateNormal(torch.zeros(2), torch.tensor([[1.], [0.]]), torch.ones(2))\n>>> m.sample()  # normally distributed with mean=`[0,0]`, cov_factor=`[[1],[0]]`, cov_diag=`[1,1]`\ntensor([-0.2102, -0.5429])\n",
        "Question": "How to use torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal, give an example?",
        "Id": 193,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a multivariate normal distribution with covariance matrix having a low-rank form\nparameterized bycov_factorandcov_diag:"
    },
    {
        "Answer": "capacitance = I + cov_factor.T @ inv(cov_diag) @ cov_factor\n",
        "Question": "How to use The computation for determinant and inverse of covariance matrix is avoided whencov_factor.shape[1] << cov_factor.shape[0]thanks toWoodbury matrix identityandmatrix determinant lemma.\nThanks to these formulas, we just need to compute the determinant and inverse of\nthe small size \u201ccapacitance\u201d matrix:, give an example?",
        "Id": 194,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " The computation for determinant and inverse of covariance matrix is avoided whencov_factor.shape[1] << cov_factor.shape[0]thanks toWoodbury matrix identityandmatrix determinant lemma.\nThanks to these formulas, we just need to compute the determinant and inverse of\nthe small size \u201ccapacitance\u201d matrix:"
    },
    {
        "Answer": "# Construct Gaussian Mixture Model in 1D consisting of 5 equally\n# weighted normal distributions\n>>> mix = D.Categorical(torch.ones(5,))\n>>> comp = D.Normal(torch.randn(5,), torch.rand(5,))\n>>> gmm = MixtureSameFamily(mix, comp)\n\n# Construct Gaussian Mixture Modle in 2D consisting of 5 equally\n# weighted bivariate normal distributions\n>>> mix = D.Categorical(torch.ones(5,))\n>>> comp = D.Independent(D.Normal(\n             torch.randn(5,2), torch.rand(5,2)), 1)\n>>> gmm = MixtureSameFamily(mix, comp)\n\n# Construct a batch of 3 Gaussian Mixture Models in 2D each\n# consisting of 5 random weighted bivariate normal distributions\n>>> mix = D.Categorical(torch.rand(3,5))\n>>> comp = D.Independent(D.Normal(\n            torch.randn(3,5,2), torch.rand(3,5,2)), 1)\n>>> gmm = MixtureSameFamily(mix, comp)\n",
        "Question": "How to use torch.distributions.mixture_same_family.MixtureSameFamily, give an example?",
        "Id": 195,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " TheMixtureSameFamilydistribution implements a (batch of) mixture\ndistribution where all component are from different parameterizations of\nthe same distribution type. It is parameterized by aCategorical\u201cselecting distribution\u201d (overkcomponent) and a component\ndistribution, i.e., aDistributionwith a rightmost batch shape\n(equal to[k]) which indexes each (batch of) component."
    },
    {
        "Answer": ">>> m = Multinomial(100, torch.tensor([ 1., 1., 1., 1.]))\n>>> x = m.sample()  # equal probability of 0, 1, 2, 3\ntensor([ 21.,  24.,  30.,  25.])\n\n>>> Multinomial(probs=torch.tensor([1., 1., 1., 1.])).log_prob(x)\ntensor([-4.1338])\n",
        "Question": "How to use torch.distributions.multinomial.Multinomial, give an example?",
        "Id": 196,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Note thattotal_countneed not be specified if onlylog_prob()is\ncalled (see example below)"
    },
    {
        "Answer": ">>> m = MultivariateNormal(torch.zeros(2), torch.eye(2))\n>>> m.sample()  # normally distributed with mean=`[0,0]` and covariance_matrix=`I`\ntensor([-0.2102, -0.5429])\n",
        "Question": "How to use torch.distributions.multivariate_normal.MultivariateNormal, give an example?",
        "Id": 197,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " The multivariate normal distribution can be parameterized either\nin terms of a positive definite covariance matrix\u03a3\\mathbf{\\Sigma}\u03a3or a positive definite precision matrix\u03a3\u22121\\mathbf{\\Sigma}^{-1}\u03a3\u22121or a lower-triangular matrixL\\mathbf{L}Lwith positive-valued\ndiagonal entries, such that\u03a3=LL\u22a4\\mathbf{\\Sigma} = \\mathbf{L}\\mathbf{L}^\\top\u03a3=LL\u22a4. This triangular matrix\ncan be obtained via e.g. Cholesky decomposition of the covariance."
    },
    {
        "Answer": ">>> m = Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n>>> m.sample()  # normally distributed with loc=0 and scale=1\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.normal.Normal, give an example?",
        "Id": 198,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a normal (also called Gaussian) distribution parameterized bylocandscale."
    },
    {
        "Answer": ">>> m = OneHotCategorical(torch.tensor([ 0.25, 0.25, 0.25, 0.25 ]))\n>>> m.sample()  # equal probability of 0, 1, 2, 3\ntensor([ 0.,  0.,  0.,  1.])\n",
        "Question": "How to use torch.distributions.one_hot_categorical.OneHotCategorical, give an example?",
        "Id": 199,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " See also:torch.distributions.Categorical()for specifications ofprobsandlogits."
    },
    {
        "Answer": ">>> m = Pareto(torch.tensor([1.0]), torch.tensor([1.0]))\n>>> m.sample()  # sample from a Pareto distribution with scale=1 and alpha=1\ntensor([ 1.5623])\n",
        "Question": "How to use torch.distributions.pareto.Pareto, give an example?",
        "Id": 200,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Samples from a Pareto Type 1 distribution."
    },
    {
        "Answer": ">>> m = Poisson(torch.tensor([4]))\n>>> m.sample()\ntensor([ 3.])\n",
        "Question": "How to use torch.distributions.poisson.Poisson, give an example?",
        "Id": 201,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Samples are nonnegative integers, with a pmf given by"
    },
    {
        "Answer": ">>> m = RelaxedBernoulli(torch.tensor([2.2]),\n                         torch.tensor([0.1, 0.2, 0.3, 0.99]))\n>>> m.sample()\ntensor([ 0.2951,  0.3442,  0.8918,  0.9021])\n",
        "Question": "How to use torch.distributions.relaxed_bernoulli.RelaxedBernoulli, give an example?",
        "Id": 202,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a RelaxedBernoulli distribution, parametrized bytemperature, and eitherprobsorlogits(but not both). This is a relaxed version of theBernoullidistribution,\nso the values are in (0, 1), and has reparametrizable samples."
    },
    {
        "Answer": ">>> m = RelaxedOneHotCategorical(torch.tensor([2.2]),\n                                 torch.tensor([0.1, 0.2, 0.3, 0.4]))\n>>> m.sample()\ntensor([ 0.1294,  0.2324,  0.3859,  0.2523])\n",
        "Question": "How to use torch.distributions.relaxed_categorical.RelaxedOneHotCategorical, give an example?",
        "Id": 203,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a RelaxedOneHotCategorical distribution parametrized bytemperature, and eitherprobsorlogits.\nThis is a relaxed version of theOneHotCategoricaldistribution, so\nits samples are on simplex, and are reparametrizable."
    },
    {
        "Answer": ">>> m = StudentT(torch.tensor([2.0]))\n>>> m.sample()  # Student's t-distributed with degrees of freedom=2\ntensor([ 0.1046])\n",
        "Question": "How to use torch.distributions.studentT.StudentT, give an example?",
        "Id": 204,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Creates a Student\u2019s t-distribution parameterized by degree of\nfreedomdf, meanlocand scalescale."
    },
    {
        "Answer": "X ~ BaseDistribution\nY = f(X) ~ TransformedDistribution(BaseDistribution, f)\nlog p(Y) = log p(X) + log |det (dX/dY)|\n",
        "Question": "How to use Extension of the Distribution class, which applies a sequence of Transforms\nto a base distribution.  Let f be the composition of transforms applied:, give an example?",
        "Id": 205,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Extension of the Distribution class, which applies a sequence of Transforms\nto a base distribution.  Let f be the composition of transforms applied:"
    },
    {
        "Answer": "# Building a Logistic Distribution\n# X ~ Uniform(0, 1)\n# f = a + b * logit(X)\n# Y ~ f(X) ~ Logistic(a, b)\nbase_distribution = Uniform(0, 1)\ntransforms = [SigmoidTransform().inv, AffineTransform(loc=a, scale=b)]\nlogistic = TransformedDistribution(base_distribution, transforms)\n",
        "Question": "How to use An example for the usage ofTransformedDistributionwould be:, give an example?",
        "Id": 206,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Note that the.event_shapeof aTransformedDistributionis the\nmaximum shape of its base distribution and its transforms, since transforms\ncan introduce correlations among events.An example for the usage ofTransformedDistributionwould be:"
    },
    {
        "Answer": ">>> m = Uniform(torch.tensor([0.0]), torch.tensor([5.0]))\n>>> m.sample()  # uniformly distributed in the range [0.0, 5.0)\ntensor([ 2.3418])\n",
        "Question": "How to use torch.distributions.uniform.Uniform, give an example?",
        "Id": 207,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Generates uniformly distributed random samples from the half-open interval[low,high)."
    },
    {
        "Answer": ">>> m = dist.VonMises(torch.tensor([1.0]), torch.tensor([1.0]))\n>>> m.sample() # von Mises distributed with loc=1 and concentration=1\ntensor([1.9777])\n",
        "Question": "How to use VonMises, give an example?",
        "Id": 208,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " "
    },
    {
        "Answer": ">>> m = Weibull(torch.tensor([1.0]), torch.tensor([1.0]))\n>>> m.sample()  # sample from a Weibull distribution with scale=1, concentration=1\ntensor([ 0.4784])\n",
        "Question": "How to use torch.distributions.weibull.Weibull, give an example?",
        "Id": 209,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Samples from a two-parameter Weibull distribution."
    },
    {
        "Answer": "@register_kl(Normal, Normal)\ndef kl_normal_normal(p, q):\n    # insert implementation here\n",
        "Question": "How to use torch.distributions.kl.register_kl, give an example?",
        "Id": 210,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Decorator to register a pairwise function withkl_divergence().\nUsage:"
    },
    {
        "Answer": "@register_kl(BaseP, DerivedQ)\ndef kl_version1(p, q): ...\n@register_kl(DerivedP, BaseQ)\ndef kl_version2(p, q): ...\n",
        "Question": "How  Lookup returns the most specific (type,type) match ordered by subclass. If\nthe match is ambiguous, aRuntimeWarningis raised. For example to\nresolve the ambiguous situation:, give an example?",
        "Id": 211,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Lookup returns the most specific (type,type) match ordered by subclass. If\nthe match is ambiguous, aRuntimeWarningis raised. For example to\nresolve the ambiguous situation:"
    },
    {
        "Answer": "register_kl(DerivedP, DerivedQ)(kl_version1)  # Break the tie.\n",
        "Question": "How  Lookup returns the most specific (type,type) match ordered by subclass. If\nthe match is ambiguous, aRuntimeWarningis raised. For example to\nresolve the ambiguous situation:you should register a third most-specific implementation, e.g.:, give an example?",
        "Id": 212,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Lookup returns the most specific (type,type) match ordered by subclass. If\nthe match is ambiguous, aRuntimeWarningis raised. For example to\nresolve the ambiguous situation:you should register a third most-specific implementation, e.g.:"
    },
    {
        "Answer": "y = t(x)\nt.log_abs_det_jacobian(x, y).backward()  # x will receive gradients.\n",
        "Question": "How to use Caching is useful for transforms whose inverses are either expensive or\nnumerically unstable. Note that care must be taken with memoized values\nsince the autograd graph may be reversed. For example while the following\nworks with or without caching:, give an example?",
        "Id": 213,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Caching is useful for transforms whose inverses are either expensive or\nnumerically unstable. Note that care must be taken with memoized values\nsince the autograd graph may be reversed. For example while the following\nworks with or without caching:"
    },
    {
        "Answer": "y = t(x)\nz = t.inv(y)\ngrad(z.sum(), [y])  # error because z is x\n",
        "Question": "How to use However the following will error when caching due to dependency reversal:, give an example?",
        "Id": 214,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Caching is useful for transforms whose inverses are either expensive or\nnumerically unstable. Note that care must be taken with memoized values\nsince the autograd graph may be reversed. For example while the following\nworks with or without caching:However the following will error when caching due to dependency reversal:"
    },
    {
        "Answer": "loc = torch.zeros(100, requires_grad=True)\nunconstrained = torch.zeros(100, requires_grad=True)\nscale = transform_to(Normal.arg_constraints['scale'])(unconstrained)\nloss = -Normal(loc, scale).log_prob(data).sum()\n",
        "Question": "How to use PyTorch provides two globalConstraintRegistryobjects that linkConstraintobjects toTransformobjects. These objects both\ninput constraints and return transforms, but they have different guarantees on\nbijectivity.Thetransform_to()registry is useful for performing unconstrained\noptimization on constrained parameters of probability distributions, which are\nindicated by each distribution\u2019s.arg_constraintsdict. These transforms often\noverparameterize a space in order to avoid rotation; they are thus more\nsuitable for coordinate-wise optimization algorithms like Adam:, give an example?",
        "Id": 215,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Thetransform_to()registry is useful for performing unconstrained\noptimization on constrained parameters of probability distributions, which are\nindicated by each distribution\u2019s.arg_constraintsdict. These transforms often\noverparameterize a space in order to avoid rotation; they are thus more\nsuitable for coordinate-wise optimization algorithms like Adam:"
    },
    {
        "Answer": "dist = Exponential(rate)\nunconstrained = torch.zeros(100, requires_grad=True)\nsample = biject_to(dist.support)(unconstrained)\npotential_energy = -dist.log_prob(sample).sum()\n",
        "Question": "How to use Thetransform_to()registry is useful for performing unconstrained\noptimization on constrained parameters of probability distributions, which are\nindicated by each distribution\u2019s.arg_constraintsdict. These transforms often\noverparameterize a space in order to avoid rotation; they are thus more\nsuitable for coordinate-wise optimization algorithms like Adam:Thebiject_to()registry is useful for Hamiltonian Monte Carlo, where\nsamples from a probability distribution with constrained.supportare\npropagated in an unconstrained space, and algorithms are typically rotation\ninvariant.:, give an example?",
        "Id": 216,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Thetransform_to()registry is useful for performing unconstrained\noptimization on constrained parameters of probability distributions, which are\nindicated by each distribution\u2019s.arg_constraintsdict. These transforms often\noverparameterize a space in order to avoid rotation; they are thus more\nsuitable for coordinate-wise optimization algorithms like Adam:Thebiject_to()registry is useful for Hamiltonian Monte Carlo, where\nsamples from a probability distribution with constrained.supportare\npropagated in an unconstrained space, and algorithms are typically rotation\ninvariant.:"
    },
    {
        "Answer": "transform_to.register(my_constraint, my_transform)\n",
        "Question": "How to use Thebiject_to()registry is useful for Hamiltonian Monte Carlo, where\nsamples from a probability distribution with constrained.supportare\npropagated in an unconstrained space, and algorithms are typically rotation\ninvariant.:Thebiject_toandtransform_toobjects can be extended by user-defined\nconstraints and transforms using their.register()method either as a\nfunction on singleton constraints:, give an example?",
        "Id": 217,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Thebiject_to()registry is useful for Hamiltonian Monte Carlo, where\nsamples from a probability distribution with constrained.supportare\npropagated in an unconstrained space, and algorithms are typically rotation\ninvariant.:Thebiject_toandtransform_toobjects can be extended by user-defined\nconstraints and transforms using their.register()method either as a\nfunction on singleton constraints:"
    },
    {
        "Answer": "@transform_to.register(MyConstraintClass)\ndef my_factory(constraint):\n    assert isinstance(constraint, MyConstraintClass)\n    return MyTransform(constraint.param1, constraint.param2)\n",
        "Question": "How to use Thebiject_toandtransform_toobjects can be extended by user-defined\nconstraints and transforms using their.register()method either as a\nfunction on singleton constraints:or as a decorator on parameterized constraints:, give an example?",
        "Id": 218,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Thebiject_toandtransform_toobjects can be extended by user-defined\nconstraints and transforms using their.register()method either as a\nfunction on singleton constraints:or as a decorator on parameterized constraints:"
    },
    {
        "Answer": "@my_registry.register(MyConstraintClass)\ndef construct_transform(constraint):\n    assert isinstance(constraint, MyConstraint)\n    return MyTransform(constraint.arg_constraints)\n",
        "Question": "How to use torch.distributions.constraint_registry.ConstraintRegistry.register, give an example?",
        "Id": 219,
        "source": "https://pytorch.org/docs/stable/distributions.html",
        "context": " Registers aConstraintsubclass in this registry. Usage:"
    },
    {
        "Answer": ">>> soboleng = torch.quasirandom.SobolEngine(dimension=5)\n>>> soboleng.draw(3)\ntensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.5000],\n        [0.7500, 0.2500, 0.7500, 0.2500, 0.7500],\n        [0.2500, 0.7500, 0.2500, 0.7500, 0.2500]])\n",
        "Question": "How to use torch.quasirandom.SobolEngine, give an example?",
        "Id": 220,
        "source": "https://pytorch.org/docs/stable/generated/torch.quasirandom.SobolEngine.html#torch.quasirandom.SobolEngine",
        "context": " References"
    },
    {
        "Answer": ">>> x = torch.tensor([1, 1, 2, 2, 3, 1, 1, 2])\n>>> output = torch.unique_consecutive(x)\n>>> output\ntensor([1, 2, 3, 1, 2])\n\n>>> output, inverse_indices = torch.unique_consecutive(x, return_inverse=True)\n>>> output\ntensor([1, 2, 3, 1, 2])\n>>> inverse_indices\ntensor([0, 0, 1, 1, 2, 3, 3, 4])\n\n>>> output, counts = torch.unique_consecutive(x, return_counts=True)\n>>> output\ntensor([1, 2, 3, 1, 2])\n>>> counts\ntensor([2, 2, 1, 2, 1])\n",
        "Question": "How to use torch.unique_consecutive, give an example?",
        "Id": 221,
        "source": "https://pytorch.org/docs/stable/generated/torch.unique_consecutive.html#torch.unique_consecutive",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([0.7, -1.2, 0., 2.3])\n>>> torch.signbit(a)\ntensor([ False, True,  False,  False])\n",
        "Question": "How to use torch.signbit, give an example?",
        "Id": 222,
        "source": "https://pytorch.org/docs/stable/generated/torch.signbit.html#torch.signbit",
        "context": " "
    },
    {
        "Answer": ">>> torch.isinf(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')]))\ntensor([False,  True,  False,  True,  False])\n",
        "Question": "How to use torch.isinf, give an example?",
        "Id": 223,
        "source": "https://pytorch.org/docs/stable/generated/torch.isinf.html#torch.isinf",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(5)\n>>> a\ntensor([-1.0090, -0.9923,  1.0249, -0.5372,  0.2492])\n>>> torch.log1p(a)\ntensor([    nan, -4.8653,  0.7055, -0.7705,  0.2225])\n",
        "Question": "How to use torch.log1p, give an example?",
        "Id": 224,
        "source": "https://pytorch.org/docs/stable/generated/torch.log1p.html#torch.log1p",
        "context": " "
    },
    {
        "Answer": ">>> torch.randperm(4)\ntensor([2, 1, 0, 3])\n",
        "Question": "How to use torch.randperm, give an example?",
        "Id": 225,
        "source": "https://pytorch.org/docs/stable/generated/torch.randperm.html#torch.randperm",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([1, 3, 2])\n>>> torch.diff(a)\ntensor([ 2, -1])\n>>> b = torch.tensor([4, 5])\n>>> torch.diff(a, append=b)\ntensor([ 2, -1,  2,  1])\n>>> c = torch.tensor([[1, 2, 3], [3, 4, 5]])\n>>> torch.diff(c, dim=0)\ntensor([[2, 2, 2]])\n>>> torch.diff(c, dim=1)\ntensor([[1, 1],\n        [1, 1]])\n",
        "Question": "How to use torch.diff, give an example?",
        "Id": 226,
        "source": "https://pytorch.org/docs/stable/generated/torch.diff.html#torch.diff",
        "context": " The first-order differences are given byout[i] = input[i + 1] - input[i]. Higher-order\ndifferences are calculated by usingtorch.diff()recursively."
    },
    {
        "Answer": ">>> a = torch.empty(3, 3).uniform_(0, 1)  # generate a uniform random matrix with range [0, 1]\n>>> a\ntensor([[ 0.1737,  0.0950,  0.3609],\n        [ 0.7148,  0.0289,  0.2676],\n        [ 0.9456,  0.8937,  0.7202]])\n>>> torch.bernoulli(a)\ntensor([[ 1.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 1.,  1.,  1.]])\n\n>>> a = torch.ones(3, 3) # probability of drawing \"1\" is 1\n>>> torch.bernoulli(a)\ntensor([[ 1.,  1.,  1.],\n        [ 1.,  1.,  1.],\n        [ 1.,  1.,  1.]])\n>>> a = torch.zeros(3, 3) # probability of drawing \"1\" is 0\n>>> torch.bernoulli(a)\ntensor([[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]])\n",
        "Question": "How to use torch.bernoulli, give an example?",
        "Id": 227,
        "source": "https://pytorch.org/docs/stable/generated/torch.bernoulli.html#torch.bernoulli",
        "context": " outcan have integraldtype, butinputmust have floating\npointdtype."
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[ 0.6451, -0.4866,  0.2987, -1.3312],\n        [-0.5744,  1.2980,  1.8397, -0.2713],\n        [ 0.9128,  0.9214, -1.7268, -0.2995],\n        [ 0.9023,  0.4853,  0.9075, -1.6165]])\n>>> torch.amin(a, 1)\ntensor([-1.3312, -0.5744, -1.7268, -1.6165])\n",
        "Question": "How to use torch.amin, give an example?",
        "Id": 228,
        "source": "https://pytorch.org/docs/stable/generated/torch.amin.html#torch.amin",
        "context": " IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimension(s)dimwhere they are of size 1.\nOtherwise,dim`saresqueezed(see:func:`torch.squeeze), resulting in\nthe output tensors having fewer dimensions thaninput."
    },
    {
        "Answer": ">>> torch.equal(torch.tensor([1, 2]), torch.tensor([1, 2]))\nTrue\n",
        "Question": "How to use torch.equal, give an example?",
        "Id": 229,
        "source": "https://pytorch.org/docs/stable/generated/torch.equal.html#torch.equal",
        "context": " "
    },
    {
        "Answer": ">>> torch.logical_not(torch.tensor([True, False]))\ntensor([False,  True])\n>>> torch.logical_not(torch.tensor([0, 1, -10], dtype=torch.int8))\ntensor([ True, False, False])\n>>> torch.logical_not(torch.tensor([0., 1.5, -10.], dtype=torch.double))\ntensor([ True, False, False])\n>>> torch.logical_not(torch.tensor([0., 1., -10.], dtype=torch.double), out=torch.empty(3, dtype=torch.int16))\ntensor([1, 0, 0], dtype=torch.int16)\n",
        "Question": "How to use torch.logical_not, give an example?",
        "Id": 230,
        "source": "https://pytorch.org/docs/stable/generated/torch.logical_not.html#torch.logical_not",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 231,
        "source": "https://pytorch.org/docs/stable/torch.html#spectral-ops",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.3348, -0.5889,  0.2005, -0.1584])\n>>> torch.acos(a)\ntensor([ 1.2294,  2.2004,  1.3690,  1.7298])\n",
        "Question": "How to use torch.acos, give an example?",
        "Id": 232,
        "source": "https://pytorch.org/docs/stable/generated/torch.acos.html#torch.acos",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 233,
        "source": "https://pytorch.org/docs/stable/torch.html#parallelism",
        "context": " "
    },
    {
        "Answer": ">>> torch.abs(torch.tensor([-1, -2, 3]))\ntensor([ 1,  2,  3])\n",
        "Question": "How to use torch.abs, give an example?",
        "Id": 234,
        "source": "https://pytorch.org/docs/stable/generated/torch.abs.html#torch.abs",
        "context": " "
    },
    {
        "Answer": ">>> a = numpy.array([1, 2, 3])\n>>> t = torch.from_numpy(a)\n>>> t\ntensor([ 1,  2,  3])\n>>> t[0] = -1\n>>> a\narray([-1,  2,  3])\n",
        "Question": "How to use torch.from_numpy, give an example?",
        "Id": 235,
        "source": "https://pytorch.org/docs/stable/generated/torch.from_numpy.html#torch.from_numpy",
        "context": " It currently acceptsndarraywith dtypes ofnumpy.float64,numpy.float32,numpy.float16,numpy.complex64,numpy.complex128,numpy.int64,numpy.int32,numpy.int16,numpy.int8,numpy.uint8,\nandnumpy.bool."
    },
    {
        "Answer": ">>> t = torch.tensor([[[1, 2],\n...                    [3, 4]],\n...                   [[5, 6],\n...                    [7, 8]]])\n>>> torch.ravel(t)\ntensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
        "Question": "How to use torch.ravel, give an example?",
        "Id": 236,
        "source": "https://pytorch.org/docs/stable/generated/torch.ravel.html#torch.ravel",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.2252, -0.2948,  1.0267, -1.1566])\n>>> torch.sinc(a)\ntensor([ 0.9186,  0.8631, -0.0259, -0.1300])\n",
        "Question": "How to use torch.sinc, give an example?",
        "Id": 237,
        "source": "https://pytorch.org/docs/stable/generated/torch.sinc.html#torch.sinc",
        "context": " "
    },
    {
        "Answer": "                        | n=1 | n=4 | ...\n                        ------------- ...\nReLU(x + 1): (float)    | ... | ... | ...\nReLU(x + 1): (int)      | ... | ... | ...\n",
        "Question": "How to use String to distinguish measurements with identical label and\nsub_label. The principal use ofdescriptionis to signal toComparethe columns of data. For instance one might set it\nbased on the input size  to create a table of the form:, give an example?",
        "Id": 238,
        "source": "https://pytorch.org/docs/stable/benchmark_utils.html",
        "context": " String to distinguish measurements with identical label and\nsub_label. The principal use ofdescriptionis to signal toComparethe columns of data. For instance one might set it\nbased on the input size  to create a table of the form:"
    },
    {
        "Answer": "`setup`\n\ntotal_time = 0\nwhile total_time < min_run_time\n    start = timer()\n    for _ in range(block_size):\n        `stmt`\n    total_time += (timer() - start)\n",
        "Question": "How to use torch.utils.benchmark.Timer.blocked_autorange, give an example?",
        "Id": 239,
        "source": "https://pytorch.org/docs/stable/benchmark_utils.html",
        "context": " At a high level, blocked_autorange executes the following pseudo-code:"
    },
    {
        "Answer": "23234231 /tmp/first_build_dir/thing.c:foo(...)\n 9823794 /tmp/first_build_dir/thing.c:bar(...)\n  ...\n   53453 .../aten/src/Aten/...:function_that_actually_changed(...)\n  ...\n -9823794 /tmp/second_build_dir/thing.c:bar(...)\n-23234231 /tmp/second_build_dir/thing.c:foo(...)\n",
        "Question": "How to use torch.utils.benchmark.CallgrindStats.as_standardized, give an example?",
        "Id": 240,
        "source": "https://pytorch.org/docs/stable/benchmark_utils.html",
        "context": " When comparing two different sets of instruction counts, on stumbling\nblock can be path prefixes. Callgrind includes the full filepath\nwhen reporting a function (as it should). However, this can cause\nissues when diffing profiles. If a key component such as Python\nor PyTorch was built in separate locations in the two profiles, which\ncan result in something resembling:"
    },
    {
        "Answer": ">>> # Save to file\n>>> x = torch.tensor([0, 1, 2, 3, 4])\n>>> torch.save(x, 'tensor.pt')\n>>> # Save to io.BytesIO buffer\n>>> buffer = io.BytesIO()\n>>> torch.save(x, buffer)\n",
        "Question": "How to use torch.save, give an example?",
        "Id": 241,
        "source": "https://pytorch.org/docs/stable/generated/torch.save.html#torch.save",
        "context": " See also:Saving and loading tensors"
    },
    {
        "Answer": ">>> x = torch.tensor([1], requires_grad=True)\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...   y = x * 2\n>>> y.requires_grad\nFalse\n>>> torch.set_grad_enabled(True)\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How to use torch.set_grad_enabled, give an example?",
        "Id": 242,
        "source": "https://pytorch.org/docs/stable/generated/torch.set_grad_enabled.html#torch.set_grad_enabled",
        "context": " This context manager is thread local; it will not affect computation\nin other threads."
    },
    {
        "Answer": ">>> a = [1, 2, 3]\n>>> list(itertools.combinations(a, r=2))\n[(1, 2), (1, 3), (2, 3)]\n>>> list(itertools.combinations(a, r=3))\n[(1, 2, 3)]\n>>> list(itertools.combinations_with_replacement(a, r=2))\n[(1, 1), (1, 2), (1, 3), (2, 2), (2, 3), (3, 3)]\n>>> tensor_a = torch.tensor(a)\n>>> torch.combinations(tensor_a)\ntensor([[1, 2],\n        [1, 3],\n        [2, 3]])\n>>> torch.combinations(tensor_a, r=3)\ntensor([[1, 2, 3]])\n>>> torch.combinations(tensor_a, with_replacement=True)\ntensor([[1, 1],\n        [1, 2],\n        [1, 3],\n        [2, 2],\n        [2, 3],\n        [3, 3]])\n",
        "Question": "How to use torch.combinations, give an example?",
        "Id": 243,
        "source": "https://pytorch.org/docs/stable/generated/torch.combinations.html#torch.combinations",
        "context": " "
    },
    {
        "Answer": ">>> mat = torch.randn(2, 3)\n>>> vec = torch.randn(3)\n>>> torch.mv(mat, vec)\ntensor([ 1.0404, -0.6361])\n",
        "Question": "How to use torch.mv, give an example?",
        "Id": 244,
        "source": "https://pytorch.org/docs/stable/generated/torch.mv.html#torch.mv",
        "context": " Ifinputis a(n\u00d7m)(n \\times m)(n\u00d7m)tensor,vecis a 1-D tensor of\nsizemmm,outwill be 1-D of sizennn."
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[ 0.8177,  1.4878, -0.2491,  0.9130],\n        [-0.7158,  1.1775,  2.0992,  0.4817],\n        [-0.0053,  0.0164, -1.3738, -0.0507],\n        [ 1.9700,  1.1106, -1.0318, -1.0816]])\n>>> torch.amax(a, 1)\ntensor([1.4878, 2.0992, 0.0164, 1.9700])\n",
        "Question": "How to use torch.amax, give an example?",
        "Id": 245,
        "source": "https://pytorch.org/docs/stable/generated/torch.amax.html#torch.amax",
        "context": " Ifkeepdimis``True`, the output tensors are of the same size\nasinputexcept in the dimension(s)dimwhere they are of size 1.\nOtherwise,dim`saresqueezed(see:func:`torch.squeeze), resulting\nin the output tensors having fewer dimension thaninput."
    },
    {
        "Answer": ">>> a = torch.randn(1, 2, 3, 4, 5)\n>>> torch.numel(a)\n120\n>>> a = torch.zeros(4,4)\n>>> torch.numel(a)\n16\n",
        "Question": "How to use torch.numel, give an example?",
        "Id": 246,
        "source": "https://pytorch.org/docs/stable/generated/torch.numel.html#torch.numel",
        "context": " "
    },
    {
        "Answer": ">>> torch.logspace(start=-10, end=10, steps=5)\ntensor([ 1.0000e-10,  1.0000e-05,  1.0000e+00,  1.0000e+05,  1.0000e+10])\n>>> torch.logspace(start=0.1, end=1.0, steps=5)\ntensor([  1.2589,   2.1135,   3.5481,   5.9566,  10.0000])\n>>> torch.logspace(start=0.1, end=1.0, steps=1)\ntensor([1.2589])\n>>> torch.logspace(start=2, end=2, steps=1, base=2)\ntensor([4.0])\n",
        "Question": "How to use torch.logspace, give an example?",
        "Id": 247,
        "source": "https://pytorch.org/docs/stable/generated/torch.logspace.html#torch.logspace",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4).uniform_(1, 2)\n>>> a\ntensor([ 1.3192, 1.9915, 1.9674, 1.7151 ])\n>>> torch.acosh(a)\ntensor([ 0.7791, 1.3120, 1.2979, 1.1341 ])\n",
        "Question": "How to use torch.acosh, give an example?",
        "Id": 248,
        "source": "https://pytorch.org/docs/stable/generated/torch.acosh.html#torch.acosh",
        "context": " "
    },
    {
        "Answer": "$ unzip my_package.pt && tree my_package\nmy_package\n\u251c\u2500\u2500 .data\n\u2502   \u251c\u2500\u2500 94304870911616.storage\n\u2502   \u251c\u2500\u2500 94304900784016.storage\n\u2502   \u251c\u2500\u2500 extern_modules\n\u2502   \u2514\u2500\u2500 version\n\u251c\u2500\u2500 models\n\u2502   \u2514\u2500\u2500 model_1.pkl\n\u2514\u2500\u2500 torchvision\n    \u2514\u2500\u2500 models\n        \u251c\u2500\u2500 resnet.py\n        \u2514\u2500\u2500 utils.py\n~ cd my_package && cat torchvision/models/resnet.py\n...\n",
        "Question": "How to use The container format for atorch.packageis ZIP, so any tools that work with standard ZIP files should\nwork for exploring the contents. Some common ways to interact with ZIP files:, give an example?",
        "Id": 249,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " The container format for atorch.packageis ZIP, so any tools that work with standard ZIP files should\nwork for exploring the contents. Some common ways to interact with ZIP files:"
    },
    {
        "Answer": "from zipfile import ZipFile\nwith ZipFile(\"my_package.pt\") as myzip:\n    file_bytes = myzip.read(\"torchvision/models/resnet.py\")\n    # edit file_bytes in some way\n    myzip.writestr(\"torchvision/models/resnet.py\", new_file_bytes)\n",
        "Question": "How  The container format for atorch.packageis ZIP, so any tools that work with standard ZIP files should\nwork for exploring the contents. Some common ways to interact with ZIP files:, give an example?",
        "Id": 250,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " The container format for atorch.packageis ZIP, so any tools that work with standard ZIP files should\nwork for exploring the contents. Some common ways to interact with ZIP files:"
    },
    {
        "Answer": "# add this to your .vimrc to treat `*.pt` files as zip files\nau BufReadCmd *.pt call zip#Browse(expand(\"<amatch>\"))\n\n~ vi my_package.pt\n",
        "Question": "How  The container format for atorch.packageis ZIP, so any tools that work with standard ZIP files should\nwork for exploring the contents. Some common ways to interact with ZIP files:, give an example?",
        "Id": 251,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " The container format for atorch.packageis ZIP, so any tools that work with standard ZIP files should\nwork for exploring the contents. Some common ways to interact with ZIP files:"
    },
    {
        "Answer": "with PackageExporter('my_package.pt', verbose=False) as pe:\n    pe.save_pickle('models', 'model_1.pkl', mod)\n    # can limit printed items with include/exclude args\n    print(pe.file_structure(include=[\"**/utils.py\", \"**/*.pkl\"], exclude=\"**/*.storages\"))\n\nimporter = PackageImporter('my_package.pt')\nprint(importer.file_structure()) # will print out all files\n",
        "Question": "How to use PackageImporterandPackageExporterprovide afile_structure()method, which will return a printable\nand queryableFolderobject. TheFolderobject is a simple directory structure that you can use to explore the\ncurrent contents of atorch.package.TheFolderobject itself is directly printable and will print out a file tree representation. To filter what is returned,\nuse the glob-styleincludeandexcludefiltering arguments., give an example?",
        "Id": 252,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " TheFolderobject itself is directly printable and will print out a file tree representation. To filter what is returned,\nuse the glob-styleincludeandexcludefiltering arguments."
    },
    {
        "Answer": "# filtered with glob pattern:\n#    include=[\"**/utils.py\", \"**/*.pkl\"], exclude=\"**/*.storages\"\n\u2500\u2500\u2500 my_package.pt\n    \u251c\u2500\u2500 models\n    \u2502   \u2514\u2500\u2500 model_1.pkl\n    \u2514\u2500\u2500 torchvision\n        \u2514\u2500\u2500 models\n            \u2514\u2500\u2500 utils.py\n\n# all files\n\u2500\u2500\u2500 my_package.pt\n    \u251c\u2500\u2500 .data\n    \u2502   \u251c\u2500\u2500 94304870911616.storage\n    \u2502   \u251c\u2500\u2500 94304900784016.storage\n    \u2502   \u251c\u2500\u2500 extern_modules\n    \u2502   \u2514\u2500\u2500 version\n    \u251c\u2500\u2500 models\n    \u2502   \u2514\u2500\u2500 model_1.pkl\n    \u2514\u2500\u2500 torchvision\n        \u2514\u2500\u2500 models\n            \u251c\u2500\u2500 resnet.py\n            \u2514\u2500\u2500 utils.py\n",
        "Question": "How to use TheFolderobject itself is directly printable and will print out a file tree representation. To filter what is returned,\nuse the glob-styleincludeandexcludefiltering arguments.Output:, give an example?",
        "Id": 253,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " TheFolderobject itself is directly printable and will print out a file tree representation. To filter what is returned,\nuse the glob-styleincludeandexcludefiltering arguments.Output:"
    },
    {
        "Answer": "exporter_file_structure = exporter.file_structure()\nfound: bool = exporter_file_structure.has_file(\"package_a/subpackage.py\")\n",
        "Question": "How to use Output:You can also queryFolderobjects with thehas_file()method., give an example?",
        "Id": 254,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Output:You can also queryFolderobjects with thehas_file()method."
    },
    {
        "Answer": "with torch.PackageExporter(\"package.pt\") as exporter:\n    # Pickles the object and saves to `my_resources/tens.pkl` in the archive.\n    exporter.save_pickle(\"my_resources\", \"tensor.pkl\", torch.randn(4))\n    exporter.save_text(\"config_stuff\", \"words.txt\", \"a sample string\")\n    exporter.save_binary(\"raw_data\", \"binary\", my_bytes)\n",
        "Question": "How to use PackageExporterexposes three methods,save_pickle,save_textandsave_binarythat allow you to save\nPython objects, text, and binary data to a package., give an example?",
        "Id": 255,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " PackageExporterexposes three methods,save_pickle,save_textandsave_binarythat allow you to save\nPython objects, text, and binary data to a package."
    },
    {
        "Answer": "importer = torch.PackageImporter(\"package.pt\")\nmy_tensor = importer.load_pickle(\"my_resources\", \"tensor.pkl\")\ntext = importer.load_text(\"config_stuff\", \"words.txt\")\nbinary = importer.load_binary(\"raw_data\", \"binary\")\n",
        "Question": "How to use PackageExporterexposes three methods,save_pickle,save_textandsave_binarythat allow you to save\nPython objects, text, and binary data to a package.PackageImporterexposes complementary methods namedload_pickle,load_textandload_binarythat allow you to load\nPython objects, text and binary data from a package., give an example?",
        "Id": 256,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " PackageImporterexposes complementary methods namedload_pickle,load_textandload_binarythat allow you to load\nPython objects, text and binary data from a package."
    },
    {
        "Answer": "# foo.py [Example of customizing how class Foo is packaged]\nfrom torch.package import PackageExporter, PackageImporter\nimport time\n\n\nclass Foo:\n    def __init__(self, my_string: str):\n        super().__init__()\n        self.my_string = my_string\n        self.time_imported = 0\n        self.time_exported = 0\n\n    def __reduce_package__(self, exporter: PackageExporter):\n        \"\"\"\n        Called by ``torch.package.PackageExporter``'s Pickler's ``persistent_id`` when\n        saving an instance of this object. This method should do the work to save this\n        object inside of the ``torch.package`` archive.\n\n        Returns function w/ arguments to load the object from a\n        ``torch.package.PackageImporter``'s Pickler's ``persistent_load`` function.\n        \"\"\"\n\n        # use this pattern to ensure no naming conflicts with normal dependencies,\n        # anything saved under this module name shouldn't conflict with other\n        # items in the package\n        generated_module_name = f\"foo-generated._{exporter.get_unique_id()}\"\n        exporter.save_text(\n            generated_module_name,\n            \"foo.txt\",\n            self.my_string + \", with exporter modification!\",\n        )\n        time_exported = time.clock_gettime(1)\n\n        # returns de-packaging function w/ arguments to invoke with\n        return (unpackage_foo, (generated_module_name, time_exported,))\n\n\ndef unpackage_foo(\n    importer: PackageImporter, generated_module_name: str, time_exported: float\n) -> Foo:\n    \"\"\"\n    Called by ``torch.package.PackageImporter``'s Pickler's ``persistent_load`` function\n    when depickling a Foo object.\n    Performs work of loading and returning a Foo instance from a ``torch.package`` archive.\n    \"\"\"\n    time_imported = time.clock_gettime(1)\n    foo = Foo(importer.load_text(generated_module_name, \"foo.txt\"))\n    foo.time_imported = time_imported\n    foo.time_exported = time_exported\n    return foo\n",
        "Question": "How to use torch.packageallows for the customization of how classes are packaged. This behavior is accessed through defining the method__reduce_package__on a class and by defining a corresponding de-packaging function. This is similar to defining__reduce__for\nPython\u2019s normal pickling process.Steps:, give an example?",
        "Id": 257,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Steps:"
    },
    {
        "Answer": "# example of saving instances of class Foo\n\nimport torch\nfrom torch.package import PackageImporter, PackageExporter\nimport foo\n\nfoo_1 = foo.Foo(\"foo_1 initial string\")\nfoo_2 = foo.Foo(\"foo_2 initial string\")\nwith PackageExporter('foo_package.pt', verbose=False) as pe:\n    # save as normal, no extra work necessary\n    pe.save_pickle('foo_collection', 'foo1.pkl', foo_1)\n    pe.save_pickle('foo_collection', 'foo2.pkl', foo_2)\n    print(pe.file_structure())\n\npi = PackageImporter('foo_package.pt')\nimported_foo = pi.load_pickle('foo_collection', 'foo1.pkl')\nprint(f\"foo_1 string: '{imported_foo.my_string}'\")\nprint(f\"foo_1 export time: {imported_foo.time_exported}\")\nprint(f\"foo_1 import time: {imported_foo.time_imported}\")\n",
        "Question": "How  Steps:, give an example?",
        "Id": 258,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Steps:"
    },
    {
        "Answer": "# output of running above script\n\u2500\u2500\u2500 foo_package\n    \u251c\u2500\u2500 foo-generated\n    \u2502   \u251c\u2500\u2500 _0\n    \u2502   \u2502   \u2514\u2500\u2500 foo.txt\n    \u2502   \u2514\u2500\u2500 _1\n    \u2502       \u2514\u2500\u2500 foo.txt\n    \u251c\u2500\u2500 foo_collection\n    \u2502   \u251c\u2500\u2500 foo1.pkl\n    \u2502   \u2514\u2500\u2500 foo2.pkl\n    \u2514\u2500\u2500 foo.py\n\nfoo_1 string: 'foo_1 initial string, with reduction modification!'\nfoo_1 export time: 9857706.650140837\nfoo_1 import time: 9857706.652698385\n",
        "Question": "How  Steps:, give an example?",
        "Id": 259,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Steps:"
    },
    {
        "Answer": "# In foo/bar.py:\n\nif \"__torch_package__\" in dir():  # true if the code is being loaded from a package\n    def is_in_package():\n        return True\n\n    UserException = Exception\nelse:\n    def is_in_package():\n        return False\n\n    UserException = UnpackageableException\n",
        "Question": "How to use APackageImporterwill add the attribute__torch_package__to every module that it initializes. Your code can check for the\npresence of this attribute to determine whether it is executing in a packaged context or not., give an example?",
        "Id": 260,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " APackageImporterwill add the attribute__torch_package__to every module that it initializes. Your code can check for the\npresence of this attribute to determine whether it is executing in a packaged context or not."
    },
    {
        "Answer": "from foo.bar import is_in_package\n\nprint(is_in_package())  # False\n\nloaded_module = PackageImporter(my_pacakge).import_module(\"foo.bar\")\nloaded_module.is_in_package()  # True\n",
        "Question": "How to use APackageImporterwill add the attribute__torch_package__to every module that it initializes. Your code can check for the\npresence of this attribute to determine whether it is executing in a packaged context or not.Now, the code will behave differently depending on whether it\u2019s imported normally through your Python environment or imported from atorch.package., give an example?",
        "Id": 261,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Now, the code will behave differently depending on whether it\u2019s imported normally through your Python environment or imported from atorch.package."
    },
    {
        "Answer": "with PackageExporter(f) as exporter:\n    # Save the my_module.foo available in your current Python environment.\n    exporter.save_module(\"my_module.foo\")\n\n    # This saves the provided string to my_module/foo.py in the package archive.\n    # It will override the my_module.foo that was previously saved.\n    exporter.save_source_string(\"my_module.foo\", textwrap.dedent(\n        \"\"\"\\\n        def my_function():\n            print('hello world')\n        \"\"\"\n    ))\n\n    # If you want to treat my_module.bar as a package\n    # (e.g. save to `my_module/bar/__init__.py` instead of `my_module/bar.py)\n    # pass is_package=True,\n    exporter.save_source_string(\"my_module.bar\",\n                                \"def foo(): print('hello')\\n\",\n                                is_package=True)\n\nimporter = PackageImporter(f)\nimporter.import_module(\"my_module.foo\").my_function()  # prints 'hello world'\n",
        "Question": "How to use PackageExporteroffers asave_source_string()method that allows one to save arbitrary Python source code to a module of your choosing., give an example?",
        "Id": 262,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " PackageExporteroffers asave_source_string()method that allows one to save arbitrary Python source code to a module of your choosing."
    },
    {
        "Answer": "with PackageExporter(f) as exporter:\n    # saves text to one/a.txt in the archive\n    exporter.save_text(\"my_resource\", \"a.txt\", \"hello world!\")\n    # saves the tensor to my_pickle/obj.pkl\n    exporter.save_pickle(\"my_pickle\", \"obj.pkl\", torch.ones(2, 2))\n\n    # see below for module contents\n    exporter.save_module(\"foo\")\n    exporter.save_module(\"bar\")\n",
        "Question": "How to use PackageImporterimplements theimportlib.resourcesAPI for accessing resources from inside a package., give an example?",
        "Id": 263,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " PackageImporterimplements theimportlib.resourcesAPI for accessing resources from inside a package."
    },
    {
        "Answer": "# foo.py:\nimport importlib.resources\nimport my_resource\n\n# returns \"hello world!\"\ndef get_my_resource():\n    return importlib.resources.read_text(my_resource, \"a.txt\")\n",
        "Question": "How to use PackageImporterimplements theimportlib.resourcesAPI for accessing resources from inside a package.Theimportlib.resourcesAPI allows access to resources from within packaged code., give an example?",
        "Id": 264,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Theimportlib.resourcesAPI allows access to resources from within packaged code."
    },
    {
        "Answer": "# bar.py:\nimport torch_package_importer # this is the PackageImporter that imported this module.\n\n# Prints \"hello world!\", equivalient to importlib.resources.read_text\ndef get_my_resource():\n    return torch_package_importer.load_text(\"my_resource\", \"a.txt\")\n\n# You also do things that the importlib.resources API does not support, like loading\n# a pickled object from the package.\ndef get_my_pickle():\n    return torch_package_importer.load_pickle(\"my_pickle\", \"obj.pkl\")\n",
        "Question": "How to use Theimportlib.resourcesAPI allows access to resources from within packaged code.Usingimportlib.resourcesis the recommended way to access package contents from within packaged code, since it complies\nwith the Python standard. However, it is also possible to access the parentPackageImporterinstance itself from within\npackaged code., give an example?",
        "Id": 265,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Theimportlib.resourcesAPI allows access to resources from within packaged code.Usingimportlib.resourcesis the recommended way to access package contents from within packaged code, since it complies\nwith the Python standard. However, it is also possible to access the parentPackageImporterinstance itself from within\npackaged code."
    },
    {
        "Answer": "importer = PackageImporter(f)\nmod = importer.import_module('foo')\nobj = importer.load_pickle('model', 'model.pkl')\ntxt = importer.load_text('text', 'my_test.txt')\n\nassert is_from_package(mod)\nassert is_from_package(obj)\nassert not is_from_package(txt) # str is from stdlib, so this will return False\n",
        "Question": "How to use To tell if an object\u2019s code is from atorch.package, use thetorch.package.is_from_package()function.\nNote: if an object is from a package but its definition is from a module markedexternor fromstdlib,\nthis check will returnFalse., give an example?",
        "Id": 266,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " To tell if an object\u2019s code is from atorch.package, use thetorch.package.is_from_package()function.\nNote: if an object is from a package but its definition is from a module markedexternor fromstdlib,\nthis check will returnFalse."
    },
    {
        "Answer": "importer = PackageImporter(f)\nobj = importer.load_pickle(\"model\", \"model.pkl\")\n\n# re-export obj in a new package\nwith PackageExporter(f2, importer=(importer, sys_importer)) as exporter:\n    exporter.save_pickle(\"model\", \"model.pkl\", obj)\n",
        "Question": "How to use To re-export an object that was previously imported by aPackageImporter, you must make the newPackageExporteraware of the originalPackageImporterso that it can find source code for your object\u2019s dependencies., give an example?",
        "Id": 267,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " To re-export an object that was previously imported by aPackageImporter, you must make the newPackageExporteraware of the originalPackageImporterso that it can find source code for your object\u2019s dependencies."
    },
    {
        "Answer": "# save TorchScript just like any other object\nwith PackageExporter(file_name, verbose=True) as e:\n    e.save_pickle(\"res\", \"script_model.pkl\", scripted_model)\n    e.save_pickle(\"res\", \"mixed_model.pkl\", python_model_with_scripted_submodule)\n# load as normal\nimporter = PackageImporter(file_name)\nloaded_script = importer.load_pickle(\"res\", \"script_model.pkl\")\nloaded_mixed = importer.load_pickle(\"res\", \"mixed_model.pkl\"\n",
        "Question": "How to use To package a TorchScript model, use the samesave_pickleandload_pickleAPIs as you would with any other object.\nSaving TorchScript objects that are attributes or submodules is supported as well with no extra work., give an example?",
        "Id": 268,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " To package a TorchScript model, use the samesave_pickleandload_pickleAPIs as you would with any other object.\nSaving TorchScript objects that are attributes or submodules is supported as well with no extra work."
    },
    {
        "Answer": "resnet\n\u251c\u2500\u2500 .data  # All framework-specific data is stored here.\n\u2502   \u2502      # It's named to avoid conflicts with user-serialized code.\n\u2502   \u251c\u2500\u2500 94286146172688.storage  # tensor data\n\u2502   \u251c\u2500\u2500 94286146172784.storage\n\u2502   \u251c\u2500\u2500 extern_modules  # text file with names of extern modules (e.g. 'torch')\n\u2502   \u251c\u2500\u2500 version         # version metadata\n\u2502   \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 model  # the pickled model\n\u2502   \u2514\u2500\u2500 model.pkl\n\u2514\u2500\u2500 torchvision  # all code dependencies are captured as source files\n    \u2514\u2500\u2500 models\n        \u251c\u2500\u2500 resnet.py\n        \u2514\u2500\u2500 utils.py\n",
        "Question": "How to use Atorch.packagefile is a ZIP archive which conventionally uses the.ptextension. Inside the ZIP archive, there are two kinds of files:As an example, this is what a fully packaged ResNet model fromtorchvisionlooks like:, give an example?",
        "Id": 269,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " As an example, this is what a fully packaged ResNet model fromtorchvisionlooks like:"
    },
    {
        "Answer": ".data\n\u251c\u2500\u2500 94286146172688.storage\n\u251c\u2500\u2500 94286146172784.storage\n\u251c\u2500\u2500 extern_modules\n\u251c\u2500\u2500 version\n\u251c\u2500\u2500 ...\n",
        "Question": "How to use The.data/directory is owned by torch.package, and its contents are considered to be a private implementation detail.\nThetorch.packageformat makes no guarantees about the contents of.data/, but any changes made will be backward compatible\n(that is, newer version of PyTorch will always be able to load oldertorch.packages).Currently, the.data/directory contains the following items:, give an example?",
        "Id": 270,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Currently, the.data/directory contains the following items:"
    },
    {
        "Answer": "<package root>\n\u251c\u2500\u2500 model  # the pickled model\n\u2502   \u2514\u2500\u2500 model.pkl\n\u251c\u2500\u2500 another_package\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 foo.txt         # a resource file , see importlib.resources\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 torchvision\n    \u2514\u2500\u2500 models\n        \u251c\u2500\u2500 resnet.py   # torchvision.models.resnet\n        \u2514\u2500\u2500 utils.py    # torchvision.models.utils\n",
        "Question": "How to use All other files in the archive were put there by a user. The layout is identical to a Pythonregular package. For a deeper dive in how Python packaging works,\nplease consultthis essay(it\u2019s slightly out of date, so double-check implementation details\nwith thePython reference documentation)., give an example?",
        "Id": 271,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " All other files in the archive were put there by a user. The layout is identical to a Pythonregular package. For a deeper dive in how Python packaging works,\nplease consultthis essay(it\u2019s slightly out of date, so double-check implementation details\nwith thePython reference documentation)."
    },
    {
        "Answer": "GLOBAL 'torchvision.models.resnet Resnet`\n",
        "Question": "How to use When you issue asave_pickle(obj,...)call,PackageExporterwill pickle the object normally. Then, it uses thepickletoolsstandard library module to parse the pickle bytecode.In a pickle, an object is saved along with aGLOBALopcode that describes where to find the implementation of the object\u2019s type, like:, give an example?",
        "Id": 272,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " In a pickle, an object is saved along with aGLOBALopcode that describes where to find the implementation of the object\u2019s type, like:"
    },
    {
        "Answer": "my_exporter.intern(\"torchvision.**\")\nmy_exporter.extern(\"numpy\")\n",
        "Question": "How to use Note that actions are only defined on entire Python modules. There is no way to package \u201cjust\u201d a function or class from module and leave the rest out.\nThis is by design. Python does not offer clean boundaries between objects defined in a module. The only defined unit of dependency organization is a\nmodule, so that\u2019s whattorch.packageuses.Actions are applied to modules using patterns. Patterns can either be module names (\"foo.bar\") or globs (like\"foo.**\"). You associate a pattern\nwith an action using methods onPackageImporter, e.g., give an example?",
        "Id": 273,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Note that actions are only defined on entire Python modules. There is no way to package \u201cjust\u201d a function or class from module and leave the rest out.\nThis is by design. Python does not offer clean boundaries between objects defined in a module. The only defined unit of dependency organization is a\nmodule, so that\u2019s whattorch.packageuses.Actions are applied to modules using patterns. Patterns can either be module names (\"foo.bar\") or globs (like\"foo.**\"). You associate a pattern\nwith an action using methods onPackageImporter, e.g."
    },
    {
        "Answer": "exporter.intern([\"torchvision.models.**\", \"torchvision.utils.**\"])\n",
        "Question": "How to use When specifying actions, you can pass multiple patterns, e.g., give an example?",
        "Id": 274,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " When specifying actions, you can pass multiple patterns, e.g."
    },
    {
        "Answer": "exporter.mock(\"**\", exclude=[\"torchvision.**\"])\n",
        "Question": "How to use A module will match against this action if it matches any of the patterns.You can also specify patterns to exlcude, e.g., give an example?",
        "Id": 275,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " A module will match against this action if it matches any of the patterns.You can also specify patterns to exlcude, e.g."
    },
    {
        "Answer": "from foo import MyClass\n\nmy_class_instance = MyClass()\n\nwith PackageExporter(f) as exporter:\n    exporter.save_module(\"foo\")\n\nimporter = PackageImporter(f)\nimported_MyClass = importer.import_module(\"foo\").MyClass\n\nassert isinstance(my_class_instance, MyClass)  # works\nassert isinstance(my_class_instance, imported_MyClass)  # ERROR!\n",
        "Question": "How to use Any class that you import from aPackageImporterwill be a version of the class specific to that importer. For example:, give an example?",
        "Id": 276,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Any class that you import from aPackageImporterwill be a version of the class specific to that importer. For example:"
    },
    {
        "Answer": "print(MyClass.__name__)  # prints \"foo.MyClass\"\nprint(imported_MyClass.__name__)  # prints <torch_package_0>.foo.MyClass\n",
        "Question": "How to use In this example,MyClassandimport_MyClassarenot the same type. In this specific example,MyClassandimport_MyClasshave exactly the\nsame implementation, so you might thing it\u2019s okay to consider them the same class. But consider the situation whereimport_MyClassis coming from an\nolder package with an entirely different implementation ofMyClass\u2014 in that case, it\u2019s unsafe to consider them the same class.Under the hood, each importer has a prefix that allows it to uniquely identify classes:, give an example?",
        "Id": 277,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " In this example,MyClassandimport_MyClassarenot the same type. In this specific example,MyClassandimport_MyClasshave exactly the\nsame implementation, so you might thing it\u2019s okay to consider them the same class. But consider the situation whereimport_MyClassis coming from an\nolder package with an entirely different implementation ofMyClass\u2014 in that case, it\u2019s unsafe to consider them the same class.Under the hood, each importer has a prefix that allows it to uniquely identify classes:"
    },
    {
        "Answer": "with PackageExporter(\"file.zip\") as e:\n    ...\n",
        "Question": "How to use torch.package.PackageExporter.close, give an example?",
        "Id": 278,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Write the package to the filesystem. Any calls afterclose()are now invalid.\nIt is preferable to use resource guard syntax instead:"
    },
    {
        "Answer": "hook(exporter: PackageExporter, module_name: str) -> None\n",
        "Question": "How to use torch.package.PackageExporter.register_extern_hook, give an example?",
        "Id": 279,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " The hook will be called each time a module matches against anextern()pattern.\nIt should have the following signature:"
    },
    {
        "Answer": "hook(exporter: PackageExporter, module_name: str) -> None\n",
        "Question": "How to use torch.package.PackageExporter.register_intern_hook, give an example?",
        "Id": 280,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " The hook will be called each time a module matches against anintern()pattern.\nIt should have the following signature:"
    },
    {
        "Answer": "hook(exporter: PackageExporter, module_name: str) -> None\n",
        "Question": "How to use torch.package.PackageExporter.register_mock_hook, give an example?",
        "Id": 281,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " The hook will be called each time a module matches against amock()pattern.\nIt should have the following signature:"
    },
    {
        "Answer": "<torch_package_0>\n",
        "Question": "How to use torch.package.PackageImporter.id, give an example?",
        "Id": 282,
        "source": "https://pytorch.org/docs/stable/package.html",
        "context": " Returns internal identifier that torch.package uses to distinguishPackageImporterinstances.\nLooks like:"
    },
    {
        "Answer": ">>> a = torch.randn(10)\n>>> a\ntensor([-0.8286, -0.4890,  0.5155,  0.8443,  0.1865, -0.1752, -2.0595,\n         0.1850, -1.1571, -0.4243])\n>>> torch.cumsum(a, dim=0)\ntensor([-0.8286, -1.3175, -0.8020,  0.0423,  0.2289,  0.0537, -2.0058,\n        -1.8209, -2.9780, -3.4022])\n",
        "Question": "How to use torch.cumsum, give an example?",
        "Id": 283,
        "source": "https://pytorch.org/docs/stable/generated/torch.cumsum.html#torch.cumsum",
        "context": " For example, ifinputis a vector of size N, the result will also be\na vector of size N, with elements."
    },
    {
        "Answer": "matrix_power(torch.linalg.solve(A, B), n) == matrix_power(A, -n)  @ B\n",
        "Question": "How to use torch.linalg.matrix_power, give an example?",
        "Id": 284,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power",
        "context": " Consider usingtorch.linalg.solve()if possible for multiplying a matrix on the left by\na negative power as, ifn> 0:"
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a\ntensor([[-0.2270,  0.6663, -1.3515],\n        [-0.9838, -0.4002, -1.9313],\n        [-0.7886, -0.0450,  0.0528]])\n>>> torch.linalg.matrix_power(a, 0)\ntensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]])\n>>> torch.linalg.matrix_power(a, 3)\ntensor([[ 1.0756,  0.4980,  0.0100],\n        [-1.6617,  1.4994, -1.9980],\n        [-0.4509,  0.2731,  0.8001]])\n>>> torch.linalg.matrix_power(a.expand(2, -1, -1), -2)\ntensor([[[ 0.2640,  0.4571, -0.5511],\n        [-1.0163,  0.3491, -1.5292],\n        [-0.4899,  0.0822,  0.2773]],\n        [[ 0.2640,  0.4571, -0.5511],\n        [-1.0163,  0.3491, -1.5292],\n        [-0.4899,  0.0822,  0.2773]]])\n",
        "Question": "How  Ifn= 0, it returns the identity matrix (or batch) of the same shape\nasA. Ifnis negative, it returns the inverse of each matrix\n(if invertible) raised to the power ofabs(n)., give an example?",
        "Id": 285,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.matrix_power.html#torch.linalg.matrix_power",
        "context": " Ifn= 0, it returns the identity matrix (or batch) of the same shape\nasA. Ifnis negative, it returns the inverse of each matrix\n(if invertible) raised to the power ofabs(n)."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 286,
        "source": "https://pytorch.org/docs/stable/torch.html#quasi-random-sampling",
        "context": " "
    },
    {
        "Answer": "with torch.profiler.profile(\n    activities=[\n        torch.profiler.ProfilerActivity.CPU,\n        torch.profiler.ProfilerActivity.CUDA,\n    ]\n) as p:\n    code_to_profile()\nprint(p.key_averages().table(\n    sort_by=\"self_cuda_time_total\", row_limit=-1))\n",
        "Question": "How to use torch.profiler.profile, give an example?",
        "Id": 287,
        "source": "https://pytorch.org/docs/stable/profiler.html",
        "context": " "
    },
    {
        "Answer": "# Non-default profiler schedule allows user to turn profiler on and off\n# on different iterations of the training loop;\n# trace_handler is called every time a new trace becomes available\ndef trace_handler(prof):\n    print(prof.key_averages().table(\n        sort_by=\"self_cuda_time_total\", row_limit=-1))\n    # prof.export_chrome_trace(\"/tmp/test_trace_\" + str(prof.step_num) + \".json\")\n\nwith torch.profiler.profile(\n    activities=[\n        torch.profiler.ProfilerActivity.CPU,\n        torch.profiler.ProfilerActivity.CUDA,\n    ],\n\n    # In this example with wait=1, warmup=1, active=2,\n    # profiler will skip the first step/iteration,\n    # start warming up on the second, record\n    # the third and the forth iterations,\n    # after which the trace will become available\n    # and on_trace_ready (when set) is called;\n    # the cycle repeats starting with the next step\n\n    schedule=torch.profiler.schedule(\n        wait=1,\n        warmup=1,\n        active=2),\n    on_trace_ready=trace_handler\n    # on_trace_ready=torch.profiler.tensorboard_trace_handler('./log')\n    # used when outputting for tensorboard\n    ) as p:\n        for iter in range(N):\n            code_iteration_to_profile(iter)\n            # send a signal to the profiler that the next iteration has started\n            p.step()\n",
        "Question": "How to use Using the profiler\u2019sschedule,on_trace_readyandstepfunctions:, give an example?",
        "Id": 288,
        "source": "https://pytorch.org/docs/stable/profiler.html",
        "context": " Using the profiler\u2019sschedule,on_trace_readyandstepfunctions:"
    },
    {
        "Answer": ">>> output = torch.unique(torch.tensor([1, 3, 2, 3], dtype=torch.long))\n>>> output\ntensor([ 2,  3,  1])\n\n>>> output, inverse_indices = torch.unique(\n...     torch.tensor([1, 3, 2, 3], dtype=torch.long), sorted=True, return_inverse=True)\n>>> output\ntensor([ 1,  2,  3])\n>>> inverse_indices\ntensor([ 0,  2,  1,  2])\n\n>>> output, inverse_indices = torch.unique(\n...     torch.tensor([[1, 3], [2, 3]], dtype=torch.long), sorted=True, return_inverse=True)\n>>> output\ntensor([ 1,  2,  3])\n>>> inverse_indices\ntensor([[ 0,  2],\n        [ 1,  2]])\n",
        "Question": "How to use torch.unique, give an example?",
        "Id": 289,
        "source": "https://pytorch.org/docs/stable/generated/torch.unique.html#torch.unique",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-0.5962,  1.4985, -0.4396,  1.4525])\n>>> torch.asin(a)\ntensor([-0.6387,     nan, -0.4552,     nan])\n",
        "Question": "How to use torch.asin, give an example?",
        "Id": 290,
        "source": "https://pytorch.org/docs/stable/generated/torch.asin.html#torch.asin",
        "context": " "
    },
    {
        "Answer": "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\noptimizer = optim.Adam([var1, var2], lr=0.0001)\n",
        "Question": "How to use To construct anOptimizeryou have to give it an iterable containing the\nparameters (all should beVariables) to optimize. Then,\nyou can specify optimizer-specific options such as the learning rate, weight decay, etc., give an example?",
        "Id": 291,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " "
    },
    {
        "Answer": "optim.SGD([\n                {'params': model.base.parameters()},\n                {'params': model.classifier.parameters(), 'lr': 1e-3}\n            ], lr=1e-2, momentum=0.9)\n",
        "Question": "How to use Optimizers also support specifying per-parameter options. To do this, instead\nof passing an iterable ofVariables, pass in an iterable ofdicts. Each of them will define a separate parameter group, and should contain\naparamskey, containing a list of parameters belonging to it. Other keys\nshould match the keyword arguments accepted by the optimizers, and will be used\nas optimization options for this group.For example, this is very useful when one wants to specify per-layer learning rates:, give an example?",
        "Id": 292,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " For example, this is very useful when one wants to specify per-layer learning rates:"
    },
    {
        "Answer": "for input, target in dataset:\n    optimizer.zero_grad()\n    output = model(input)\n    loss = loss_fn(output, target)\n    loss.backward()\n    optimizer.step()\n",
        "Question": "How to use This is a simplified version supported by most optimizers. The function can be\ncalled once the gradients are computed using e.g.backward()., give an example?",
        "Id": 293,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " "
    },
    {
        "Answer": "for input, target in dataset:\n    def closure():\n        optimizer.zero_grad()\n        output = model(input)\n        loss = loss_fn(output, target)\n        loss.backward()\n        return loss\n    optimizer.step(closure)\n",
        "Question": "How to use Some optimization algorithms such as Conjugate Gradient and LBFGS need to\nreevaluate the function multiple times, so you have to pass in a closure that\nallows them to recompute your model. The closure should clear the gradients,\ncompute the loss, and return it., give an example?",
        "Id": 294,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " "
    },
    {
        "Answer": "model = [Parameter(torch.randn(2, 2, requires_grad=True))]\noptimizer = SGD(model, 0.1)\nscheduler = ExponentialLR(optimizer, gamma=0.9)\n\nfor epoch in range(20):\n    for input, target in dataset:\n        optimizer.zero_grad()\n        output = model(input)\n        loss = loss_fn(output, target)\n        loss.backward()\n        optimizer.step()\n    scheduler.step()\n",
        "Question": "How to use Learning rate scheduling should be applied after optimizer\u2019s update; e.g., you\nshould write your code this way:, give an example?",
        "Id": 295,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " Learning rate scheduling should be applied after optimizer\u2019s update; e.g., you\nshould write your code this way:"
    },
    {
        "Answer": "model = [Parameter(torch.randn(2, 2, requires_grad=True))]\noptimizer = SGD(model, 0.1)\nscheduler1 = ExponentialLR(optimizer, gamma=0.9)\nscheduler2 = MultiStepLR(optimizer, milestones=[30,80], gamma=0.1)\n\nfor epoch in range(20):\n    for input, target in dataset:\n        optimizer.zero_grad()\n        output = model(input)\n        loss = loss_fn(output, target)\n        loss.backward()\n        optimizer.step()\n    scheduler1.step()\n    scheduler2.step()\n",
        "Question": "How to use Most learning rate schedulers can be called back-to-back (also referred to as\nchaining schedulers). The result is that each scheduler is applied one after the\nother on the learning rate obtained by the one preceding it., give an example?",
        "Id": 296,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " Most learning rate schedulers can be called back-to-back (also referred to as\nchaining schedulers). The result is that each scheduler is applied one after the\nother on the learning rate obtained by the one preceding it."
    },
    {
        "Answer": ">>> scheduler = ...\n>>> for epoch in range(100):\n>>>     train(...)\n>>>     validate(...)\n>>>     scheduler.step()\n",
        "Question": "How to use In many places in the documentation, we will use the following template to refer to schedulers\nalgorithms., give an example?",
        "Id": 297,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " In many places in the documentation, we will use the following template to refer to schedulers\nalgorithms."
    },
    {
        "Answer": ">>> swa_model = AveragedModel(model)\n",
        "Question": "How to use AveragedModelclass serves to compute the weights of the SWA model. You can create an\naveraged model by running:, give an example?",
        "Id": 298,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " AveragedModelclass serves to compute the weights of the SWA model. You can create an\naveraged model by running:"
    },
    {
        "Answer": ">>> swa_model.update_parameters(model)\n",
        "Question": "How to use AveragedModelclass serves to compute the weights of the SWA model. You can create an\naveraged model by running:Here the modelmodelcan be an arbitrarytorch.nn.Moduleobject.swa_modelwill keep track of the running averages of the parameters of themodel. To update these\naverages, you can use theupdate_parameters()function:, give an example?",
        "Id": 299,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " Here the modelmodelcan be an arbitrarytorch.nn.Moduleobject.swa_modelwill keep track of the running averages of the parameters of themodel. To update these\naverages, you can use theupdate_parameters()function:"
    },
    {
        "Answer": ">>> swa_scheduler = torch.optim.swa_utils.SWALR(optimizer, \\\n>>>         anneal_strategy=\"linear\", anneal_epochs=5, swa_lr=0.05)\n",
        "Question": "How to use Typically, in SWA the learning rate is set to a high constant value.SWALRis a\nlearning rate scheduler that anneals the learning rate to a fixed value, and then keeps it\nconstant. For example, the following code creates a scheduler that linearly anneals the\nlearning rate from its initial value to 0.05 in 5 epochs within each parameter group:, give an example?",
        "Id": 300,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " Typically, in SWA the learning rate is set to a high constant value.SWALRis a\nlearning rate scheduler that anneals the learning rate to a fixed value, and then keeps it\nconstant. For example, the following code creates a scheduler that linearly anneals the\nlearning rate from its initial value to 0.05 in 5 epochs within each parameter group:"
    },
    {
        "Answer": ">>> torch.optim.swa_utils.update_bn(loader, swa_model)\n",
        "Question": "How to use update_bn()is a utility function that allows to compute the batchnorm statistics for the SWA model\non a given dataloaderloaderat the end of training:, give an example?",
        "Id": 301,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " update_bn()is a utility function that allows to compute the batchnorm statistics for the SWA model\non a given dataloaderloaderat the end of training:"
    },
    {
        "Answer": ">>> ema_avg = lambda averaged_model_parameter, model_parameter, num_averaged:\\\n>>>         0.1 * averaged_model_parameter + 0.9 * model_parameter\n>>> ema_model = torch.optim.swa_utils.AveragedModel(model, avg_fn=ema_avg)\n",
        "Question": "How to use By default,torch.optim.swa_utils.AveragedModelcomputes a running equal average of\nthe parameters that you provide, but you can also use custom averaging functions with theavg_fnparameter. In the following exampleema_modelcomputes an exponential moving average., give an example?",
        "Id": 302,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " "
    },
    {
        "Answer": ">>> loader, optimizer, model, loss_fn = ...\n>>> swa_model = torch.optim.swa_utils.AveragedModel(model)\n>>> scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=300)\n>>> swa_start = 160\n>>> swa_scheduler = SWALR(optimizer, swa_lr=0.05)\n>>>\n>>> for epoch in range(300):\n>>>       for input, target in loader:\n>>>           optimizer.zero_grad()\n>>>           loss_fn(model(input), target).backward()\n>>>           optimizer.step()\n>>>       if epoch > swa_start:\n>>>           swa_model.update_parameters(model)\n>>>           swa_scheduler.step()\n>>>       else:\n>>>           scheduler.step()\n>>>\n>>> # Update bn statistics for the swa_model at the end\n>>> torch.optim.swa_utils.update_bn(loader, swa_model)\n>>> # Use swa_model to make predictions on test data\n>>> preds = swa_model(test_input)\n",
        "Question": "How to use In the example below,swa_modelis the SWA model that accumulates the averages of the weights.\nWe train the model for a total of 300 epochs and we switch to the SWA learning rate schedule\nand start to collect SWA averages of the parameters at epoch 160:, give an example?",
        "Id": 303,
        "source": "https://pytorch.org/docs/stable/optim.html",
        "context": " In the example below,swa_modelis the SWA model that accumulates the averages of the weights.\nWe train the model for a total of 300 epochs and we switch to the SWA learning rate schedule\nand start to collect SWA averages of the parameters at epoch 160:"
    },
    {
        "Answer": ">>> t = torch.tensor([float('nan'), 1, 2])\n>>> t.quantile(0.5)\ntensor(nan)\n>>> t.nanquantile(0.5)\ntensor(1.5000)\n>>> t = torch.tensor([[float('nan'), float('nan')], [1, 2]])\n>>> t\ntensor([[nan, nan],\n        [1., 2.]])\n>>> t.nanquantile(0.5, dim=0)\ntensor([1., 2.])\n>>> t.nanquantile(0.5, dim=1)\ntensor([   nan, 1.5000])\n",
        "Question": "How to use torch.nanquantile, give an example?",
        "Id": 304,
        "source": "https://pytorch.org/docs/stable/generated/torch.nanquantile.html#torch.nanquantile",
        "context": " "
    },
    {
        "Answer": "UPLO = \"U\" if upper else \"L\"\nL = torch.linalg.eigvalsh(A, UPLO=UPLO)\n",
        "Question": "How to use torch.symeig, give an example?",
        "Id": 305,
        "source": "https://pytorch.org/docs/stable/generated/torch.symeig.html#torch.symeig",
        "context": " torch.symeig()is deprecated in favor oftorch.linalg.eigh()and will be removed in a future PyTorch release. The default behavior has changed\nfrom using the upper triangular portion of the matrix by default to using the\nlower triangular portion.L,_=torch.symeig(A,upper=upper)should be replaced with"
    },
    {
        "Answer": "UPLO = \"U\" if upper else \"L\"\nL, V = torch.linalg.eigh(A, UPLO=UPLO)\n",
        "Question": "How  L,_=torch.symeig(A,upper=upper)should be replaced withL,V=torch.symeig(A,eigenvectors=True,upper=upper)should be replaced with, give an example?",
        "Id": 306,
        "source": "https://pytorch.org/docs/stable/generated/torch.symeig.html#torch.symeig",
        "context": " L,_=torch.symeig(A,upper=upper)should be replaced withL,V=torch.symeig(A,eigenvectors=True,upper=upper)should be replaced with"
    },
    {
        "Answer": ">>> a = torch.randn(5, 5)\n>>> a = a + a.t()  # To make a symmetric\n>>> a\ntensor([[-5.7827,  4.4559, -0.2344, -1.7123, -1.8330],\n        [ 4.4559,  1.4250, -2.8636, -3.2100, -0.1798],\n        [-0.2344, -2.8636,  1.7112, -5.5785,  7.1988],\n        [-1.7123, -3.2100, -5.5785, -2.6227,  3.1036],\n        [-1.8330, -0.1798,  7.1988,  3.1036, -5.1453]])\n>>> e, v = torch.symeig(a, eigenvectors=True)\n>>> e\ntensor([-13.7012,  -7.7497,  -2.3163,   5.2477,   8.1050])\n>>> v\ntensor([[ 0.1643,  0.9034, -0.0291,  0.3508,  0.1817],\n        [-0.2417, -0.3071, -0.5081,  0.6534,  0.4026],\n        [-0.5176,  0.1223, -0.0220,  0.3295, -0.7798],\n        [-0.4850,  0.2695, -0.5773, -0.5840,  0.1337],\n        [ 0.6415, -0.0447, -0.6381, -0.0193, -0.4230]])\n>>> a_big = torch.randn(5, 2, 2)\n>>> a_big = a_big + a_big.transpose(-2, -1)  # To make a_big symmetric\n>>> e, v = a_big.symeig(eigenvectors=True)\n>>> torch.allclose(torch.matmul(v, torch.matmul(e.diag_embed(), v.transpose(-2, -1))), a_big)\nTrue\n",
        "Question": "How  IfupperisFalse, then lower triangular portion is used., give an example?",
        "Id": 307,
        "source": "https://pytorch.org/docs/stable/generated/torch.symeig.html#torch.symeig",
        "context": " IfupperisFalse, then lower triangular portion is used."
    },
    {
        "Answer": ">>> a = torch.tensor([5, 10, 15])\n>>> b = torch.tensor([3, 4, 5])\n>>> torch.gcd(a, b)\ntensor([1, 2, 5])\n>>> c = torch.tensor([3])\n>>> torch.gcd(a, c)\ntensor([1, 1, 3])\n",
        "Question": "How to use torch.gcd, give an example?",
        "Id": 308,
        "source": "https://pytorch.org/docs/stable/generated/torch.gcd.html#torch.gcd",
        "context": " Bothinputandothermust have integer types."
    },
    {
        "Answer": ">>> a = torch.randn(2, 2, 2)\n>>> a[0, :, :] = torch.eye(2, 2)\n>>> a[1, :, :] = 2 * torch.eye(2, 2)\n>>> a\ntensor([[[1., 0.],\n         [0., 1.]],\n\n        [[2., 0.],\n         [0., 2.]]])\n>>> torch.matrix_exp(a)\ntensor([[[2.7183, 0.0000],\n         [0.0000, 2.7183]],\n\n         [[7.3891, 0.0000],\n          [0.0000, 7.3891]]])\n\n>>> import math\n>>> x = torch.tensor([[0, math.pi/3], [-math.pi/3, 0]])\n>>> x.matrix_exp() # should be [[cos(pi/3), sin(pi/3)], [-sin(pi/3), cos(pi/3)]]\ntensor([[ 0.5000,  0.8660],\n        [-0.8660,  0.5000]])\n",
        "Question": "How to use torch.matrix_exp, give an example?",
        "Id": 309,
        "source": "https://pytorch.org/docs/stable/generated/torch.matrix_exp.html#torch.matrix_exp",
        "context": " Bader, P.; Blanes, S.; Casas, F.\nComputing the Matrix Exponential with an Optimized Taylor Polynomial Approximation.\nMathematics 2019, 7, 1174."
    },
    {
        "Answer": "def entrypoint_name(*args, **kwargs):\n    # args & kwargs are optional, for models which take positional/keyword arguments.\n    ...\n",
        "Question": "How to use Pytorch Hub supports publishing pre-trained models(model definitions and pre-trained weights)\nto a github repository by adding a simplehubconf.pyfile;hubconf.pycan have multiple entrypoints. Each entrypoint is defined as a python function\n(example: a pre-trained model you want to publish)., give an example?",
        "Id": 310,
        "source": "https://pytorch.org/docs/stable/hub.html",
        "context": " hubconf.pycan have multiple entrypoints. Each entrypoint is defined as a python function\n(example: a pre-trained model you want to publish)."
    },
    {
        "Answer": "dependencies = ['torch']\nfrom torchvision.models.resnet import resnet18 as _resnet18\n\n# resnet18 is the name of entrypoint\ndef resnet18(pretrained=False, **kwargs):\n    \"\"\" # This docstring shows up in hub.help()\n    Resnet18 model\n    pretrained (bool): kwargs, load pretrained weights into the model\n    \"\"\"\n    # Call the model, load pretrained weights\n    model = _resnet18(pretrained=pretrained, **kwargs)\n    return model\n",
        "Question": "How to use Here is a code snippet specifies an entrypoint forresnet18model if we expand\nthe implementation inpytorch/vision/hubconf.py.\nIn most case importing the right function inhubconf.pyis sufficient. Here we\njust want to use the expanded version as an example to show how it works.\nYou can see the full script inpytorch/vision repo, give an example?",
        "Id": 311,
        "source": "https://pytorch.org/docs/stable/hub.html",
        "context": " Here is a code snippet specifies an entrypoint forresnet18model if we expand\nthe implementation inpytorch/vision/hubconf.py.\nIn most case importing the right function inhubconf.pyis sufficient. Here we\njust want to use the expanded version as an example to show how it works.\nYou can see the full script inpytorch/vision repo"
    },
    {
        "Answer": "if pretrained:\n    # For checkpoint saved in local github repo, e.g. <RELATIVE_PATH_TO_CHECKPOINT>=weights/save.pth\n    dirname = os.path.dirname(__file__)\n    checkpoint = os.path.join(dirname, <RELATIVE_PATH_TO_CHECKPOINT>)\n    state_dict = torch.load(checkpoint)\n    model.load_state_dict(state_dict)\n\n    # For checkpoint saved elsewhere\n    checkpoint = 'https://download.pytorch.org/models/resnet18-5c106cde.pth'\n    model.load_state_dict(torch.hub.load_state_dict_from_url(checkpoint, progress=False))\n",
        "Question": "How  Here is a code snippet specifies an entrypoint forresnet18model if we expand\nthe implementation inpytorch/vision/hubconf.py.\nIn most case importing the right function inhubconf.pyis sufficient. Here we\njust want to use the expanded version as an example to show how it works.\nYou can see the full script inpytorch/vision repo, give an example?",
        "Id": 312,
        "source": "https://pytorch.org/docs/stable/hub.html",
        "context": " Here is a code snippet specifies an entrypoint forresnet18model if we expand\nthe implementation inpytorch/vision/hubconf.py.\nIn most case importing the right function inhubconf.pyis sufficient. Here we\njust want to use the expanded version as an example to show how it works.\nYou can see the full script inpytorch/vision repo"
    },
    {
        "Answer": ">>> entrypoints = torch.hub.list('pytorch/vision', force_reload=True)\n",
        "Question": "How to use torch.hub.list, give an example?",
        "Id": 313,
        "source": "https://pytorch.org/docs/stable/hub.html",
        "context": " "
    },
    {
        "Answer": ">>> print(torch.hub.help('pytorch/vision', 'resnet18', force_reload=True))\n",
        "Question": "How to use torch.hub.help, give an example?",
        "Id": 314,
        "source": "https://pytorch.org/docs/stable/hub.html",
        "context": " "
    },
    {
        "Answer": ">>> # from a github repo\n>>> repo = 'pytorch/vision'\n>>> model = torch.hub.load(repo, 'resnet50', pretrained=True)\n>>> # from a local directory\n>>> path = '/some/local/path/pytorch/vision'\n>>> model = torch.hub.load(path, 'resnet50', pretrained=True)\n",
        "Question": "How to use torch.hub.load, give an example?",
        "Id": 315,
        "source": "https://pytorch.org/docs/stable/hub.html",
        "context": " Ifsourceis'local',repo_or_diris expected to be a\npath to a local directory."
    },
    {
        "Answer": ">>> torch.hub.download_url_to_file('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth', '/tmp/temporary_file')\n",
        "Question": "How to use torch.hub.download_url_to_file, give an example?",
        "Id": 316,
        "source": "https://pytorch.org/docs/stable/hub.html",
        "context": " "
    },
    {
        "Answer": ">>> state_dict = torch.hub.load_state_dict_from_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth')\n",
        "Question": "How to use torch.hub.load_state_dict_from_url, give an example?",
        "Id": 317,
        "source": "https://pytorch.org/docs/stable/hub.html",
        "context": " If the object is already present inmodel_dir, it\u2019s deserialized and\nreturned.\nThe default value ofmodel_diris<hub_dir>/checkpointswherehub_diris the directory returned byget_dir()."
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([ 0.5224,  0.9354,  0.7257,  0.1301,  0.2251])\n\n\n>>> torch.log10(a)\ntensor([-0.2820, -0.0290, -0.1392, -0.8857, -0.6476])\n",
        "Question": "How to use torch.log10, give an example?",
        "Id": 318,
        "source": "https://pytorch.org/docs/stable/generated/torch.log10.html#torch.log10",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([2.2, float('nan'), 2.1, float('nan')])\n>>> b = torch.tensor([-9.3, 0.1, float('nan'), float('nan')])\n>>> torch.fmin(a, b)\ntensor([-9.3000, 0.1000, 2.1000,    nan])\n",
        "Question": "How to use torch.fmin, give an example?",
        "Id": 319,
        "source": "https://pytorch.org/docs/stable/generated/torch.fmin.html#torch.fmin",
        "context": " Supportsbroadcasting to a common shape,type promotion, and integer and floating-point inputs."
    },
    {
        "Answer": ">>> v1 = torch.arange(1., 5.)\n>>> v2 = torch.arange(1., 4.)\n>>> torch.outer(v1, v2)\ntensor([[  1.,   2.,   3.],\n        [  2.,   4.,   6.],\n        [  3.,   6.,   9.],\n        [  4.,   8.,  12.]])\n",
        "Question": "How to use torch.outer, give an example?",
        "Id": 320,
        "source": "https://pytorch.org/docs/stable/generated/torch.outer.html#torch.outer",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-1.2027, -1.7687,  0.4412, -1.3856])\n>>> torch.tan(a)\ntensor([-2.5930,  4.9859,  0.4722, -5.3366])\n",
        "Question": "How to use torch.tan, give an example?",
        "Id": 321,
        "source": "https://pytorch.org/docs/stable/generated/torch.tan.html#torch.tan",
        "context": " "
    },
    {
        "Answer": ">>> vec1 = torch.arange(1., 4.)\n>>> vec2 = torch.arange(1., 3.)\n>>> M = torch.zeros(3, 2)\n>>> torch.addr(M, vec1, vec2)\ntensor([[ 1.,  2.],\n        [ 2.,  4.],\n        [ 3.,  6.]])\n",
        "Question": "How to use torch.addr, give an example?",
        "Id": 322,
        "source": "https://pytorch.org/docs/stable/generated/torch.addr.html#torch.addr",
        "context": " Ifvec1is a vector of sizenandvec2is a vector\nof sizem, theninputmust bebroadcastablewith a matrix of size(n\u00d7m)(n \\times m)(n\u00d7m)andoutwill be a matrix of size(n\u00d7m)(n \\times m)(n\u00d7m)."
    },
    {
        "Answer": ">>> a = torch.randn(10)\n>>> a\ntensor([ 0.6001,  0.2069, -0.1919,  0.9792,  0.6727,  1.0062,  0.4126,\n        -0.2129, -0.4206,  0.1968])\n>>> torch.cumprod(a, dim=0)\ntensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0158, -0.0065,\n         0.0014, -0.0006, -0.0001])\n\n>>> a[5] = 0.0\n>>> torch.cumprod(a, dim=0)\ntensor([ 0.6001,  0.1241, -0.0238, -0.0233, -0.0157, -0.0000, -0.0000,\n         0.0000, -0.0000, -0.0000])\n",
        "Question": "How to use torch.cumprod, give an example?",
        "Id": 323,
        "source": "https://pytorch.org/docs/stable/generated/torch.cumprod.html#torch.cumprod",
        "context": " For example, ifinputis a vector of size N, the result will also be\na vector of size N, with elements."
    },
    {
        "Answer": "# Dot product\n>>> torch.inner(torch.tensor([1, 2, 3]), torch.tensor([0, 2, 1]))\ntensor(7)\n\n# Multidimensional input tensors\n>>> a = torch.randn(2, 3)\n>>> a\ntensor([[0.8173, 1.0874, 1.1784],\n        [0.3279, 0.1234, 2.7894]])\n>>> b = torch.randn(2, 4, 3)\n>>> b\ntensor([[[-0.4682, -0.7159,  0.1506],\n        [ 0.4034, -0.3657,  1.0387],\n        [ 0.9892, -0.6684,  0.1774],\n        [ 0.9482,  1.3261,  0.3917]],\n\n        [[ 0.4537,  0.7493,  1.1724],\n        [ 0.2291,  0.5749, -0.2267],\n        [-0.7920,  0.3607, -0.3701],\n        [ 1.3666, -0.5850, -1.7242]]])\n>>> torch.inner(a, b)\ntensor([[[-0.9837,  1.1560,  0.2907,  2.6785],\n        [ 2.5671,  0.5452, -0.6912, -1.5509]],\n\n        [[ 0.1782,  2.9843,  0.7366,  1.5672],\n        [ 3.5115, -0.4864, -1.2476, -4.4337]]])\n\n# Scalar input\n>>> torch.inner(a, torch.tensor(2))\ntensor([[1.6347, 2.1748, 2.3567],\n        [0.6558, 0.2469, 5.5787]])\n",
        "Question": "How to use torch.inner, give an example?",
        "Id": 324,
        "source": "https://pytorch.org/docs/stable/generated/torch.inner.html#torch.inner",
        "context": " "
    },
    {
        "Answer": ">>> torch.isclose(torch.tensor((1., 2, 3)), torch.tensor((1 + 1e-10, 3, 4)))\ntensor([ True, False, False])\n>>> torch.isclose(torch.tensor((float('inf'), 4)), torch.tensor((float('inf'), 6)), rtol=.5)\ntensor([True, True])\n",
        "Question": "How to use torch.isclose, give an example?",
        "Id": 325,
        "source": "https://pytorch.org/docs/stable/generated/torch.isclose.html#torch.isclose",
        "context": " whereinputandotherare finite. Whereinputand/orotherare nonfinite they are close if and only if\nthey are equal, with NaNs being considered equal to each other whenequal_nanis True."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-0.0370,  0.2970,  1.5420, -0.9105])\n>>> torch.rsqrt(a)\ntensor([    nan,  1.8351,  0.8053,     nan])\n",
        "Question": "How to use torch.rsqrt, give an example?",
        "Id": 326,
        "source": "https://pytorch.org/docs/stable/generated/torch.rsqrt.html#torch.rsqrt",
        "context": " "
    },
    {
        "Answer": ">>> sorted_sequence = torch.tensor([[1, 3, 5, 7, 9], [2, 4, 6, 8, 10]])\n>>> sorted_sequence\ntensor([[ 1,  3,  5,  7,  9],\n        [ 2,  4,  6,  8, 10]])\n>>> values = torch.tensor([[3, 6, 9], [3, 6, 9]])\n>>> values\ntensor([[3, 6, 9],\n        [3, 6, 9]])\n>>> torch.searchsorted(sorted_sequence, values)\ntensor([[1, 3, 4],\n        [1, 2, 4]])\n>>> torch.searchsorted(sorted_sequence, values, right=True)\ntensor([[2, 3, 5],\n        [1, 3, 4]])\n\n>>> sorted_sequence_1d = torch.tensor([1, 3, 5, 7, 9])\n>>> sorted_sequence_1d\ntensor([1, 3, 5, 7, 9])\n>>> torch.searchsorted(sorted_sequence_1d, values)\ntensor([[1, 3, 4],\n        [1, 3, 4]])\n",
        "Question": "How to use torch.searchsorted, give an example?",
        "Id": 327,
        "source": "https://pytorch.org/docs/stable/generated/torch.searchsorted.html#torch.searchsorted",
        "context": " "
    },
    {
        "Answer": ">>> import torch\n>>> A = torch.tensor([[0, 1], [1, 0]])\n>>> B = torch.tensor([[3, 4, 5], [6, 7, 8]])\n>>> C = torch.tensor(7)\n>>> D = torch.tensor([1, 2, 3])\n>>> E = torch.tensor([[4], [5], [6]])\n>>> torch.block_diag(A, B, C, D, E)\ntensor([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 3, 4, 5, 0, 0, 0, 0, 0],\n        [0, 0, 6, 7, 8, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 7, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1, 2, 3, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 4],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 6]])\n",
        "Question": "How to use torch.block_diag, give an example?",
        "Id": 328,
        "source": "https://pytorch.org/docs/stable/generated/torch.block_diag.html#torch.block_diag",
        "context": " "
    },
    {
        "Answer": "torch.linalg.solve(A, B) == A.inv() @ B\n",
        "Question": "How to use torch.linalg.inv, give an example?",
        "Id": 329,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.inv.html#torch.linalg.inv",
        "context": " Consider usingtorch.linalg.solve()if possible for multiplying a matrix on the left by\nthe inverse, as:"
    },
    {
        "Answer": ">>> x = torch.rand(4, 4)\n>>> y = torch.linalg.inv(x)\n>>> z = x @ y\n>>> z\ntensor([[ 1.0000, -0.0000, -0.0000,  0.0000],\n        [ 0.0000,  1.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  1.0000,  0.0000],\n        [ 0.0000, -0.0000, -0.0000,  1.0000]])\n>>> torch.dist(z, torch.eye(4))\ntensor(1.1921e-07)\n\n>>> # Batched inverse example\n>>> x = torch.randn(2, 3, 4, 4)\n>>> y = torch.linalg.inv(x)\n>>> z = x @ y\n>>> torch.dist(z, torch.eye(4).expand_as(x))\ntensor(1.9073e-06)\n\n>>> x = torch.rand(4, 4, dtype=torch.cdouble)\n>>> y = torch.linalg.inv(x)\n>>> z = x @ y\n>>> torch.dist(z, torch.eye(4, dtype=torch.cdouble))\ntensor(7.5107e-16, dtype=torch.float64)\n",
        "Question": "How  Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices\nthen the output has the same batch dimensions., give an example?",
        "Id": 330,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.inv.html#torch.linalg.inv",
        "context": " Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices\nthen the output has the same batch dimensions."
    },
    {
        "Answer": ">>> torch.bitwise_or(torch.tensor([-1, -2, 3], dtype=torch.int8), torch.tensor([1, 0, 3], dtype=torch.int8))\ntensor([-1, -2,  3], dtype=torch.int8)\n>>> torch.bitwise_or(torch.tensor([True, True, False]), torch.tensor([False, True, False]))\ntensor([ True, True, False])\n",
        "Question": "How to use torch.bitwise_or, give an example?",
        "Id": 331,
        "source": "https://pytorch.org/docs/stable/generated/torch.bitwise_or.html#torch.bitwise_or",
        "context": " "
    },
    {
        "Answer": ">>> a1 = torch.tensor([4.0])\n>>> a2 = torch.tensor([3.0, 4.0, 5.0])\n>>> a = torch.igammac(a1, a2)\ntensor([0.6472, 0.4335, 0.2650])\n>>> b = torch.igamma(a1, a2) + torch.igammac(a1, a2)\ntensor([1., 1., 1.])\n",
        "Question": "How to use torch.igammac, give an example?",
        "Id": 332,
        "source": "https://pytorch.org/docs/stable/generated/torch.igammac.html#torch.igammac",
        "context": " Supportsbroadcasting to a common shapeand float inputs."
    },
    {
        "Answer": ">>> torch.randint(3, 5, (3,))\ntensor([4, 3, 4])\n\n\n>>> torch.randint(10, (2, 2))\ntensor([[0, 2],\n        [5, 5]])\n\n\n>>> torch.randint(3, 10, (2, 2))\ntensor([[4, 5],\n        [6, 7]])\n",
        "Question": "How to use torch.randint, give an example?",
        "Id": 333,
        "source": "https://pytorch.org/docs/stable/generated/torch.randint.html#torch.randint",
        "context": " The shape of the tensor is defined by the variable argumentsize."
    },
    {
        "Answer": ">>> x = torch.randn(3, 4)\n>>> x\ntensor([[ 0.3552, -2.3825, -0.8297,  0.3477],\n        [-1.2035,  1.2252,  0.5002,  0.6248],\n        [ 0.1307, -2.0608,  0.1244,  2.0139]])\n>>> mask = x.ge(0.5)\n>>> mask\ntensor([[False, False, False, False],\n        [False, True, True, True],\n        [False, False, False, True]])\n>>> torch.masked_select(x, mask)\ntensor([ 1.2252,  0.5002,  0.6248,  2.0139])\n",
        "Question": "How to use torch.masked_select, give an example?",
        "Id": 334,
        "source": "https://pytorch.org/docs/stable/generated/torch.masked_select.html#torch.masked_select",
        "context": " The shapes of themasktensor and theinputtensor don\u2019t need\nto match, but they must bebroadcastable."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 335,
        "source": "https://pytorch.org/docs/stable/torch.html#tensors",
        "context": " "
    },
    {
        "Answer": ">>> mat1 = torch.randn(2, 3)\n>>> mat2 = torch.randn(3, 3)\n>>> torch.mm(mat1, mat2)\ntensor([[ 0.4851,  0.5037, -0.3633],\n        [-0.0760, -3.6705,  2.4784]])\n",
        "Question": "How to use torch.mm, give an example?",
        "Id": 336,
        "source": "https://pytorch.org/docs/stable/generated/torch.mm.html#torch.mm",
        "context": " This operator supportsTensorFloat32."
    },
    {
        "Answer": ">>> t = torch.randn(3,2,1)\n>>> t\ntensor([[[-0.3362],\n        [-0.8437]],\n\n        [[-0.9627],\n        [ 0.1727]],\n\n        [[ 0.5173],\n        [-0.1398]]])\n>>> torch.movedim(t, 1, 0).shape\ntorch.Size([2, 3, 1])\n>>> torch.movedim(t, 1, 0)\ntensor([[[-0.3362],\n        [-0.9627],\n        [ 0.5173]],\n\n        [[-0.8437],\n        [ 0.1727],\n        [-0.1398]]])\n>>> torch.movedim(t, (1, 2), (0, 1)).shape\ntorch.Size([2, 1, 3])\n>>> torch.movedim(t, (1, 2), (0, 1))\ntensor([[[-0.3362, -0.9627,  0.5173]],\n\n        [[-0.8437,  0.1727, -0.1398]]])\n",
        "Question": "How to use torch.movedim, give an example?",
        "Id": 337,
        "source": "https://pytorch.org/docs/stable/generated/torch.movedim.html#torch.movedim",
        "context": " Other dimensions ofinputthat are not explicitly moved remain in\ntheir original order and appear at the positions not specified indestination."
    },
    {
        "Answer": ">>> M = torch.randn(2, 3)\n>>> mat1 = torch.randn(2, 3)\n>>> mat2 = torch.randn(3, 3)\n>>> torch.addmm(M, mat1, mat2)\ntensor([[-4.8716,  1.4671, -1.3746],\n        [ 0.7573, -3.9555, -2.8681]])\n",
        "Question": "How to use torch.addmm, give an example?",
        "Id": 338,
        "source": "https://pytorch.org/docs/stable/generated/torch.addmm.html#torch.addmm",
        "context": " This operator supportsTensorFloat32."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 339,
        "source": "https://pytorch.org/docs/stable/torch.html#serialization",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(1, 3)\n>>> a\ntensor([[-0.8020,  0.5428, -1.5854]])\n>>> torch.prod(a)\ntensor(0.6902)\n",
        "Question": "How to use torch.prod, give an example?",
        "Id": 340,
        "source": "https://pytorch.org/docs/stable/generated/torch.prod.html#torch.prod",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4, 2)\n>>> a\ntensor([[ 0.5261, -0.3837],\n        [ 1.1857, -0.2498],\n        [-1.1646,  0.0705],\n        [ 1.1131, -1.0629]])\n>>> torch.prod(a, 1)\ntensor([-0.2018, -0.2962, -0.0821, -1.1831])\n",
        "Question": "How  IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput., give an example?",
        "Id": 341,
        "source": "https://pytorch.org/docs/stable/generated/torch.prod.html#torch.prod",
        "context": " IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput."
    },
    {
        "Answer": ">>> x = torch.randn(3, 2)\n>>> y = torch.ones(3, 2)\n>>> x\ntensor([[-0.4620,  0.3139],\n        [ 0.3898, -0.7197],\n        [ 0.0478, -0.1657]])\n>>> torch.where(x > 0, x, y)\ntensor([[ 1.0000,  0.3139],\n        [ 0.3898,  1.0000],\n        [ 0.0478,  1.0000]])\n>>> x = torch.randn(2, 2, dtype=torch.double)\n>>> x\ntensor([[ 1.0779,  0.0383],\n        [-0.8785, -1.1089]], dtype=torch.float64)\n>>> torch.where(x > 0, x, 0.)\ntensor([[1.0779, 0.0383],\n        [0.0000, 0.0000]], dtype=torch.float64)\n",
        "Question": "How to use torch.where, give an example?",
        "Id": 342,
        "source": "https://pytorch.org/docs/stable/generated/torch.where.html#torch.where",
        "context": " The operation is defined as:"
    },
    {
        "Answer": ">>> torch.empty((2,3), dtype=torch.int64)\ntensor([[ 9.4064e+13,  2.8000e+01,  9.3493e+13],\n        [ 7.5751e+18,  7.1428e+18,  7.5955e+18]])\n",
        "Question": "How to use torch.empty_like, give an example?",
        "Id": 343,
        "source": "https://pytorch.org/docs/stable/generated/torch.empty_like.html#torch.empty_like",
        "context": " "
    },
    {
        "Answer": ">>> input = torch.randn(10, 3, 4)\n>>> mat2 = torch.randn(10, 4, 5)\n>>> res = torch.bmm(input, mat2)\n>>> res.size()\ntorch.Size([10, 3, 5])\n",
        "Question": "How to use torch.bmm, give an example?",
        "Id": 344,
        "source": "https://pytorch.org/docs/stable/generated/torch.bmm.html#torch.bmm",
        "context": " This operator supportsTensorFloat32."
    },
    {
        "Answer": ">>> torch.randn(4)\ntensor([-2.1436,  0.9966,  2.3426, -0.6366])\n>>> torch.randn(2, 3)\ntensor([[ 1.5954,  2.8929, -1.0923],\n        [ 1.1719, -0.4709, -0.1996]])\n",
        "Question": "How to use torch.randn, give an example?",
        "Id": 345,
        "source": "https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn",
        "context": " The shape of the tensor is defined by the variable argumentsize."
    },
    {
        "Answer": ">>> rates = torch.rand(4, 4) * 5  # rate parameter between 0 and 5\n>>> torch.poisson(rates)\ntensor([[9., 1., 3., 5.],\n        [8., 6., 6., 0.],\n        [0., 4., 5., 3.],\n        [2., 1., 4., 2.]])\n",
        "Question": "How to use torch.poisson, give an example?",
        "Id": 346,
        "source": "https://pytorch.org/docs/stable/generated/torch.poisson.html#torch.poisson",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([1, 2, 3])\n>>> b = torch.tensor([4, 5, 6])\n>>> torch.vstack((a,b))\ntensor([[1, 2, 3],\n        [4, 5, 6]])\n>>> a = torch.tensor([[1],[2],[3]])\n>>> b = torch.tensor([[4],[5],[6]])\n>>> torch.vstack((a,b))\ntensor([[1],\n        [2],\n        [3],\n        [4],\n        [5],\n        [6]])\n",
        "Question": "How to use torch.vstack, give an example?",
        "Id": 347,
        "source": "https://pytorch.org/docs/stable/generated/torch.vstack.html#torch.vstack",
        "context": " This is equivalent to concatenation along the first axis after all 1-D tensors have been reshaped bytorch.atleast_2d()."
    },
    {
        "Answer": ">>> a = torch.arange(4.)\n>>> torch.reshape(a, (2, 2))\ntensor([[ 0.,  1.],\n        [ 2.,  3.]])\n>>> b = torch.tensor([[0, 1], [2, 3]])\n>>> torch.reshape(b, (-1,))\ntensor([ 0,  1,  2,  3])\n",
        "Question": "How to use torch.reshape, give an example?",
        "Id": 348,
        "source": "https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape",
        "context": " A single dimension may be -1, in which case it\u2019s inferred from the remaining\ndimensions and the number of elements ininput."
    },
    {
        "Answer": ">>> boundaries = torch.tensor([1, 3, 5, 7, 9])\n>>> boundaries\ntensor([1, 3, 5, 7, 9])\n>>> v = torch.tensor([[3, 6, 9], [3, 6, 9]])\n>>> v\ntensor([[3, 6, 9],\n        [3, 6, 9]])\n>>> torch.bucketize(v, boundaries)\ntensor([[1, 3, 4],\n        [1, 3, 4]])\n>>> torch.bucketize(v, boundaries, right=True)\ntensor([[2, 3, 5],\n        [2, 3, 5]])\n",
        "Question": "How to use torch.bucketize, give an example?",
        "Id": 349,
        "source": "https://pytorch.org/docs/stable/generated/torch.bucketize.html#torch.bucketize",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(5)\n>>> a\ntensor([-1.2557, -0.0026, -0.5387,  0.4740, -0.9244])\n>>> torch.copysign(a, 1)\ntensor([1.2557, 0.0026, 0.5387, 0.4740, 0.9244])\n>>> a = torch.randn(4, 4)\n>>> a\ntensor([[ 0.7079,  0.2778, -1.0249,  0.5719],\n        [-0.0059, -0.2600, -0.4475, -1.3948],\n        [ 0.3667, -0.9567, -2.5757, -0.1751],\n        [ 0.2046, -0.0742,  0.2998, -0.1054]])\n>>> b = torch.randn(4)\ntensor([ 0.2373,  0.3120,  0.3190, -1.1128])\n>>> torch.copysign(a, b)\ntensor([[ 0.7079,  0.2778,  1.0249, -0.5719],\n        [ 0.0059,  0.2600,  0.4475, -1.3948],\n        [ 0.3667,  0.9567,  2.5757, -0.1751],\n        [ 0.2046,  0.0742,  0.2998, -0.1054]])\n",
        "Question": "How to use torch.copysign, give an example?",
        "Id": 350,
        "source": "https://pytorch.org/docs/stable/generated/torch.copysign.html#torch.copysign",
        "context": " Supportsbroadcasting to a common shape,\nand integer and float inputs."
    },
    {
        "Answer": ">>> x = torch.arange(1., 6.)\n>>> x\ntensor([ 1.,  2.,  3.,  4.,  5.])\n>>> torch.kthvalue(x, 4)\ntorch.return_types.kthvalue(values=tensor(4.), indices=tensor(3))\n\n>>> x=torch.arange(1.,7.).resize_(2,3)\n>>> x\ntensor([[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.]])\n>>> torch.kthvalue(x, 2, 0, True)\ntorch.return_types.kthvalue(values=tensor([[4., 5., 6.]]), indices=tensor([[1, 1, 1]]))\n",
        "Question": "How to use torch.kthvalue, give an example?",
        "Id": 351,
        "source": "https://pytorch.org/docs/stable/generated/torch.kthvalue.html#torch.kthvalue",
        "context": " IfkeepdimisTrue, both thevaluesandindicestensors\nare the same size asinput, except in the dimensiondimwhere\nthey are of size 1. Otherwise,dimis squeezed\n(seetorch.squeeze()), resulting in both thevaluesandindicestensors having 1 fewer dimension than theinputtensor."
    },
    {
        "Answer": "L = torch.linalg.cholesky(A)\n",
        "Question": "How to use torch.cholesky, give an example?",
        "Id": 352,
        "source": "https://pytorch.org/docs/stable/generated/torch.cholesky.html#torch.cholesky",
        "context": " torch.cholesky()is deprecated in favor oftorch.linalg.cholesky()and will be removed in a future PyTorch release.L=torch.cholesky(A)should be replaced with"
    },
    {
        "Answer": "U = torch.linalg.cholesky(A.transpose(-2, -1).conj()).transpose(-2, -1).conj()\n",
        "Question": "How  L=torch.cholesky(A)should be replaced withU=torch.cholesky(A,upper=True)should be replaced with, give an example?",
        "Id": 353,
        "source": "https://pytorch.org/docs/stable/generated/torch.cholesky.html#torch.cholesky",
        "context": " L=torch.cholesky(A)should be replaced withU=torch.cholesky(A,upper=True)should be replaced with"
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a = torch.mm(a, a.t()) # make symmetric positive-definite\n>>> l = torch.cholesky(a)\n>>> a\ntensor([[ 2.4112, -0.7486,  1.4551],\n        [-0.7486,  1.3544,  0.1294],\n        [ 1.4551,  0.1294,  1.6724]])\n>>> l\ntensor([[ 1.5528,  0.0000,  0.0000],\n        [-0.4821,  1.0592,  0.0000],\n        [ 0.9371,  0.5487,  0.7023]])\n>>> torch.mm(l, l.t())\ntensor([[ 2.4112, -0.7486,  1.4551],\n        [-0.7486,  1.3544,  0.1294],\n        [ 1.4551,  0.1294,  1.6724]])\n>>> a = torch.randn(3, 2, 2)\n>>> a = torch.matmul(a, a.transpose(-1, -2)) + 1e-03 # make symmetric positive-definite\n>>> l = torch.cholesky(a)\n>>> z = torch.matmul(l, l.transpose(-1, -2))\n>>> torch.max(torch.abs(z - a)) # Max non-zero\ntensor(2.3842e-07)\n",
        "Question": "How  IfupperisTrue, andAAAis a batch of symmetric positive-definite\nmatrices, then the returned tensor will be composed of upper-triangular Cholesky factors\nof each of the individual matrices. Similarly, whenupperisFalse, the returned\ntensor will be composed of lower-triangular Cholesky factors of each of the individual\nmatrices., give an example?",
        "Id": 354,
        "source": "https://pytorch.org/docs/stable/generated/torch.cholesky.html#torch.cholesky",
        "context": " IfupperisTrue, andAAAis a batch of symmetric positive-definite\nmatrices, then the returned tensor will be composed of upper-triangular Cholesky factors\nof each of the individual matrices. Similarly, whenupperisFalse, the returned\ntensor will be composed of lower-triangular Cholesky factors of each of the individual\nmatrices."
    },
    {
        "Answer": ">>> torch.histc(torch.tensor([1., 2, 1]), bins=4, min=0, max=3)\ntensor([ 0.,  2.,  1.,  0.])\n",
        "Question": "How to use torch.histc, give an example?",
        "Id": 355,
        "source": "https://pytorch.org/docs/stable/generated/torch.histc.html#torch.histc",
        "context": " Elements lower than min and higher than max are ignored."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 356,
        "source": "https://pytorch.org/docs/stable/torch.html#creation-ops",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 357,
        "source": "https://pytorch.org/docs/stable/torch.html#torch",
        "context": " "
    },
    {
        "Answer": ">>> torch.eq(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[ True, False],\n        [False, True]])\n",
        "Question": "How to use torch.eq, give an example?",
        "Id": 358,
        "source": "https://pytorch.org/docs/stable/generated/torch.eq.html#torch.eq",
        "context": " The second argument can be a number or a tensor whose shape isbroadcastablewith the first argument."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 359,
        "source": "https://pytorch.org/docs/stable/torch.html#utilities",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([1, 2, 3, 4])\n>>> torch.unsqueeze(x, 0)\ntensor([[ 1,  2,  3,  4]])\n>>> torch.unsqueeze(x, 1)\ntensor([[ 1],\n        [ 2],\n        [ 3],\n        [ 4]])\n",
        "Question": "How to use torch.unsqueeze, give an example?",
        "Id": 360,
        "source": "https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze",
        "context": " Adimvalue within the range[-input.dim()-1,input.dim()+1)can be used. Negativedimwill correspond tounsqueeze()applied atdim=dim+input.dim()+1."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 361,
        "source": "https://pytorch.org/docs/stable/torch.html#random-sampling",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.eye(10)\n>>> torch.matrix_rank(a)\ntensor(10)\n>>> b = torch.eye(10)\n>>> b[0, 0] = 0\n>>> torch.matrix_rank(b)\ntensor(9)\n",
        "Question": "How to use torch.matrix_rank, give an example?",
        "Id": 362,
        "source": "https://pytorch.org/docs/stable/generated/torch.matrix_rank.html#torch.matrix_rank",
        "context": " tolis the threshold below which the singular values (or the eigenvalues\nwhensymmetricisTrue) are considered to be 0. Iftolis not\nspecified,tolis set toS.max()*max(S.size())*epswhereSis the\nsingular values (or the eigenvalues whensymmetricisTrue), andepsis the epsilon value for the datatype ofinput."
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n        [-0.7401, -0.8805, -0.3402, -1.1936],\n        [ 0.4907, -1.3948, -1.0691, -0.3132],\n        [-1.6092,  0.5419, -0.2993,  0.3195]])\n>>> torch.argmax(a)\ntensor(0)\n",
        "Question": "How to use torch.argmax, give an example?",
        "Id": 363,
        "source": "https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax",
        "context": " This is the second value returned bytorch.max(). See its\ndocumentation for the exact semantics of this method."
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[ 1.3398,  0.2663, -0.2686,  0.2450],\n        [-0.7401, -0.8805, -0.3402, -1.1936],\n        [ 0.4907, -1.3948, -1.0691, -0.3132],\n        [-1.6092,  0.5419, -0.2993,  0.3195]])\n>>> torch.argmax(a, dim=1)\ntensor([ 0,  2,  0,  1])\n",
        "Question": "How  This is the second value returned bytorch.max(). See its\ndocumentation for the exact semantics of this method., give an example?",
        "Id": 364,
        "source": "https://pytorch.org/docs/stable/generated/torch.argmax.html#torch.argmax",
        "context": " This is the second value returned bytorch.max(). See its\ndocumentation for the exact semantics of this method."
    },
    {
        "Answer": ">>> x=torch.randn(4, dtype=torch.cfloat)\n>>> x\ntensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n>>> x.imag\ntensor([ 0.3553, -0.7896, -0.0633, -0.8119])\n",
        "Question": "How to use torch.imag, give an example?",
        "Id": 365,
        "source": "https://pytorch.org/docs/stable/generated/torch.imag.html#torch.imag",
        "context": " "
    },
    {
        "Answer": ">>> torch.exp(torch.tensor([0, math.log(2.)]))\ntensor([ 1.,  2.])\n",
        "Question": "How to use torch.exp, give an example?",
        "Id": 366,
        "source": "https://pytorch.org/docs/stable/generated/torch.exp.html#torch.exp",
        "context": " "
    },
    {
        "Answer": ">>> torch.angle(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))*180/3.14159\ntensor([ 135.,  135,  -45])\n",
        "Question": "How to use torch.angle, give an example?",
        "Id": 367,
        "source": "https://pytorch.org/docs/stable/generated/torch.angle.html#torch.angle",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(-0.5, 1, 0.5)\n>>> a\ntensor([-0.5000,  0.0000,  0.5000])\n>>> torch.special.entr(a)\ntensor([  -inf, 0.0000, 0.3466])\n",
        "Question": "How  , give an example?",
        "Id": 368,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erf(torch.tensor([0, -1., 10.]))\ntensor([ 0.0000, -0.8427,  1.0000])\n",
        "Question": "How  , give an example?",
        "Id": 369,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n",
        "Question": "How  , give an example?",
        "Id": 370,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n",
        "Question": "How  , give an example?",
        "Id": 371,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(4)\n>>> t\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n>>> torch.special.expit(t)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
        "Question": "How  , give an example?",
        "Id": 372,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n",
        "Question": "How  , give an example?",
        "Id": 373,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\ntensor([ 1.,  2.,  8., 16.])\n",
        "Question": "How  , give an example?",
        "Id": 374,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.special.gammaln(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How  , give an example?",
        "Id": 375,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.i0e(torch.arange(5, dtype=torch.float32))\ntensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])\n",
        "Question": "How  , give an example?",
        "Id": 376,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n>>> torch.special.logit(a, eps=1e-6)\ntensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
        "Question": "How  , give an example?",
        "Id": 377,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.special.xlog1py(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.special.xlog1py(x, y)\ntensor([1.3863, 2.1972, 2.0794])\n>>> torch.special.xlog1py(x, 4)\ntensor([1.6094, 3.2189, 4.8283])\n>>> torch.special.xlog1py(2, y)\ntensor([2.7726, 2.1972, 1.3863])\n",
        "Question": "How  Similar to SciPy\u2019sscipy.special.xlog1py., give an example?",
        "Id": 378,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.exp2",
        "context": " Similar to SciPy\u2019sscipy.special.xlog1py."
    },
    {
        "Answer": "self[index[i][j][k]][j][k] = src[i][j][k]  # if dim == 0\nself[i][index[i][j][k]][k] = src[i][j][k]  # if dim == 1\nself[i][j][index[i][j][k]] = src[i][j][k]  # if dim == 2\n",
        "Question": "How to use torch.Tensor.scatter_, give an example?",
        "Id": 379,
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_",
        "context": " For a 3-D tensor,selfis updated as:"
    },
    {
        "Answer": "self[index[i][j][k]][j][k] *= src[i][j][k]  # if dim == 0\nself[i][index[i][j][k]][k] *= src[i][j][k]  # if dim == 1\nself[i][j][index[i][j][k]] *= src[i][j][k]  # if dim == 2\n",
        "Question": "How  Additionally accepts an optionalreduceargument that allows\nspecification of an optional reduction operation, which is applied to all\nvalues in the tensorsrcintoselfat the indicies\nspecified in theindex. For each value insrc, the reduction\noperation is applied to an index inselfwhich is specified by\nits index insrcfordimension!=dimand by the corresponding\nvalue inindexfordimension=dim.Given a 3-D tensor and reduction using the multiplication operation,selfis updated as:, give an example?",
        "Id": 380,
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_",
        "context": " Additionally accepts an optionalreduceargument that allows\nspecification of an optional reduction operation, which is applied to all\nvalues in the tensorsrcintoselfat the indicies\nspecified in theindex. For each value insrc, the reduction\noperation is applied to an index inselfwhich is specified by\nits index insrcfordimension!=dimand by the corresponding\nvalue inindexfordimension=dim.Given a 3-D tensor and reduction using the multiplication operation,selfis updated as:"
    },
    {
        "Answer": ">>> src = torch.arange(1, 11).reshape((2, 5))\n>>> src\ntensor([[ 1,  2,  3,  4,  5],\n        [ 6,  7,  8,  9, 10]])\n>>> index = torch.tensor([[0, 1, 2, 0]])\n>>> torch.zeros(3, 5, dtype=src.dtype).scatter_(0, index, src)\ntensor([[1, 0, 0, 4, 0],\n        [0, 2, 0, 0, 0],\n        [0, 0, 3, 0, 0]])\n>>> index = torch.tensor([[0, 1, 2], [0, 1, 4]])\n>>> torch.zeros(3, 5, dtype=src.dtype).scatter_(1, index, src)\ntensor([[1, 2, 3, 0, 0],\n        [6, 7, 0, 0, 8],\n        [0, 0, 0, 0, 0]])\n\n>>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n...            1.23, reduce='multiply')\ntensor([[2.0000, 2.0000, 2.4600, 2.0000],\n        [2.0000, 2.0000, 2.0000, 2.4600]])\n>>> torch.full((2, 4), 2.).scatter_(1, torch.tensor([[2], [3]]),\n...            1.23, reduce='add')\ntensor([[2.0000, 2.0000, 3.2300, 2.0000],\n        [2.0000, 2.0000, 2.0000, 3.2300]])\n",
        "Question": "How  Reducing with the addition operation is the same as usingscatter_add_()., give an example?",
        "Id": 381,
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_.html#torch.Tensor.scatter_",
        "context": " Reducing with the addition operation is the same as usingscatter_add_()."
    },
    {
        "Answer": ">>> torch.range(1, 4)\ntensor([ 1.,  2.,  3.,  4.])\n>>> torch.range(1, 4, 0.5)\ntensor([ 1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,  4.0000])\n",
        "Question": "How to use torch.range, give an example?",
        "Id": 382,
        "source": "https://pytorch.org/docs/stable/generated/torch.range.html#torch.range",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([1, 2, 3])\n>>> torch.broadcast_to(x, (3, 3))\ntensor([[1, 2, 3],\n        [1, 2, 3],\n        [1, 2, 3]])\n",
        "Question": "How to use torch.broadcast_to, give an example?",
        "Id": 383,
        "source": "https://pytorch.org/docs/stable/generated/torch.broadcast_to.html#torch.broadcast_to",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(2, 1, 2, 1, 2)\n>>> x.size()\ntorch.Size([2, 1, 2, 1, 2])\n>>> y = torch.squeeze(x)\n>>> y.size()\ntorch.Size([2, 2, 2])\n>>> y = torch.squeeze(x, 0)\n>>> y.size()\ntorch.Size([2, 1, 2, 1, 2])\n>>> y = torch.squeeze(x, 1)\n>>> y.size()\ntorch.Size([2, 2, 1, 2])\n",
        "Question": "How to use torch.squeeze, give an example?",
        "Id": 384,
        "source": "https://pytorch.org/docs/stable/generated/torch.squeeze.html#torch.squeeze",
        "context": " Whendimis given, a squeeze operation is done only in the given\ndimension. Ifinputis of shape:(A\u00d71\u00d7B)(A \\times 1 \\times B)(A\u00d71\u00d7B),squeeze(input,0)leaves the tensor unchanged, butsqueeze(input,1)will squeeze the tensor to the shape(A\u00d7B)(A \\times B)(A\u00d7B)."
    },
    {
        "Answer": "import torch\ntorch.manual_seed(0)\n",
        "Question": "How to use You can usetorch.manual_seed()to seed the RNG for all devices (both\nCPU and CUDA):, give an example?",
        "Id": 385,
        "source": "https://pytorch.org/docs/stable/notes/randomness.html",
        "context": " You can usetorch.manual_seed()to seed the RNG for all devices (both\nCPU and CUDA):"
    },
    {
        "Answer": "import random\nrandom.seed(0)\n",
        "Question": "How to use For custom operators, you might need to set python seed as well:, give an example?",
        "Id": 386,
        "source": "https://pytorch.org/docs/stable/notes/randomness.html",
        "context": " For custom operators, you might need to set python seed as well:"
    },
    {
        "Answer": "import numpy as np\nnp.random.seed(0)\n",
        "Question": "How to use If you or any of the libraries you are using rely on NumPy, you can seed the global\nNumPy RNG with:, give an example?",
        "Id": 387,
        "source": "https://pytorch.org/docs/stable/notes/randomness.html",
        "context": " If you or any of the libraries you are using rely on NumPy, you can seed the global\nNumPy RNG with:"
    },
    {
        "Answer": ">>> import torch\n>>> torch.use_deterministic_algorithms(True)\n>>> torch.randn(2, 2).cuda().index_add_(0, torch.tensor([0, 1]), torch.randn(2, 2))\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nRuntimeError: index_add_cuda_ does not have a deterministic implementation, but you set\n'torch.use_deterministic_algorithms(True)'. ...\n",
        "Question": "How to use Please check the documentation fortorch.use_deterministic_algorithms()for a full list of affected operations. If an operation does not act correctly\naccording to the documentation, or if you need a deterministic implementation\nof an operation that does not have one, please submit an issue:https://github.com/pytorch/pytorch/issues?q=label:%22topic:%20determinism%22For example, running the nondeterministic CUDA implementation oftorch.Tensor.index_add_()will throw an error:, give an example?",
        "Id": 388,
        "source": "https://pytorch.org/docs/stable/notes/randomness.html",
        "context": " Please check the documentation fortorch.use_deterministic_algorithms()for a full list of affected operations. If an operation does not act correctly\naccording to the documentation, or if you need a deterministic implementation\nof an operation that does not have one, please submit an issue:https://github.com/pytorch/pytorch/issues?q=label:%22topic:%20determinism%22For example, running the nondeterministic CUDA implementation oftorch.Tensor.index_add_()will throw an error:"
    },
    {
        "Answer": ">>> import torch\n>>> torch.use_deterministic_algorithms(True)\n>>> torch.bmm(torch.randn(2, 2, 2).to_sparse().cuda(), torch.randn(2, 2, 2).cuda())\ntensor([[[ 1.1900, -2.3409],\n         [ 0.4796,  0.8003]],\n        [[ 0.1509,  1.8027],\n         [ 0.0333, -1.1444]]], device='cuda:0')\n",
        "Question": "How to use For example, running the nondeterministic CUDA implementation oftorch.Tensor.index_add_()will throw an error:Whentorch.bmm()is called with sparse-dense CUDA tensors it typically uses a\nnondeterministic algorithm, but when the deterministic flag is turned on, its alternate\ndeterministic implementation will be used:, give an example?",
        "Id": 389,
        "source": "https://pytorch.org/docs/stable/notes/randomness.html",
        "context": " For example, running the nondeterministic CUDA implementation oftorch.Tensor.index_add_()will throw an error:Whentorch.bmm()is called with sparse-dense CUDA tensors it typically uses a\nnondeterministic algorithm, but when the deterministic flag is turned on, its alternate\ndeterministic implementation will be used:"
    },
    {
        "Answer": "def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    numpy.random.seed(worker_seed)\n    random.seed(worker_seed)\n\ng = torch.Generator()\ng.manual_seed(0)\n\nDataLoader(\n    train_dataset,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    worker_init_fn=seed_worker\n    generator=g,\n)\n",
        "Question": "How to use DataLoader will reseed workers followingRandomness in multi-process data loadingalgorithm.\nUseworker_init_fn()andgeneratorto preserve reproducibility:, give an example?",
        "Id": 390,
        "source": "https://pytorch.org/docs/stable/notes/randomness.html",
        "context": " DataLoader will reseed workers followingRandomness in multi-process data loadingalgorithm.\nUseworker_init_fn()andgeneratorto preserve reproducibility:"
    },
    {
        "Answer": ">>> t = torch.arange(16.0).reshape(2, 2, 4)\n>>> t\ntensor([[[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.]],\n        [[ 8.,  9., 10., 11.],\n         [12., 13., 14., 15.]]])\n>>> torch.dsplit(t, 2)\n(tensor([[[ 0.,  1.],\n        [ 4.,  5.]],\n       [[ 8.,  9.],\n        [12., 13.]]]),\n tensor([[[ 2.,  3.],\n          [ 6.,  7.]],\n         [[10., 11.],\n          [14., 15.]]]))\n",
        "Question": "How to use torch.dsplit, give an example?",
        "Id": 391,
        "source": "https://pytorch.org/docs/stable/generated/torch.dsplit.html#torch.dsplit",
        "context": " "
    },
    {
        "Answer": ">>> torch.dsplit(t, [3, 6])\n(tensor([[[ 0.,  1.,  2.],\n          [ 4.,  5.,  6.]],\n         [[ 8.,  9., 10.],\n          [12., 13., 14.]]]),\n tensor([[[ 3.],\n          [ 7.]],\n         [[11.],\n          [15.]]]),\n tensor([], size=(2, 2, 0)))\n",
        "Question": "How  , give an example?",
        "Id": 392,
        "source": "https://pytorch.org/docs/stable/generated/torch.dsplit.html#torch.dsplit",
        "context": " "
    },
    {
        "Answer": ">>> torch.can_cast(torch.double, torch.float)\nTrue\n>>> torch.can_cast(torch.float, torch.int)\nFalse\n",
        "Question": "How to use torch.can_cast, give an example?",
        "Id": 393,
        "source": "https://pytorch.org/docs/stable/generated/torch.can_cast.html#torch.can_cast",
        "context": " "
    },
    {
        "Answer": ">>> A = torch.randn(3, 3)\n>>> A\ntensor([[ 0.0032, -0.2239, -1.1219],\n        [-0.6690,  0.1161,  0.4053],\n        [-1.6218, -0.9273, -0.0082]])\n>>> torch.linalg.det(A)\ntensor(-0.7576)\n>>> torch.linalg.logdet(A)\ntensor(nan)\n>>> torch.linalg.slogdet(A)\ntorch.return_types.linalg_slogdet(sign=tensor(-1.), logabsdet=tensor(-0.2776))\n",
        "Question": "How to use torch.linalg.slogdet, give an example?",
        "Id": 394,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.slogdet.html#torch.linalg.slogdet",
        "context": " Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions."
    },
    {
        "Answer": "Q, R = torch.linalg.qr(A)\n",
        "Question": "How to use torch.qr, give an example?",
        "Id": 395,
        "source": "https://pytorch.org/docs/stable/generated/torch.qr.html#torch.qr",
        "context": " torch.qr()is deprecated in favor oftorch.linalg.qr()and will be removed in a future PyTorch release. The boolean parametersomehas been\nreplaced with a string parametermode.Q,R=torch.qr(A)should be replaced with"
    },
    {
        "Answer": "Q, R = torch.linalg.qr(A, mode=\"complete\")\n",
        "Question": "How  Q,R=torch.qr(A)should be replaced withQ,R=torch.qr(A,some=False)should be replaced with, give an example?",
        "Id": 396,
        "source": "https://pytorch.org/docs/stable/generated/torch.qr.html#torch.qr",
        "context": " Q,R=torch.qr(A)should be replaced withQ,R=torch.qr(A,some=False)should be replaced with"
    },
    {
        "Answer": ">>> a = torch.tensor([[12., -51, 4], [6, 167, -68], [-4, 24, -41]])\n>>> q, r = torch.qr(a)\n>>> q\ntensor([[-0.8571,  0.3943,  0.3314],\n        [-0.4286, -0.9029, -0.0343],\n        [ 0.2857, -0.1714,  0.9429]])\n>>> r\ntensor([[ -14.0000,  -21.0000,   14.0000],\n        [   0.0000, -175.0000,   70.0000],\n        [   0.0000,    0.0000,  -35.0000]])\n>>> torch.mm(q, r).round()\ntensor([[  12.,  -51.,    4.],\n        [   6.,  167.,  -68.],\n        [  -4.,   24.,  -41.]])\n>>> torch.mm(q.t(), q).round()\ntensor([[ 1.,  0.,  0.],\n        [ 0.,  1., -0.],\n        [ 0., -0.,  1.]])\n>>> a = torch.randn(3, 4, 5)\n>>> q, r = torch.qr(a, some=False)\n>>> torch.allclose(torch.matmul(q, r), a)\nTrue\n>>> torch.allclose(torch.matmul(q.transpose(-2, -1), q), torch.eye(5))\nTrue\n",
        "Question": "How  IfsomeisTrue, then this function returns the thin (reduced) QR factorization.\nOtherwise, ifsomeisFalse, this function returns the complete QR factorization., give an example?",
        "Id": 397,
        "source": "https://pytorch.org/docs/stable/generated/torch.qr.html#torch.qr",
        "context": " IfsomeisTrue, then this function returns the thin (reduced) QR factorization.\nOtherwise, ifsomeisFalse, this function returns the complete QR factorization."
    },
    {
        "Answer": ">>> x = torch.tensor([float('nan'), float('inf'), -float('inf'), 3.14])\n>>> torch.nan_to_num(x)\ntensor([ 0.0000e+00,  3.4028e+38, -3.4028e+38,  3.1400e+00])\n>>> torch.nan_to_num(x, nan=2.0)\ntensor([ 2.0000e+00,  3.4028e+38, -3.4028e+38,  3.1400e+00])\n>>> torch.nan_to_num(x, nan=2.0, posinf=1.0)\ntensor([ 2.0000e+00,  1.0000e+00, -3.4028e+38,  3.1400e+00])\n",
        "Question": "How to use torch.nan_to_num, give an example?",
        "Id": 398,
        "source": "https://pytorch.org/docs/stable/generated/torch.nan_to_num.html#torch.nan_to_num",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([ 0.3810,  1.2774, -0.2972, -0.3719,  0.4637])\n>>> torch.div(x, 0.5)\ntensor([ 0.7620,  2.5548, -0.5944, -0.7438,  0.9274])\n\n>>> a = torch.tensor([[-0.3711, -1.9353, -0.4605, -0.2917],\n...                   [ 0.1815, -1.0111,  0.9805, -1.5923],\n...                   [ 0.1062,  1.4581,  0.7759, -1.2344],\n...                   [-0.1830, -0.0313,  1.1908, -1.4757]])\n>>> b = torch.tensor([ 0.8032,  0.2930, -0.8113, -0.2308])\n>>> torch.div(a, b)\ntensor([[-0.4620, -6.6051,  0.5676,  1.2639],\n        [ 0.2260, -3.4509, -1.2086,  6.8990],\n        [ 0.1322,  4.9764, -0.9564,  5.3484],\n        [-0.2278, -0.1068, -1.4678,  6.3938]])\n\n>>> torch.div(a, b, rounding_mode='trunc')\ntensor([[-0., -6.,  0.,  1.],\n        [ 0., -3., -1.,  6.],\n        [ 0.,  4., -0.,  5.],\n        [-0., -0., -1.,  6.]])\n\n>>> torch.div(a, b, rounding_mode='floor')\ntensor([[-1., -7.,  0.,  1.],\n        [ 0., -4., -2.,  6.],\n        [ 0.,  4., -1.,  5.],\n        [-1., -1., -2.,  6.]])\n",
        "Question": "How to use torch.div, give an example?",
        "Id": 399,
        "source": "https://pytorch.org/docs/stable/generated/torch.div.html#torch.div",
        "context": " Supportsbroadcasting to a common shape,type promotion, and integer, float, and complex inputs.\nAlways promotes integer types to the default scalar type."
    },
    {
        "Answer": "import torch\n\ndef foo(x, y):\n    return 2 * x + y\n\ntraced_foo = torch.jit.trace(foo, (torch.rand(3), torch.rand(3)))\n\n@torch.jit.script\ndef bar(x):\n    return traced_foo(x, x)\n",
        "Question": "How to use Mixing Tracing and Scripting, give an example?",
        "Id": 400,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "import torch\n\n@torch.jit.script\ndef foo(x, y):\n    if x.max() > y.max():\n        r = x\n    else:\n        r = y\n    return r\n\n\ndef bar(x, y, z):\n    return foo(x, y) + z\n\ntraced_bar = torch.jit.trace(bar, (torch.rand(3), torch.rand(3), torch.rand(3)))\n",
        "Question": "How  , give an example?",
        "Id": 401,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "import torch\nimport torchvision\n\nclass MyScriptModule(torch.nn.Module):\n    def __init__(self):\n        super(MyScriptModule, self).__init__()\n        self.means = torch.nn.Parameter(torch.tensor([103.939, 116.779, 123.68])\n                                        .resize_(1, 3, 1, 1))\n        self.resnet = torch.jit.trace(torchvision.models.resnet18(),\n                                      torch.rand(1, 3, 224, 224))\n\n    def forward(self, input):\n        return self.resnet(input - self.means)\n\nmy_script_module = torch.jit.script(MyScriptModule())\n",
        "Question": "How  , give an example?",
        "Id": 402,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "@torch.jit.script\ndef scripted_fn(x : torch.Tensor):\n    for i in range(12):\n        x = x + x\n    return x\n\ndef fn(x):\n    x = torch.neg(x)\n    import pdb; pdb.set_trace()\n    return scripted_fn(x)\n\ntraced_fn = torch.jit.trace(fn, (torch.rand(4, 5),))\ntraced_fn(torch.rand(3, 4))\n",
        "Question": "How to use Setting the environment variablePYTORCH_JIT=0will disable all script\nand tracing annotations. If there is hard-to-debug error in one of your\nTorchScript models, you can use this flag to force everything to run using native\nPython. Since TorchScript (scripting and tracing) is disabled with this flag,\nyou can use tools likepdbto debug the model code.  For example:, give an example?",
        "Id": 403,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " Setting the environment variablePYTORCH_JIT=0will disable all script\nand tracing annotations. If there is hard-to-debug error in one of your\nTorchScript models, you can use this flag to force everything to run using native\nPython. Since TorchScript (scripting and tracing) is disabled with this flag,\nyou can use tools likepdbto debug the model code.  For example:"
    },
    {
        "Answer": "$ PYTORCH_JIT=0 python disable_jit_example.py\n",
        "Question": "How to use Setting the environment variablePYTORCH_JIT=0will disable all script\nand tracing annotations. If there is hard-to-debug error in one of your\nTorchScript models, you can use this flag to force everything to run using native\nPython. Since TorchScript (scripting and tracing) is disabled with this flag,\nyou can use tools likepdbto debug the model code.  For example:Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so:, give an example?",
        "Id": 404,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " Debugging this script withpdbworks except for when we invoke the@torch.jit.scriptfunction. We can globally disable\nJIT, so that we can call the@torch.jit.scriptfunction as a normal Python function and not compile it. If the above script\nis calleddisable_jit_example.py, we can invoke it like so:"
    },
    {
        "Answer": "@torch.jit.script\ndef foo(len):\n    # type: (int) -> torch.Tensor\n    rv = torch.zeros(3, 4)\n    for i in range(len):\n        if i < 10:\n            rv = rv - 1.0\n        else:\n            rv = rv + 1.0\n    return rv\n\nprint(foo.code)\n",
        "Question": "How to use Inspecting Code, give an example?",
        "Id": 405,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "def foo(len: int) -> Tensor:\n    rv = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n    rv0 = rv\n    for i in range(len):\n        if torch.lt(i, 10):\n            rv1 = torch.sub(rv0, 1., 1)\n        else:\n            rv1 = torch.add(rv0, 1., 1)\n        rv0 = rv1\n    return rv0\n",
        "Question": "How to use TorchScript provides a code pretty-printer for allScriptModuleinstances. This\npretty-printer gives an interpretation of the script method\u2019s code as valid\nPython syntax. For example:AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output:, give an example?",
        "Id": 406,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " AScriptModulewith a singleforwardmethod will have an attributecode, which you can use to inspect theScriptModule\u2019s code.\nIf theScriptModulehas more than one method, you will need to access.codeon the method itself and not the module. We can inspect the\ncode of a method namedfooon aScriptModuleby accessing.foo.code.\nThe example above produces this output:"
    },
    {
        "Answer": "@torch.jit.script\ndef foo(len):\n    # type: (int) -> torch.Tensor\n    rv = torch.zeros(3, 4)\n    for i in range(len):\n        if i < 10:\n            rv = rv - 1.0\n        else:\n            rv = rv + 1.0\n    return rv\n\nprint(foo.graph)\n",
        "Question": "How to use Interpreting Graphs, give an example?",
        "Id": 407,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "graph(%len.1 : int):\n  %24 : int = prim::Constant[value=1]()\n  %17 : bool = prim::Constant[value=1]() # test.py:10:5\n  %12 : bool? = prim::Constant()\n  %10 : Device? = prim::Constant()\n  %6 : int? = prim::Constant()\n  %1 : int = prim::Constant[value=3]() # test.py:9:22\n  %2 : int = prim::Constant[value=4]() # test.py:9:25\n  %20 : int = prim::Constant[value=10]() # test.py:11:16\n  %23 : float = prim::Constant[value=1]() # test.py:12:23\n  %4 : int[] = prim::ListConstruct(%1, %2)\n  %rv.1 : Tensor = aten::zeros(%4, %6, %6, %10, %12) # test.py:9:10\n  %rv : Tensor = prim::Loop(%len.1, %17, %rv.1) # test.py:10:5\n    block0(%i.1 : int, %rv.14 : Tensor):\n      %21 : bool = aten::lt(%i.1, %20) # test.py:11:12\n      %rv.13 : Tensor = prim::If(%21) # test.py:11:9\n        block0():\n          %rv.3 : Tensor = aten::sub(%rv.14, %23, %24) # test.py:12:18\n          -> (%rv.3)\n        block1():\n          %rv.6 : Tensor = aten::add(%rv.14, %23, %24) # test.py:14:18\n          -> (%rv.6)\n      -> (%17, %rv.13)\n  return (%rv)\n",
        "Question": "How to use graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup.The example script above produces the graph:, give an example?",
        "Id": 408,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " graphfollows the same rules described in theInspecting Codesection\nwith regard toforwardmethod lookup.The example script above produces the graph:"
    },
    {
        "Answer": "def loop_in_traced_fn(x):\n    result = x[0]\n    for i in range(x.size(0)):\n        result = result * x[i]\n    return result\n\ninputs = (torch.rand(3, 4, 5),)\ncheck_inputs = [(torch.rand(4, 5, 6),), (torch.rand(2, 3, 4),)]\n\ntraced = torch.jit.trace(loop_in_traced_fn, inputs, check_inputs=check_inputs)\n",
        "Question": "How to use One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example:, give an example?",
        "Id": 409,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example:"
    },
    {
        "Answer": "ERROR: Graphs differed across invocations!\nGraph diff:\n\n            graph(%x : Tensor) {\n            %1 : int = prim::Constant[value=0]()\n            %2 : int = prim::Constant[value=0]()\n            %result.1 : Tensor = aten::select(%x, %1, %2)\n            %4 : int = prim::Constant[value=0]()\n            %5 : int = prim::Constant[value=0]()\n            %6 : Tensor = aten::select(%x, %4, %5)\n            %result.2 : Tensor = aten::mul(%result.1, %6)\n            %8 : int = prim::Constant[value=0]()\n            %9 : int = prim::Constant[value=1]()\n            %10 : Tensor = aten::select(%x, %8, %9)\n        -   %result : Tensor = aten::mul(%result.2, %10)\n        +   %result.3 : Tensor = aten::mul(%result.2, %10)\n        ?          ++\n            %12 : int = prim::Constant[value=0]()\n            %13 : int = prim::Constant[value=2]()\n            %14 : Tensor = aten::select(%x, %12, %13)\n        +   %result : Tensor = aten::mul(%result.3, %14)\n        +   %16 : int = prim::Constant[value=0]()\n        +   %17 : int = prim::Constant[value=3]()\n        +   %18 : Tensor = aten::select(%x, %16, %17)\n        -   %15 : Tensor = aten::mul(%result, %14)\n        ?     ^                                 ^\n        +   %19 : Tensor = aten::mul(%result, %18)\n        ?     ^                                 ^\n        -   return (%15);\n        ?             ^\n        +   return (%19);\n        ?             ^\n            }\n",
        "Question": "How to use One way to automatically catch many errors in traces is by usingcheck_inputson thetorch.jit.trace()API.check_inputstakes a list of tuples\nof inputs that will be used to re-trace the computation and verify the\nresults. For example:Gives us the following diagnostic information:, give an example?",
        "Id": 410,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " Gives us the following diagnostic information:"
    },
    {
        "Answer": "def fn(x):\n    result = x[0]\n    for i in range(x.size(0)):\n        result = result * x[i]\n    return result\n\ninputs = (torch.rand(3, 4, 5),)\ncheck_inputs = [(torch.rand(4, 5, 6),), (torch.rand(2, 3, 4),)]\n\nscripted_fn = torch.jit.script(fn)\nprint(scripted_fn.graph)\n#print(str(scripted_fn.graph).strip())\n\nfor input_tuple in [inputs] + check_inputs:\n    torch.testing.assert_allclose(fn(*input_tuple), scripted_fn(*input_tuple))\n",
        "Question": "How to use  , give an example?",
        "Id": 411,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "graph(%x : Tensor) {\n    %5 : bool = prim::Constant[value=1]()\n    %1 : int = prim::Constant[value=0]()\n    %result.1 : Tensor = aten::select(%x, %1, %1)\n    %4 : int = aten::size(%x, %1)\n    %result : Tensor = prim::Loop(%4, %5, %result.1)\n    block0(%i : int, %7 : Tensor) {\n        %10 : Tensor = aten::select(%x, %1, %i)\n        %result.2 : Tensor = aten::mul(%7, %10)\n        -> (%5, %result.2)\n    }\n    return (%result);\n}\n",
        "Question": "How to use In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead:Which produces:, give an example?",
        "Id": 412,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " In this case, data-dependent control flow like this can be captured usingtorch.jit.script()instead:Which produces:"
    },
    {
        "Answer": "def fill_row_zero(x):\n    x[0] = torch.rand(*x.shape[1:2])\n    return x\n\ntraced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),))\nprint(traced.graph)\n",
        "Question": "How  , give an example?",
        "Id": 413,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "fill_row_zero.py:4: TracerWarning: There are 2 live references to the data region being modified when tracing in-place operator copy_ (possibly due to an assignment). This might cause the trace to be incorrect, because all other views that also reference this data will not reflect this change in the trace! On the other hand, if all other views use the same memory chunk, but are disjoint (e.g. are outputs of torch.split), this might still be safe.\n    x[0] = torch.rand(*x.shape[1:2])\nfill_row_zero.py:6: TracerWarning: Output nr 1. of the traced function does not match the corresponding output of the Python function. Detailed error:\nNot within tolerance rtol=1e-05 atol=1e-05 at input[0, 1] (0.09115803241729736 vs. 0.6782537698745728) and 3 other locations (33.00%)\n    traced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),))\ngraph(%0 : Float(3, 4)) {\n    return (%0);\n}\n",
        "Question": "How to use The tracer produces warnings for several problematic patterns in traced\ncomputation. As an example, take a trace of a function that contains an\nin-place assignment on a slice (a view) of a Tensor:Produces several warnings and a graph which simply returns the input:, give an example?",
        "Id": 414,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " Produces several warnings and a graph which simply returns the input:"
    },
    {
        "Answer": "def fill_row_zero(x):\n    x = torch.cat((torch.rand(1, *x.shape[1:2]), x[1:2]), dim=0)\n    return x\n\ntraced = torch.jit.trace(fill_row_zero, (torch.rand(3, 4),))\nprint(traced.graph)\n",
        "Question": "How  , give an example?",
        "Id": 415,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "cpu_model = gpu_model.cpu()\nsample_input_cpu = sample_input_gpu.cpu()\ntraced_cpu = torch.jit.trace(cpu_model, sample_input_cpu)\ntorch.jit.save(traced_cpu, \"cpu.pt\")\n\ntraced_gpu = torch.jit.trace(gpu_model, sample_input_gpu)\ntorch.jit.save(traced_gpu, \"gpu.pt\")\n\n# ... later, when using the model:\n\nif use_gpu:\n  model = torch.jit.load(\"gpu.pt\")\nelse:\n  model = torch.jit.load(\"cpu.pt\")\n\nmodel(input)\n",
        "Question": "How to use First convert your model from GPU to CPU and then save it, like so:, give an example?",
        "Id": 416,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " First convert your model from GPU to CPU and then save it, like so:"
    },
    {
        "Answer": "import torch\n\nclass Model(torch.nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.x = 2\n\n    def forward(self):\n        return self.x\n\nm = torch.jit.script(Model())\n",
        "Question": "How to use Frequently Asked Questions, give an example?",
        "Id": 417,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\n\nmy_model = Model()\nmy_scripted_model = torch.jit.script(my_model)\n",
        "Question": "How to use Migrating to PyTorch 1 2 Recursive Scripting API, give an example?",
        "Id": 418,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "import torch\nimport torch.nn as nn\n\nclass MyModule(nn.Module):\n    def implicitly_compiled_method(self, x):\n        return x + 99\n\n    # `forward` is implicitly decorated with `@torch.jit.export`,\n    # so adding it here would have no effect\n    def forward(self, x):\n        return x + 10\n\n    @torch.jit.export\n    def another_forward(self, x):\n        # When the compiler sees this call, it will compile\n        # `implicitly_compiled_method`\n        return self.implicitly_compiled_method(x)\n\n    def unused_method(self, x):\n        return x - 20\n\n# `m` will contain compiled methods:\n#     `forward`\n#     `another_forward`\n#     `implicitly_compiled_method`\n# `unused_method` will not be compiled since it was not called from\n# any compiled methods and wasn't decorated with `@torch.jit.export`\nm = torch.jit.script(MyModule())\n",
        "Question": "How  , give an example?",
        "Id": 419,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "# Same behavior as pre-PyTorch 1.2\n@torch.jit.script\ndef some_fn():\n    return 2\n\n# Marks a function as ignored, if nothing\n# ever calls it then this has no effect\n@torch.jit.ignore\ndef some_fn2():\n    return 2\n\n# As with ignore, if nothing calls it then it has no effect.\n# If it is called in script it is replaced with an exception.\n@torch.jit.unused\ndef some_fn3():\n  import pdb; pdb.set_trace()\n  return 4\n\n# Doesn't do anything, this function is already\n# the main entry point\n@torch.jit.export\ndef some_fn4():\n    return 2\n",
        "Question": "How  , give an example?",
        "Id": 420,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "from typing import Dict\nimport torch\n\nclass MyModule(torch.jit.ScriptModule):\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.my_dict = torch.jit.Attribute({}, Dict[str, int])\n        self.my_int = torch.jit.Attribute(20, int)\n\nm = MyModule()\n",
        "Question": "How  , give an example?",
        "Id": 421,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "from typing import Dict\n\nclass MyModule(torch.nn.Module):\n    my_dict: Dict[str, int]\n\n    def __init__(self):\n        super(MyModule, self).__init__()\n        # This type cannot be inferred and must be specified\n        self.my_dict = {}\n\n        # The attribute type here is inferred to be `int`\n        self.my_int = 20\n\n    def forward(self):\n        pass\n\nm = torch.jit.script(MyModule())\n",
        "Question": "How  , give an example?",
        "Id": 422,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "class MyModule(torch.jit.ScriptModule):\n    __constants__ = ['my_constant']\n\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.my_constant = 2\n\n    def forward(self):\n        pass\nm = MyModule()\n",
        "Question": "How  , give an example?",
        "Id": 423,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": "try:\n    from typing_extensions import Final\nexcept:\n    # If you don't have `typing_extensions` installed, you can use a\n    # polyfill from `torch.jit`.\n    from torch.jit import Final\n\nclass MyModule(torch.nn.Module):\n\n    my_constant: Final[int]\n\n    def __init__(self):\n        super(MyModule, self).__init__()\n        self.my_constant = 2\n\n    def forward(self):\n        pass\n\nm = torch.jit.script(MyModule())\n",
        "Question": "How to use Old API:New API:, give an example?",
        "Id": 424,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " Old API:New API:"
    },
    {
        "Answer": "import torch\nfrom typing import Dict, Optional\n\n@torch.jit.script\ndef make_dict(flag: bool):\n    x: Dict[str, int] = {}\n    x['hi'] = 2\n    b: Optional[int] = None\n    if flag:\n        b = 2\n    return x, b\n",
        "Question": "How  , give an example?",
        "Id": 425,
        "source": "https://pytorch.org/docs/stable/jit.html",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([1, 2, 3])\n>>> b = torch.tensor([4, 5, 6])\n>>> torch.column_stack((a, b))\ntensor([[1, 4],\n    [2, 5],\n    [3, 6]])\n>>> a = torch.arange(5)\n>>> b = torch.arange(10).reshape(5, 2)\n>>> torch.column_stack((a, b, b))\ntensor([[0, 0, 1, 0, 1],\n        [1, 2, 3, 2, 3],\n        [2, 4, 5, 4, 5],\n        [3, 6, 7, 6, 7],\n        [4, 8, 9, 8, 9]])\n",
        "Question": "How to use torch.column_stack, give an example?",
        "Id": 426,
        "source": "https://pytorch.org/docs/stable/generated/torch.column_stack.html#torch.column_stack",
        "context": " Equivalent totorch.hstack(tensors), except each zero or one dimensional tensortintensorsis first reshaped into a(t.numel(),1)column before being stacked horizontally."
    },
    {
        "Answer": ">>> x=torch.tensor([1,2,3])\n>>> torch.is_tensor(x)\nTrue\n",
        "Question": "How to use torch.is_tensor, give an example?",
        "Id": 427,
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html",
        "context": " Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor."
    },
    {
        "Answer": ">>> torch.set_flush_denormal(True)\nTrue\n>>> torch.tensor([1e-323], dtype=torch.float64)\ntensor([ 0.], dtype=torch.float64)\n>>> torch.set_flush_denormal(False)\nTrue\n>>> torch.tensor([1e-323], dtype=torch.float64)\ntensor(9.88131e-324 *\n       [ 1.0000], dtype=torch.float64)\n",
        "Question": "How to use torch.set_flush_denormal, give an example?",
        "Id": 428,
        "source": "https://pytorch.org/docs/stable/generated/torch.set_flush_denormal.html#torch.set_flush_denormal",
        "context": " ReturnsTrueif your system supports flushing denormal numbers and it\nsuccessfully configures flush denormal mode.set_flush_denormal()is only supported on x86 architectures supporting SSE3."
    },
    {
        "Answer": "# trace\n>>> torch.einsum('ii', torch.randn(4, 4))\ntensor(-1.2104)\n\n# diagonal\n>>> torch.einsum('ii->i', torch.randn(4, 4))\ntensor([-0.1034,  0.7952, -0.2433,  0.4545])\n\n# outer product\n>>> x = torch.randn(5)\n>>> y = torch.randn(4)\n>>> torch.einsum('i,j->ij', x, y)\ntensor([[ 0.1156, -0.2897, -0.3918,  0.4963],\n        [-0.3744,  0.9381,  1.2685, -1.6070],\n        [ 0.7208, -1.8058, -2.4419,  3.0936],\n        [ 0.1713, -0.4291, -0.5802,  0.7350],\n        [ 0.5704, -1.4290, -1.9323,  2.4480]])\n\n# batch matrix multiplication\n>>> As = torch.randn(3,2,5)\n>>> Bs = torch.randn(3,5,4)\n>>> torch.einsum('bij,bjk->bik', As, Bs)\ntensor([[[-1.0564, -1.5904,  3.2023,  3.1271],\n        [-1.6706, -0.8097, -0.8025, -2.1183]],\n\n        [[ 4.2239,  0.3107, -0.5756, -0.2354],\n        [-1.4558, -0.3460,  1.5087, -0.8530]],\n\n        [[ 2.8153,  1.8787, -4.3839, -1.2112],\n        [ 0.3728, -2.1131,  0.0921,  0.8305]]])\n\n# batch permute\n>>> A = torch.randn(2, 3, 4, 5)\n>>> torch.einsum('...ij->...ji', A).shape\ntorch.Size([2, 3, 5, 4])\n\n# equivalent to torch.nn.functional.bilinear\n>>> A = torch.randn(3,5,4)\n>>> l = torch.randn(2,5)\n>>> r = torch.randn(2,4)\n>>> torch.einsum('bn,anm,bm->ba', l, A, r)\ntensor([[-0.3430, -5.2405,  0.4494],\n        [ 0.3311,  5.5201, -3.0356]])\n",
        "Question": "How to use torch.einsum, give an example?",
        "Id": 429,
        "source": "https://pytorch.org/docs/stable/generated/torch.einsum.html#torch.einsum",
        "context": " Equation:"
    },
    {
        "Answer": ">>> start = torch.arange(1., 5.)\n>>> end = torch.empty(4).fill_(10)\n>>> start\ntensor([ 1.,  2.,  3.,  4.])\n>>> end\ntensor([ 10.,  10.,  10.,  10.])\n>>> torch.lerp(start, end, 0.5)\ntensor([ 5.5000,  6.0000,  6.5000,  7.0000])\n>>> torch.lerp(start, end, torch.full_like(start, 0.5))\ntensor([ 5.5000,  6.0000,  6.5000,  7.0000])\n",
        "Question": "How to use torch.lerp, give an example?",
        "Id": 430,
        "source": "https://pytorch.org/docs/stable/generated/torch.lerp.html#torch.lerp",
        "context": " The shapes ofstartandendmust bebroadcastable. Ifweightis a tensor, then\nthe shapes ofweight,start, andendmust bebroadcastable."
    },
    {
        "Answer": ">>> a = torch.tensor((1, 2, -1))\n>>> b = torch.tensor((3, 0, 4))\n>>> torch.maximum(a, b)\ntensor([3, 2, 4])\n",
        "Question": "How to use torch.maximum, give an example?",
        "Id": 431,
        "source": "https://pytorch.org/docs/stable/generated/torch.maximum.html#torch.maximum",
        "context": " "
    },
    {
        "Answer": ">>> import torch\n>>> a = torch.arange(9, dtype= torch.float) - 4\n>>> b = a.reshape((3, 3))\n>>> torch.norm(a)\ntensor(7.7460)\n>>> torch.norm(b)\ntensor(7.7460)\n>>> torch.norm(a, float('inf'))\ntensor(4.)\n>>> torch.norm(b, float('inf'))\ntensor(4.)\n>>> c = torch.tensor([[ 1, 2, 3],[-1, 1, 4]] , dtype= torch.float)\n>>> torch.norm(c, dim=0)\ntensor([1.4142, 2.2361, 5.0000])\n>>> torch.norm(c, dim=1)\ntensor([3.7417, 4.2426])\n>>> torch.norm(c, p=1, dim=1)\ntensor([6., 6.])\n>>> d = torch.arange(8, dtype= torch.float).reshape(2,2,2)\n>>> torch.norm(d, dim=(1,2))\ntensor([ 3.7417, 11.2250])\n>>> torch.norm(d[0, :, :]), torch.norm(d[1, :, :])\n(tensor(3.7417), tensor(11.2250))\n",
        "Question": "How to use torch.norm, give an example?",
        "Id": 432,
        "source": "https://pytorch.org/docs/stable/generated/torch.norm.html#torch.norm",
        "context": " "
    },
    {
        "Answer": ">>> torch.zeros(2, 3)\ntensor([[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]])\n\n>>> torch.zeros(5)\ntensor([ 0.,  0.,  0.,  0.,  0.])\n",
        "Question": "How to use torch.zeros, give an example?",
        "Id": 433,
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros.html#torch.zeros",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(1, 2).bool()\n>>> a\ntensor([[False, True]], dtype=torch.bool)\n>>> torch.any(a)\ntensor(True, dtype=torch.bool)\n>>> a = torch.arange(0, 3)\n>>> a\ntensor([0, 1, 2])\n>>> torch.any(a)\ntensor(True)\n",
        "Question": "How to use torch.any, give an example?",
        "Id": 434,
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4, 2) < 0\n>>> a\ntensor([[ True,  True],\n        [False,  True],\n        [ True,  True],\n        [False, False]])\n>>> torch.any(a, 1)\ntensor([ True,  True,  True, False])\n>>> torch.any(a, 0)\ntensor([True, True])\n",
        "Question": "How  IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput., give an example?",
        "Id": 435,
        "source": "https://pytorch.org/docs/stable/generated/torch.any.html#torch.any",
        "context": " IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput."
    },
    {
        "Answer": ">>> A = torch.randn(2, 3, 3)\n>>> b = torch.randn(2, 3, 1)\n>>> A_LU = torch.lu(A)\n>>> x = torch.lu_solve(b, *A_LU)\n>>> torch.norm(torch.bmm(A, x) - b)\ntensor(1.00000e-07 *\n       2.8312)\n",
        "Question": "How to use torch.lu_solve, give an example?",
        "Id": 436,
        "source": "https://pytorch.org/docs/stable/generated/torch.lu_solve.html#torch.lu_solve",
        "context": " This function supportsfloat,double,cfloatandcdoubledtypes forinput."
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[ 0.0785,  1.5267, -0.8521,  0.4065],\n        [ 0.1598,  0.0788, -0.0745, -1.2700],\n        [ 1.2208,  1.0722, -0.7064,  1.2564],\n        [ 0.0669, -0.2318, -0.8229, -0.9280]])\n\n\n>>> torch.argsort(a, dim=1)\ntensor([[2, 0, 3, 1],\n        [3, 2, 1, 0],\n        [2, 1, 0, 3],\n        [3, 2, 1, 0]])\n",
        "Question": "How to use torch.argsort, give an example?",
        "Id": 437,
        "source": "https://pytorch.org/docs/stable/generated/torch.argsort.html#torch.argsort",
        "context": " This is the second value returned bytorch.sort().  See its documentation\nfor the exact semantics of this method."
    },
    {
        "Answer": ">>> a = torch.randn(10)\n>>> a\ntensor([-0.3449, -1.5447,  0.0685, -1.5104, -1.1706,  0.2259,  1.4696, -1.3284,\n     1.9946, -0.8209])\n>>> torch.cummax(a, dim=0)\ntorch.return_types.cummax(\n    values=tensor([-0.3449, -0.3449,  0.0685,  0.0685,  0.0685,  0.2259,  1.4696,  1.4696,\n     1.9946,  1.9946]),\n    indices=tensor([0, 0, 2, 2, 2, 5, 6, 6, 8, 8]))\n",
        "Question": "How to use torch.cummax, give an example?",
        "Id": 438,
        "source": "https://pytorch.org/docs/stable/generated/torch.cummax.html#torch.cummax",
        "context": " "
    },
    {
        "Answer": "out[i][j][k] = input[index[i][j][k]][j][k]  # if dim == 0\nout[i][j][k] = input[i][index[i][j][k]][k]  # if dim == 1\nout[i][j][k] = input[i][j][index[i][j][k]]  # if dim == 2\n",
        "Question": "How to use torch.gather, give an example?",
        "Id": 439,
        "source": "https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather",
        "context": " For a 3-D tensor the output is specified by:"
    },
    {
        "Answer": ">>> t = torch.tensor([[1, 2], [3, 4]])\n>>> torch.gather(t, 1, torch.tensor([[0, 0], [1, 0]]))\ntensor([[ 1,  1],\n        [ 4,  3]])\n",
        "Question": "How  inputandindexmust have the same number of dimensions.\nIt is also required thatindex.size(d)<=input.size(d)for all\ndimensionsd!=dim.outwill have the same shape asindex.\nNote thatinputandindexdo not broadcast against each other., give an example?",
        "Id": 440,
        "source": "https://pytorch.org/docs/stable/generated/torch.gather.html#torch.gather",
        "context": " inputandindexmust have the same number of dimensions.\nIt is also required thatindex.size(d)<=input.size(d)for all\ndimensionsd!=dim.outwill have the same shape asindex.\nNote thatinputandindexdo not broadcast against each other."
    },
    {
        "Answer": ">>> torch.isreal(torch.tensor([1, 1+1j, 2+0j]))\ntensor([True, False, True])\n",
        "Question": "How to use torch.isreal, give an example?",
        "Id": 441,
        "source": "https://pytorch.org/docs/stable/generated/torch.isreal.html#torch.isreal",
        "context": " "
    },
    {
        "Answer": ">>> gain = nn.init.calculate_gain('leaky_relu', 0.2)  # leaky_relu with negative_slope=0.2\n",
        "Question": "How to use torch.nn.init.calculate_gain, give an example?",
        "Id": 442,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.uniform_(w)\n",
        "Question": "How to use torch.nn.init.uniform_, give an example?",
        "Id": 443,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.normal_(w)\n",
        "Question": "How to use torch.nn.init.normal_, give an example?",
        "Id": 444,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.constant_(w, 0.3)\n",
        "Question": "How to use torch.nn.init.constant_, give an example?",
        "Id": 445,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.ones_(w)\n",
        "Question": "How to use torch.nn.init.ones_, give an example?",
        "Id": 446,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.zeros_(w)\n",
        "Question": "How to use torch.nn.init.zeros_, give an example?",
        "Id": 447,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.eye_(w)\n",
        "Question": "How to use torch.nn.init.eye_, give an example?",
        "Id": 448,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 16, 5, 5)\n>>> nn.init.dirac_(w)\n>>> w = torch.empty(3, 24, 5, 5)\n>>> nn.init.dirac_(w, 3)\n",
        "Question": "How to use torch.nn.init.dirac_, give an example?",
        "Id": 449,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.xavier_uniform_(w, gain=nn.init.calculate_gain('relu'))\n",
        "Question": "How to use torch.nn.init.xavier_uniform_, give an example?",
        "Id": 450,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " Also known as Glorot initialization."
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.xavier_normal_(w)\n",
        "Question": "How to use torch.nn.init.xavier_normal_, give an example?",
        "Id": 451,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " Also known as Glorot initialization."
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.kaiming_uniform_(w, mode='fan_in', nonlinearity='relu')\n",
        "Question": "How to use torch.nn.init.kaiming_uniform_, give an example?",
        "Id": 452,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " Also known as He initialization."
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.kaiming_normal_(w, mode='fan_out', nonlinearity='relu')\n",
        "Question": "How to use torch.nn.init.kaiming_normal_, give an example?",
        "Id": 453,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " Also known as He initialization."
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.orthogonal_(w)\n",
        "Question": "How to use torch.nn.init.orthogonal_, give an example?",
        "Id": 454,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> w = torch.empty(3, 5)\n>>> nn.init.sparse_(w, sparsity=0.1)\n",
        "Question": "How to use torch.nn.init.sparse_, give an example?",
        "Id": 455,
        "source": "https://pytorch.org/docs/stable/nn.init.html",
        "context": " "
    },
    {
        "Answer": ">>> M = torch.randn(3, 5)\n>>> batch1 = torch.randn(10, 3, 4)\n>>> batch2 = torch.randn(10, 4, 5)\n>>> torch.addbmm(M, batch1, batch2)\ntensor([[  6.6311,   0.0503,   6.9768, -12.0362,  -2.1653],\n        [ -4.8185,  -1.4255,  -6.6760,   8.9453,   2.5743],\n        [ -3.8202,   4.3691,   1.0943,  -1.1109,   5.4730]])\n",
        "Question": "How to use torch.addbmm, give an example?",
        "Id": 456,
        "source": "https://pytorch.org/docs/stable/generated/torch.addbmm.html#torch.addbmm",
        "context": " This operator supportsTensorFloat32."
    },
    {
        "Answer": "torch.linalg.lstsq(A, B).solution == A.pinv() @ B\n",
        "Question": "How to use torch.linalg.pinv, give an example?",
        "Id": 457,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv",
        "context": " Consider usingtorch.linalg.lstsq()if possible for multiplying a matrix on the left by\nthe the pseudoinverse, as:"
    },
    {
        "Answer": ">>> A = torch.randn(3, 5)\n>>> A\ntensor([[ 0.5495,  0.0979, -1.4092, -0.1128,  0.4132],\n        [-1.1143, -0.3662,  0.3042,  1.6374, -0.9294],\n        [-0.3269, -0.5745, -0.0382, -0.5922, -0.6759]])\n>>> torch.linalg.pinv(A)\ntensor([[ 0.0600, -0.1933, -0.2090],\n        [-0.0903, -0.0817, -0.4752],\n        [-0.7124, -0.1631, -0.2272],\n        [ 0.1356,  0.3933, -0.5023],\n        [-0.0308, -0.1725, -0.5216]])\n\nBatched linalg.pinv example\n>>> A = torch.randn(2, 6, 3)\n>>> B = torch.linalg.pinv(A)\n>>> torch.matmul(B, A).round()\ntensor([[[1., -0., 0.],\n         [0., 1., -0.],\n         [0., 0., 1.]],\n\n        [[1., -0., 0.],\n         [-0., 1., 0.],\n         [-0., -0., 1.]]])\n\nHermitian input example\n>>> A = torch.randn(3, 3, dtype=torch.complex64)\n>>> A = A + A.t().conj()  # creates a Hermitian matrix\n>>> B = torch.linalg.pinv(A, hermitian=True)\n>>> torch.matmul(B, A)\ntensor([[ 1.0000e+00+0.0000e+00j, -1.1921e-07-2.3842e-07j,\n        5.9605e-08-2.3842e-07j],\n        [ 5.9605e-08+2.3842e-07j,  1.0000e+00+2.3842e-07j,\n        -4.7684e-07+1.1921e-07j],\n        [-1.1921e-07+0.0000e+00j, -2.3842e-07-2.9802e-07j,\n        1.0000e+00-1.7897e-07j]])\n\nNon-default rcond example\n>>> rcond = 0.5\n>>> A = torch.randn(3, 3)\n>>> torch.linalg.pinv(A)\ntensor([[ 0.2971, -0.4280, -2.0111],\n        [-0.0090,  0.6426, -0.1116],\n        [-0.7832, -0.2465,  1.0994]])\n>>> torch.linalg.pinv(A, rcond)\ntensor([[-0.2672, -0.2351, -0.0539],\n        [-0.0211,  0.6467, -0.0698],\n        [-0.4400, -0.3638, -0.0910]])\n\nMatrix-wise rcond example\n>>> A = torch.randn(5, 6, 2, 3, 3)\n>>> rcond = torch.rand(2)  # different rcond values for each matrix in a[:, :, 0] and a[:, :, 1]\n>>> torch.linalg.pinv(A, rcond)\n>>> rcond = torch.randn(5, 6, 2) # different rcond value for each matrix in 'a'\n>>> torch.linalg.pinv(A, rcond)\n",
        "Question": "How  The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation., give an example?",
        "Id": 458,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.pinv.html#torch.linalg.pinv",
        "context": " The singular values (or the norm of the eigenvalues whenhermitian= True)\nthat are below the specifiedrcondthreshold are treated as zero and discarded in the computation."
    },
    {
        "Answer": ">>> torch.result_type(torch.tensor([1, 2], dtype=torch.int), 1.0)\ntorch.float32\n>>> torch.result_type(torch.tensor([1, 2], dtype=torch.uint8), torch.tensor(1))\ntorch.uint8\n",
        "Question": "How to use torch.result_type, give an example?",
        "Id": 459,
        "source": "https://pytorch.org/docs/stable/generated/torch.result_type.html#torch.result_type",
        "context": " "
    },
    {
        "Answer": ">>> # initial default for floating point is torch.float32\n>>> torch.tensor([1.2, 3]).dtype\ntorch.float32\n>>> # initial default for floating point is torch.complex64\n>>> torch.tensor([1.2, 3j]).dtype\ntorch.complex64\n>>> torch.set_default_dtype(torch.float64)\n>>> torch.tensor([1.2, 3]).dtype    # a new floating point tensor\ntorch.float64\n>>> torch.tensor([1.2, 3j]).dtype   # a new complex tensor\ntorch.complex128\n",
        "Question": "How to use torch.set_default_dtype, give an example?",
        "Id": 460,
        "source": "https://pytorch.org/docs/stable/generated/torch.set_default_dtype.html#torch.set_default_dtype",
        "context": " The default floating point dtype is initiallytorch.float32."
    },
    {
        "Answer": ">>> a = torch.randn(10)\n>>> a\ntensor([-0.2284, -0.6628,  0.0975,  0.2680, -1.3298, -0.4220, -0.3885,  1.1762,\n     0.9165,  1.6684])\n>>> torch.cummin(a, dim=0)\ntorch.return_types.cummin(\n    values=tensor([-0.2284, -0.6628, -0.6628, -0.6628, -1.3298, -1.3298, -1.3298, -1.3298,\n    -1.3298, -1.3298]),\n    indices=tensor([0, 1, 1, 1, 4, 4, 4, 4, 4, 4]))\n",
        "Question": "How to use torch.cummin, give an example?",
        "Id": 461,
        "source": "https://pytorch.org/docs/stable/generated/torch.cummin.html#torch.cummin",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randint(10, (5,))\n>>> a\ntensor([6, 5, 1, 0, 2])\n>>> b = a + (torch.randn(50, 1) * 5).long()\n>>> torch.mode(b, 0)\ntorch.return_types.mode(values=tensor([6, 5, 1, 0, 2]), indices=tensor([2, 2, 2, 2, 2]))\n",
        "Question": "How to use torch.mode, give an example?",
        "Id": 462,
        "source": "https://pytorch.org/docs/stable/generated/torch.mode.html#torch.mode",
        "context": " IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput."
    },
    {
        "Answer": ">>> x=torch.tensor([1,2,3])\n>>> torch.is_tensor(x)\nTrue\n",
        "Question": "How  Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor., give an example?",
        "Id": 463,
        "source": "https://pytorch.org/docs/stable/generated/torch.is_tensor.html#torch.is_tensor",
        "context": " Note that this function is simply doingisinstance(obj,Tensor).\nUsing thatisinstancecheck is better for typechecking with mypy,\nand more explicit - so it\u2019s recommended to use that instead ofis_tensor."
    },
    {
        "Answer": ">>> import torch.nn as nn\n>>> from torch.distributed.optim import ZeroRedundancyOptimizer\n>>> from torch.nn.parallel import DistributedDataParallel as DDP\n\n>>> model = nn.Sequential(*[nn.Linear(2000, 2000).to(rank) for _ in range(20)])\n>>> ddp = DDP(model, device_ids=[rank])\n>>> opt = ZeroRedundancyOptimizer(\n>>>     ddp.parameters(),\n>>>     optimizer_class=torch.optim.Adam,\n>>>     lr=0.01\n>>> )\n>>> ddp(inputs).sum().backward()\n>>> opt.step()\n",
        "Question": "How to use torch.distributed.optim.ZeroRedundancyOptimizer, give an example?",
        "Id": 464,
        "source": "https://pytorch.org/docs/stable/distributed.optim.html",
        "context": " ZeroRedundancyOptimizeruse a greedy algorithm to pack a number of\nparameters at each rank. Each parameter belongs to a single rank and is not\ndivided among ranks. The partition is arbitrary and might not match the\nthe parameter registration or usage order."
    },
    {
        "Answer": ">>> torch.arange(5)\ntensor([ 0,  1,  2,  3,  4])\n>>> torch.arange(1, 4)\ntensor([ 1,  2,  3])\n>>> torch.arange(1, 2.5, 0.5)\ntensor([ 1.0000,  1.5000,  2.0000])\n",
        "Question": "How to use torch.arange, give an example?",
        "Id": 465,
        "source": "https://pytorch.org/docs/stable/generated/torch.arange.html#torch.arange",
        "context": " Note that non-integerstepis subject to floating point rounding errors when\ncomparing againstend; to avoid inconsistency, we advise adding a small epsilon toendin such cases."
    },
    {
        "Answer": ">>> a = torch.hypot(torch.tensor([4.0]), torch.tensor([3.0, 4.0, 5.0]))\ntensor([5.0000, 5.6569, 6.4031])\n",
        "Question": "How to use torch.hypot, give an example?",
        "Id": 466,
        "source": "https://pytorch.org/docs/stable/generated/torch.hypot.html#torch.hypot",
        "context": " The shapes ofinputandothermust bebroadcastable."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 467,
        "source": "https://pytorch.org/docs/stable/torch.html#in-place-random-sampling",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.randn(3, 3)\n>>> x\ntensor([[ 0.9039,  0.6291,  1.0795],\n        [ 0.1586,  2.1939, -0.4900],\n        [-0.1909, -0.7503,  1.9355]])\n>>> t = torch.as_strided(x, (2, 2), (1, 2))\n>>> t\ntensor([[0.9039, 1.0795],\n        [0.6291, 0.1586]])\n>>> t = torch.as_strided(x, (2, 2), (1, 2), 1)\ntensor([[0.6291, 0.1586],\n        [1.0795, 2.1939]])\n",
        "Question": "How to use torch.as_strided, give an example?",
        "Id": 468,
        "source": "https://pytorch.org/docs/stable/generated/torch.as_strided.html#torch.as_strided",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.randn(2, 3)\n>>> x\ntensor([[ 1.0028, -0.9893,  0.5809],\n        [-0.1669,  0.7299,  0.4942]])\n>>> torch.transpose(x, 0, 1)\ntensor([[ 1.0028, -0.1669],\n        [-0.9893,  0.7299],\n        [ 0.5809,  0.4942]])\n",
        "Question": "How to use torch.transpose, give an example?",
        "Id": 469,
        "source": "https://pytorch.org/docs/stable/generated/torch.transpose.html#torch.transpose",
        "context": " The resultingouttensor shares its underlying storage with theinputtensor, so changing the content of one would change the content\nof the other."
    },
    {
        "Answer": ">>> a = torch.randn(4, 3)\n>>> a\ntensor([[-0.3956,  1.1455,  1.6895],\n        [-0.5849,  1.3672,  0.3599],\n        [-1.1626,  0.7180, -0.0521],\n        [-0.1339,  0.9902, -2.0225]])\n>>> b = torch.randn(4, 3)\n>>> b\ntensor([[-0.0257, -1.4725, -1.2251],\n        [-1.1479, -0.7005, -1.9757],\n        [-1.3904,  0.3726, -1.1836],\n        [-0.9688, -0.7153,  0.2159]])\n>>> torch.cross(a, b, dim=1)\ntensor([[ 1.0844, -0.5281,  0.6120],\n        [-2.4490, -1.5687,  1.9792],\n        [-0.8304, -1.3037,  0.5650],\n        [-1.2329,  1.9883,  1.0551]])\n>>> torch.cross(a, b)\ntensor([[ 1.0844, -0.5281,  0.6120],\n        [-2.4490, -1.5687,  1.9792],\n        [-0.8304, -1.3037,  0.5650],\n        [-1.2329,  1.9883,  1.0551]])\n",
        "Question": "How to use torch.cross, give an example?",
        "Id": 470,
        "source": "https://pytorch.org/docs/stable/generated/torch.cross.html#torch.cross",
        "context": " Ifdimis not given, it defaults to the first dimension found with the\nsize 3. Note that this might be unexpected."
    },
    {
        "Answer": ">>> x = torch.arange(4).view(2, 2)\n>>> x\ntensor([[0, 1],\n        [2, 3]])\n>>> torch.rot90(x, 1, [0, 1])\ntensor([[1, 3],\n        [0, 2]])\n\n>>> x = torch.arange(8).view(2, 2, 2)\n>>> x\ntensor([[[0, 1],\n         [2, 3]],\n\n        [[4, 5],\n         [6, 7]]])\n>>> torch.rot90(x, 1, [1, 2])\ntensor([[[1, 3],\n         [0, 2]],\n\n        [[5, 7],\n         [4, 6]]])\n",
        "Question": "How to use torch.rot90, give an example?",
        "Id": 471,
        "source": "https://pytorch.org/docs/stable/generated/torch.rot90.html#torch.rot90",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 472,
        "source": "https://pytorch.org/docs/stable/torch.html#pointwise-ops",
        "context": " "
    },
    {
        "Answer": "self[index[i][j][k]][j][k] += src[i][j][k]  # if dim == 0\nself[i][index[i][j][k]][k] += src[i][j][k]  # if dim == 1\nself[i][j][index[i][j][k]] += src[i][j][k]  # if dim == 2\n",
        "Question": "How to use torch.Tensor.scatter_add_, give an example?",
        "Id": 473,
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_",
        "context": " For a 3-D tensor,selfis updated as:"
    },
    {
        "Answer": ">>> src = torch.ones((2, 5))\n>>> index = torch.tensor([[0, 1, 2, 0, 0]])\n>>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\ntensor([[1., 0., 0., 1., 1.],\n        [0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0.]])\n>>> index = torch.tensor([[0, 1, 2, 0, 0], [0, 1, 2, 2, 2]])\n>>> torch.zeros(3, 5, dtype=src.dtype).scatter_add_(0, index, src)\ntensor([[2., 0., 0., 1., 1.],\n        [0., 2., 0., 0., 0.],\n        [0., 0., 2., 1., 1.]])\n",
        "Question": "How  self,indexandsrcshould have same number of\ndimensions. It is also required thatindex.size(d)<=src.size(d)for all\ndimensionsd, and thatindex.size(d)<=self.size(d)for all dimensionsd!=dim. Note thatindexandsrcdo not broadcast., give an example?",
        "Id": 474,
        "source": "https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_add_.html#torch.Tensor.scatter_add_",
        "context": " self,indexandsrcshould have same number of\ndimensions. It is also required thatindex.size(d)<=src.size(d)for all\ndimensionsd, and thatindex.size(d)<=self.size(d)for all dimensionsd!=dim. Note thatindexandsrcdo not broadcast."
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a\ntensor([[ 0.2309,  0.5207,  2.0049],\n        [ 0.2072, -1.0680,  0.6602],\n        [ 0.3480, -0.5211, -0.4573]])\n>>> torch.triu(a)\ntensor([[ 0.2309,  0.5207,  2.0049],\n        [ 0.0000, -1.0680,  0.6602],\n        [ 0.0000,  0.0000, -0.4573]])\n>>> torch.triu(a, diagonal=1)\ntensor([[ 0.0000,  0.5207,  2.0049],\n        [ 0.0000,  0.0000,  0.6602],\n        [ 0.0000,  0.0000,  0.0000]])\n>>> torch.triu(a, diagonal=-1)\ntensor([[ 0.2309,  0.5207,  2.0049],\n        [ 0.2072, -1.0680,  0.6602],\n        [ 0.0000, -0.5211, -0.4573]])\n\n>>> b = torch.randn(4, 6)\n>>> b\ntensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n        [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],\n        [ 0.4333,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],\n        [-0.9888,  1.0679, -1.3337, -1.6556,  0.4798,  0.2830]])\n>>> torch.triu(b, diagonal=1)\ntensor([[ 0.0000, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n        [ 0.0000,  0.0000, -1.2919,  1.3378, -0.1768, -1.0857],\n        [ 0.0000,  0.0000,  0.0000, -1.0432,  0.9348, -0.4410],\n        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.4798,  0.2830]])\n>>> torch.triu(b, diagonal=-1)\ntensor([[ 0.5876, -0.0794, -1.8373,  0.6654,  0.2604,  1.5235],\n        [-0.2447,  0.9556, -1.2919,  1.3378, -0.1768, -1.0857],\n        [ 0.0000,  0.3146,  0.6576, -1.0432,  0.9348, -0.4410],\n        [ 0.0000,  0.0000, -1.3337, -1.6556,  0.4798,  0.2830]])\n",
        "Question": "How to use torch.triu, give an example?",
        "Id": 475,
        "source": "https://pytorch.org/docs/stable/generated/torch.triu.html#torch.triu",
        "context": " The argumentdiagonalcontrols which diagonal to consider. Ifdiagonal= 0, all elements on and above the main diagonal are\nretained. A positive value excludes just as many diagonals above the main\ndiagonal, and similarly a negative value includes just as many diagonals below\nthe main diagonal. The main diagonal are the set of indices{(i,i)}\\lbrace (i, i) \\rbrace{(i,i)}fori\u2208[0,min\u2061{d1,d2}\u22121]i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]i\u2208[0,min{d1\u200b,d2\u200b}\u22121]whered1,d2d_{1}, d_{2}d1\u200b,d2\u200bare the dimensions of the matrix."
    },
    {
        "Answer": ">>> a = torch.tensor([1, 0.5])\n>>> torch.polygamma(1, a)\ntensor([1.64493, 4.9348])\n>>> torch.polygamma(2, a)\ntensor([ -2.4041, -16.8288])\n>>> torch.polygamma(3, a)\ntensor([ 6.4939, 97.4091])\n>>> torch.polygamma(4, a)\ntensor([ -24.8863, -771.4742])\n",
        "Question": "How to use torch.polygamma, give an example?",
        "Id": 476,
        "source": "https://pytorch.org/docs/stable/generated/torch.polygamma.html#torch.polygamma",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([[-0.8166, -1.3802, -0.3560]])\n>>> torch.var(a, unbiased=False)\ntensor(0.1754)\n",
        "Question": "How to use torch.var, give an example?",
        "Id": 477,
        "source": "https://pytorch.org/docs/stable/generated/torch.var.html#torch.var",
        "context": " IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction."
    },
    {
        "Answer": ">>> a = torch.arange(-0.5, 1, 0.5)\n>>> a\ntensor([-0.5000,  0.0000,  0.5000])\n>>> torch.special.entr(a)\ntensor([  -inf, 0.0000, 0.3466])\n",
        "Question": "How  , give an example?",
        "Id": 478,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erf(torch.tensor([0, -1., 10.]))\ntensor([ 0.0000, -0.8427,  1.0000])\n",
        "Question": "How  , give an example?",
        "Id": 479,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n",
        "Question": "How  , give an example?",
        "Id": 480,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n",
        "Question": "How  , give an example?",
        "Id": 481,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(4)\n>>> t\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n>>> torch.special.expit(t)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
        "Question": "How  , give an example?",
        "Id": 482,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n",
        "Question": "How  , give an example?",
        "Id": 483,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\ntensor([ 1.,  2.,  8., 16.])\n",
        "Question": "How  , give an example?",
        "Id": 484,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.special.gammaln(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How  , give an example?",
        "Id": 485,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.i0e(torch.arange(5, dtype=torch.float32))\ntensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])\n",
        "Question": "How  , give an example?",
        "Id": 486,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n>>> torch.special.logit(a, eps=1e-6)\ntensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
        "Question": "How  , give an example?",
        "Id": 487,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.special.xlog1py(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.special.xlog1py(x, y)\ntensor([1.3863, 2.1972, 2.0794])\n>>> torch.special.xlog1py(x, 4)\ntensor([1.6094, 3.2189, 4.8283])\n>>> torch.special.xlog1py(2, y)\ntensor([2.7726, 2.1972, 1.3863])\n",
        "Question": "How  Similar to SciPy\u2019sscipy.special.xlog1py., give an example?",
        "Id": 488,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erf",
        "context": " Similar to SciPy\u2019sscipy.special.xlog1py."
    },
    {
        "Answer": ">>> torch.allclose(torch.tensor([10000., 1e-07]), torch.tensor([10000.1, 1e-08]))\nFalse\n>>> torch.allclose(torch.tensor([10000., 1e-08]), torch.tensor([10000.1, 1e-09]))\nTrue\n>>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]))\nFalse\n>>> torch.allclose(torch.tensor([1.0, float('nan')]), torch.tensor([1.0, float('nan')]), equal_nan=True)\nTrue\n",
        "Question": "How to use torch.allclose, give an example?",
        "Id": 489,
        "source": "https://pytorch.org/docs/stable/generated/torch.allclose.html#torch.allclose",
        "context": " elementwise, for all elements ofinputandother. The behaviour of this function is analogous tonumpy.allclose"
    },
    {
        "Answer": ">>> # vector x vector\n>>> tensor1 = torch.randn(3)\n>>> tensor2 = torch.randn(3)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([])\n>>> # matrix x vector\n>>> tensor1 = torch.randn(3, 4)\n>>> tensor2 = torch.randn(4)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([3])\n>>> # batched matrix x broadcasted vector\n>>> tensor1 = torch.randn(10, 3, 4)\n>>> tensor2 = torch.randn(4)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([10, 3])\n>>> # batched matrix x batched matrix\n>>> tensor1 = torch.randn(10, 3, 4)\n>>> tensor2 = torch.randn(10, 4, 5)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([10, 3, 5])\n>>> # batched matrix x broadcasted matrix\n>>> tensor1 = torch.randn(10, 3, 4)\n>>> tensor2 = torch.randn(4, 5)\n>>> torch.matmul(tensor1, tensor2).size()\ntorch.Size([10, 3, 5])\n",
        "Question": "How to use torch.matmul, give an example?",
        "Id": 490,
        "source": "https://pytorch.org/docs/stable/generated/torch.matmul.html#torch.matmul",
        "context": " This operator supportsTensorFloat32."
    },
    {
        "Answer": ">>> x = torch.zeros(3,3)\n>>> x[torch.randn(3,3) > 0.5] = 1\n>>> x\ntensor([[0., 1., 1.],\n        [0., 0., 0.],\n        [0., 0., 1.]])\n>>> torch.count_nonzero(x)\ntensor(3)\n>>> torch.count_nonzero(x, dim=0)\ntensor([0, 1, 2])\n",
        "Question": "How to use torch.count_nonzero, give an example?",
        "Id": 491,
        "source": "https://pytorch.org/docs/stable/generated/torch.count_nonzero.html#torch.count_nonzero",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([4, 5, 6])\n>>> grid_x, grid_y = torch.meshgrid(x, y)\n>>> grid_x\ntensor([[1, 1, 1],\n        [2, 2, 2],\n        [3, 3, 3]])\n>>> grid_y\ntensor([[4, 5, 6],\n        [4, 5, 6],\n        [4, 5, 6]])\n",
        "Question": "How to use torch.meshgrid, give an example?",
        "Id": 492,
        "source": "https://pytorch.org/docs/stable/generated/torch.meshgrid.html#torch.meshgrid",
        "context": " "
    },
    {
        "Answer": ">>> torch.is_nonzero(torch.tensor([0.]))\nFalse\n>>> torch.is_nonzero(torch.tensor([1.5]))\nTrue\n>>> torch.is_nonzero(torch.tensor([False]))\nFalse\n>>> torch.is_nonzero(torch.tensor([3]))\nTrue\n>>> torch.is_nonzero(torch.tensor([1, 3, 5]))\nTraceback (most recent call last):\n...\nRuntimeError: bool value of Tensor with more than one value is ambiguous\n>>> torch.is_nonzero(torch.tensor([]))\nTraceback (most recent call last):\n...\nRuntimeError: bool value of Tensor with no values is ambiguous\n",
        "Question": "How to use torch.is_nonzero, give an example?",
        "Id": 493,
        "source": "https://pytorch.org/docs/stable/generated/torch.is_nonzero.html#torch.is_nonzero",
        "context": " "
    },
    {
        "Answer": ">>> torch.tensor([[1., -1.], [1., -1.]])\ntensor([[ 1.0000, -1.0000],\n        [ 1.0000, -1.0000]])\n>>> torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\ntensor([[ 1,  2,  3],\n        [ 4,  5,  6]])\n",
        "Question": "How to use A tensor can be constructed from a Pythonlistor sequence using thetorch.tensor()constructor:, give an example?",
        "Id": 494,
        "source": "https://pytorch.org/docs/stable/tensors.html",
        "context": " A tensor can be constructed from a Pythonlistor sequence using thetorch.tensor()constructor:"
    },
    {
        "Answer": ">>> torch.zeros([2, 4], dtype=torch.int32)\ntensor([[ 0,  0,  0,  0],\n        [ 0,  0,  0,  0]], dtype=torch.int32)\n>>> cuda0 = torch.device('cuda:0')\n>>> torch.ones([2, 4], dtype=torch.float64, device=cuda0)\ntensor([[ 1.0000,  1.0000,  1.0000,  1.0000],\n        [ 1.0000,  1.0000,  1.0000,  1.0000]], dtype=torch.float64, device='cuda:0')\n",
        "Question": "How to use A tensor can be constructed from a Pythonlistor sequence using thetorch.tensor()constructor:A tensor of specific data type can be constructed by passing atorch.dtypeand/or atorch.deviceto a\nconstructor or tensor creation op:, give an example?",
        "Id": 495,
        "source": "https://pytorch.org/docs/stable/tensors.html",
        "context": " A tensor of specific data type can be constructed by passing atorch.dtypeand/or atorch.deviceto a\nconstructor or tensor creation op:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n>>> print(x[1][2])\ntensor(6)\n>>> x[0][1] = 8\n>>> print(x)\ntensor([[ 1,  8,  3],\n        [ 4,  5,  6]])\n",
        "Question": "How to use For more information about building Tensors, seeCreation OpsThe contents of a tensor can be accessed and modified using Python\u2019s indexing\nand slicing notation:, give an example?",
        "Id": 496,
        "source": "https://pytorch.org/docs/stable/tensors.html",
        "context": " For more information about building Tensors, seeCreation OpsThe contents of a tensor can be accessed and modified using Python\u2019s indexing\nand slicing notation:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1]])\n>>> x\ntensor([[ 1]])\n>>> x.item()\n1\n>>> x = torch.tensor(2.5)\n>>> x\ntensor(2.5000)\n>>> x.item()\n2.5\n",
        "Question": "How to use The contents of a tensor can be accessed and modified using Python\u2019s indexing\nand slicing notation:Usetorch.Tensor.item()to get a Python number from a tensor containing a\nsingle value:, give an example?",
        "Id": 497,
        "source": "https://pytorch.org/docs/stable/tensors.html",
        "context": " The contents of a tensor can be accessed and modified using Python\u2019s indexing\nand slicing notation:Usetorch.Tensor.item()to get a Python number from a tensor containing a\nsingle value:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n>>> out = x.pow(2).sum()\n>>> out.backward()\n>>> x.grad\ntensor([[ 2.0000, -2.0000],\n        [ 2.0000,  2.0000]])\n",
        "Question": "How to use For more information about indexing, seeIndexing, Slicing, Joining, Mutating OpsA tensor can be created withrequires_grad=Trueso thattorch.autogradrecords operations on them for automatic differentiation., give an example?",
        "Id": 498,
        "source": "https://pytorch.org/docs/stable/tensors.html",
        "context": " For more information about indexing, seeIndexing, Slicing, Joining, Mutating OpsA tensor can be created withrequires_grad=Trueso thattorch.autogradrecords operations on them for automatic differentiation."
    },
    {
        "Answer": ">>> i = [[0, 1, 1],\n         [2, 0, 2]]\n>>> v =  [3, 4, 5]\n>>> s = torch.sparse_coo_tensor(i, v, (2, 3))\n>>> s\ntensor(indices=tensor([[0, 1, 1],\n                       [2, 0, 2]]),\n       values=tensor([3, 4, 5]),\n       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n>>> s.to_dense()\ntensor([[0, 0, 3],\n        [4, 0, 5]])\n",
        "Question": "How to use A sparse COO tensor can be constructed by providing the two tensors of\nindices and values, as well as the size of the sparse tensor (when it\ncannot be inferred from the indices and values tensors) to a functiontorch.sparse_coo_tensor().Suppose we want to define a sparse tensor with the entry 3 at location\n(0, 2), entry 4 at location (1, 0), and entry 5 at location (1, 2).\nUnspecified elements are assumed to have the same value, fill value,\nwhich is zero by default. We would then write:, give an example?",
        "Id": 499,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Suppose we want to define a sparse tensor with the entry 3 at location\n(0, 2), entry 4 at location (1, 0), and entry 5 at location (1, 2).\nUnspecified elements are assumed to have the same value, fill value,\nwhich is zero by default. We would then write:"
    },
    {
        "Answer": ">>> i = [[0, 2], [1, 0], [1, 2]]\n>>> v =  [3,      4,      5    ]\n>>> s = torch.sparse_coo_tensor(list(zip(*i)), v, (2, 3))\n>>> # Or another equivalent formulation to get s\n>>> s = torch.sparse_coo_tensor(torch.tensor(i).t(), v, (2, 3))\n>>> torch.sparse_coo_tensor(i.t(), v, torch.Size([2,3])).to_dense()\ntensor([[0, 0, 3],\n        [4, 0, 5]])\n",
        "Question": "How to use Suppose we want to define a sparse tensor with the entry 3 at location\n(0, 2), entry 4 at location (1, 0), and entry 5 at location (1, 2).\nUnspecified elements are assumed to have the same value, fill value,\nwhich is zero by default. We would then write:Note that the inputiis NOT a list of index tuples.  If you want\nto write your indices this way, you should transpose before passing them to\nthe sparse constructor:, give an example?",
        "Id": 500,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Suppose we want to define a sparse tensor with the entry 3 at location\n(0, 2), entry 4 at location (1, 0), and entry 5 at location (1, 2).\nUnspecified elements are assumed to have the same value, fill value,\nwhich is zero by default. We would then write:Note that the inputiis NOT a list of index tuples.  If you want\nto write your indices this way, you should transpose before passing them to\nthe sparse constructor:"
    },
    {
        "Answer": ">>> torch.sparse_coo_tensor(size=(2, 3))\ntensor(indices=tensor([], size=(2, 0)),\n       values=tensor([], size=(0,)),\n       size=(2, 3), nnz=0, layout=torch.sparse_coo)\n",
        "Question": "How to use Note that the inputiis NOT a list of index tuples.  If you want\nto write your indices this way, you should transpose before passing them to\nthe sparse constructor:An empty sparse COO tensor can be constructed by specifying its size\nonly:, give an example?",
        "Id": 501,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Note that the inputiis NOT a list of index tuples.  If you want\nto write your indices this way, you should transpose before passing them to\nthe sparse constructor:An empty sparse COO tensor can be constructed by specifying its size\nonly:"
    },
    {
        "Answer": ">>> i = [[0, 1, 1],\n         [2, 0, 2]]\n>>> v =  [[3, 4], [5, 6], [7, 8]]\n>>> s = torch.sparse_coo_tensor(i, v, (2, 3, 2))\n>>> s\ntensor(indices=tensor([[0, 1, 1],\n                       [2, 0, 2]]),\n       values=tensor([[3, 4],\n                      [5, 6],\n                      [7, 8]]),\n       size=(2, 3, 2), nnz=3, layout=torch.sparse_coo)\n",
        "Question": "How to use PyTorch hybrid COO tensor extends the sparse COO tensor by allowing\nthevaluestensor to be a multi-dimensional tensor so that we\nhave:Suppose we want to create a (2 + 1)-dimensional tensor with the entry\n[3, 4] at location (0, 2), entry [5, 6] at location (1, 0), and entry\n[7, 8] at location (1, 2). We would write, give an example?",
        "Id": 502,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " PyTorch hybrid COO tensor extends the sparse COO tensor by allowing\nthevaluestensor to be a multi-dimensional tensor so that we\nhave:Suppose we want to create a (2 + 1)-dimensional tensor with the entry\n[3, 4] at location (0, 2), entry [5, 6] at location (1, 0), and entry\n[7, 8] at location (1, 2). We would write"
    },
    {
        "Answer": ">>> s.to_dense()\ntensor([[[0, 0],\n         [0, 0],\n         [3, 4]],\n        [[5, 6],\n         [0, 0],\n         [7, 8]]])\n",
        "Question": "How  PyTorch hybrid COO tensor extends the sparse COO tensor by allowing\nthevaluestensor to be a multi-dimensional tensor so that we\nhave:Suppose we want to create a (2 + 1)-dimensional tensor with the entry\n[3, 4] at location (0, 2), entry [5, 6] at location (1, 0), and entry\n[7, 8] at location (1, 2). We would write, give an example?",
        "Id": 503,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " PyTorch hybrid COO tensor extends the sparse COO tensor by allowing\nthevaluestensor to be a multi-dimensional tensor so that we\nhave:Suppose we want to create a (2 + 1)-dimensional tensor with the entry\n[3, 4] at location (0, 2), entry [5, 6] at location (1, 0), and entry\n[7, 8] at location (1, 2). We would write"
    },
    {
        "Answer": ">>> i = [[1, 1]]\n>>> v =  [3, 4]\n>>> s=torch.sparse_coo_tensor(i, v, (3,))\n>>> s\ntensor(indices=tensor([[1, 1]]),\n       values=tensor(  [3, 4]),\n       size=(3,), nnz=2, layout=torch.sparse_coo)\n",
        "Question": "How to use PyTorch sparse COO tensor format permitsuncoalescedsparse tensors,\nwhere there may be duplicate coordinates in the indices; in this case,\nthe interpretation is that the value at that index is the sum of all\nduplicate value entries. For example, one can specify multiple values,3and4, for the same index1, that leads to an 1-D\nuncoalesced tensor:, give an example?",
        "Id": 504,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " PyTorch sparse COO tensor format permitsuncoalescedsparse tensors,\nwhere there may be duplicate coordinates in the indices; in this case,\nthe interpretation is that the value at that index is the sum of all\nduplicate value entries. For example, one can specify multiple values,3and4, for the same index1, that leads to an 1-D\nuncoalesced tensor:"
    },
    {
        "Answer": ">>> s.coalesce()\ntensor(indices=tensor([[1]]),\n       values=tensor([7]),\n       size=(3,), nnz=1, layout=torch.sparse_coo)\n",
        "Question": "How to use PyTorch sparse COO tensor format permitsuncoalescedsparse tensors,\nwhere there may be duplicate coordinates in the indices; in this case,\nthe interpretation is that the value at that index is the sum of all\nduplicate value entries. For example, one can specify multiple values,3and4, for the same index1, that leads to an 1-D\nuncoalesced tensor:while the coalescing process will accumulate the multi-valued elements\ninto a single value using summation:, give an example?",
        "Id": 505,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " while the coalescing process will accumulate the multi-valued elements\ninto a single value using summation:"
    },
    {
        "Answer": ">>> a = torch.sparse_coo_tensor([[1, 1]], [5, 6], (2,))\n>>> b = torch.sparse_coo_tensor([[0, 0]], [7, 8], (2,))\n>>> a + b\ntensor(indices=tensor([[0, 0, 1, 1]]),\n       values=tensor([7, 8, 5, 6]),\n       size=(2,), nnz=4, layout=torch.sparse_coo)\n",
        "Question": "How to use However, some operations can be implemented more efficiently on\nuncoalesced tensors, and some on coalesced tensors.For instance, addition of sparse COO tensors is implemented by\nsimply concatenating the indices and values tensors:, give an example?",
        "Id": 506,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " However, some operations can be implemented more efficiently on\nuncoalesced tensors, and some on coalesced tensors.For instance, addition of sparse COO tensors is implemented by\nsimply concatenating the indices and values tensors:"
    },
    {
        "Answer": ">>> i = [[0, 1, 1],\n         [2, 0, 2]]\n>>> v =  [[3, 4], [5, 6], [7, 8]]\n>>> s = torch.sparse_coo_tensor(i, v, (2, 3, 2))\n",
        "Question": "How to use Let\u2019s consider the following example:, give an example?",
        "Id": 507,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Let\u2019s consider the following example:"
    },
    {
        "Answer": ">>> isinstance(s, torch.Tensor)\nTrue\n>>> s.is_sparse\nTrue\n>>> s.layout == torch.sparse_coo\nTrue\n",
        "Question": "How to use Let\u2019s consider the following example:As mentioned above, a sparse COO tensor is atorch.Tensorinstance and to distinguish it from theTensorinstances that use\nsome other layout, on can usetorch.Tensor.is_sparseortorch.Tensor.layoutproperties:, give an example?",
        "Id": 508,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " As mentioned above, a sparse COO tensor is atorch.Tensorinstance and to distinguish it from theTensorinstances that use\nsome other layout, on can usetorch.Tensor.is_sparseortorch.Tensor.layoutproperties:"
    },
    {
        "Answer": ">>> s.sparse_dim(), s.dense_dim()\n(2, 1)\n",
        "Question": "How to use As mentioned above, a sparse COO tensor is atorch.Tensorinstance and to distinguish it from theTensorinstances that use\nsome other layout, on can usetorch.Tensor.is_sparseortorch.Tensor.layoutproperties:The number of sparse and dense dimensions can be acquired using\nmethodstorch.Tensor.sparse_dim()andtorch.Tensor.dense_dim(), respectively. For instance:, give an example?",
        "Id": 509,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " As mentioned above, a sparse COO tensor is atorch.Tensorinstance and to distinguish it from theTensorinstances that use\nsome other layout, on can usetorch.Tensor.is_sparseortorch.Tensor.layoutproperties:The number of sparse and dense dimensions can be acquired using\nmethodstorch.Tensor.sparse_dim()andtorch.Tensor.dense_dim(), respectively. For instance:"
    },
    {
        "Answer": ">>> s.indices()\nRuntimeError: Cannot get indices on an uncoalesced tensor, please call .coalesce() first\n",
        "Question": "How to use NoteCurrently, one can acquire the COO format data only when the tensor\ninstance is coalesced:, give an example?",
        "Id": 510,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Currently, one can acquire the COO format data only when the tensor\ninstance is coalesced:"
    },
    {
        "Answer": ">>> s._indices()\ntensor([[0, 1, 1],\n        [2, 0, 2]])\n",
        "Question": "How to use Currently, one can acquire the COO format data only when the tensor\ninstance is coalesced:For acquiring the COO format data of an uncoalesced tensor, usetorch.Tensor._values()andtorch.Tensor._indices():, give an example?",
        "Id": 511,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Currently, one can acquire the COO format data only when the tensor\ninstance is coalesced:For acquiring the COO format data of an uncoalesced tensor, usetorch.Tensor._values()andtorch.Tensor._indices():"
    },
    {
        "Answer": ">>> s.is_coalesced()\nFalse\n",
        "Question": "How to use Ifsis a sparse COO tensor then its COO format data can be\nacquired using methodstorch.Tensor.indices()andtorch.Tensor.values().Constructing a new sparse COO tensor results a tensor that is not\ncoalesced:, give an example?",
        "Id": 512,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Ifsis a sparse COO tensor then its COO format data can be\nacquired using methodstorch.Tensor.indices()andtorch.Tensor.values().Constructing a new sparse COO tensor results a tensor that is not\ncoalesced:"
    },
    {
        "Answer": ">>> s2 = s.coalesce()\n>>> s2.indices()\ntensor([[0, 1, 1],\n       [2, 0, 2]])\n",
        "Question": "How to use Constructing a new sparse COO tensor results a tensor that is not\ncoalesced:but one can construct a coalesced copy of a sparse COO tensor using\nthetorch.Tensor.coalesce()method:, give an example?",
        "Id": 513,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Constructing a new sparse COO tensor results a tensor that is not\ncoalesced:but one can construct a coalesced copy of a sparse COO tensor using\nthetorch.Tensor.coalesce()method:"
    },
    {
        "Answer": ">>> s[1]\ntensor(indices=tensor([[0, 2]]),\n       values=tensor([[5, 6],\n                      [7, 8]]),\n       size=(3, 2), nnz=2, layout=torch.sparse_coo)\n>>> s[1, 0, 1]\ntensor(6)\n>>> s[1, 0, 1:]\ntensor([6])\n",
        "Question": "How to use When working with uncoalesced sparse COO tensors, one must take into\nan account the additive nature of uncoalesced data: the values of the\nsame indices are the terms of a sum that evaluation gives the value of\nthe corresponding tensor element. For example, the scalar\nmultiplication on an uncoalesced sparse tensor could be implemented by\nmultiplying all the uncoalesced values with the scalar becausec*(a+b)==c*a+c*bholds. However, any nonlinear operation,\nsay, a square root, cannot be implemented by applying the operation to\nuncoalesced data becausesqrt(a+b)==sqrt(a)+sqrt(b)does not\nhold in general.Slicing (with positive step) of a sparse COO tensor is supported only\nfor dense dimensions. Indexing is supported for both sparse and dense\ndimensions:, give an example?",
        "Id": 514,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " When working with uncoalesced sparse COO tensors, one must take into\nan account the additive nature of uncoalesced data: the values of the\nsame indices are the terms of a sum that evaluation gives the value of\nthe corresponding tensor element. For example, the scalar\nmultiplication on an uncoalesced sparse tensor could be implemented by\nmultiplying all the uncoalesced values with the scalar becausec*(a+b)==c*a+c*bholds. However, any nonlinear operation,\nsay, a square root, cannot be implemented by applying the operation to\nuncoalesced data becausesqrt(a+b)==sqrt(a)+sqrt(b)does not\nhold in general.Slicing (with positive step) of a sparse COO tensor is supported only\nfor dense dimensions. Indexing is supported for both sparse and dense\ndimensions:"
    },
    {
        "Answer": ">>> crow_indices = torch.tensor([0, 2, 4])\n>>> col_indices = torch.tensor([0, 1, 0, 1])\n>>> values = torch.tensor([1, 2, 3, 4])\n>>> csr = torch._sparse_csr_tensor(crow_indices, col_indices, values, dtype=torch.double)\n>>> csr\ntensor(crow_indices=tensor([0, 2, 4]),\n      col_indices=tensor([0, 1, 0, 1]),\n      values=tensor([1., 2., 3., 4.]), size=(2, 2), nnz=4,\n      dtype=torch.float64)\n>>> csr.to_dense()\ntensor([[1., 2.],\n        [3., 4.]], dtype=torch.float64)\n",
        "Question": "How to use Sparse CSR matrices can be directly constructed by using thetorch._sparse_csr_tensor()method. The user must supply the row and column indices and values tensors separately.\nThesizeargument is optional and will be deduced from the thecrow_indicesandcol_indicesif it is not present., give an example?",
        "Id": 515,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " Sparse CSR matrices can be directly constructed by using thetorch._sparse_csr_tensor()method. The user must supply the row and column indices and values tensors separately.\nThesizeargument is optional and will be deduced from the thecrow_indicesandcol_indicesif it is not present."
    },
    {
        "Answer": ">>> a = torch.tensor([[0, 0, 1, 0], [1, 2, 0, 0], [0, 0, 0, 0]], dtype = torch.float64)\n>>> sp = a._to_sparse_csr()\n>>> sp\ntensor(crow_indices=tensor([0, 1, 3, 3]),\n      col_indices=tensor([2, 0, 1]),\n      values=tensor([1., 1., 2.]), size=(3, 4), nnz=3, dtype=torch.float64)\n",
        "Question": "How to use The simplest way of constructing a sparse CSR tensor from a strided or sparse COO\ntensor is to usetensor._to_sparse_csr(). Any zeros in the (strided) tensor will\nbe interpreted as missing values in the sparse tensor:, give an example?",
        "Id": 516,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " The simplest way of constructing a sparse CSR tensor from a strided or sparse COO\ntensor is to usetensor._to_sparse_csr(). Any zeros in the (strided) tensor will\nbe interpreted as missing values in the sparse tensor:"
    },
    {
        "Answer": ">>> vec = torch.randn(4, 1, dtype=torch.float64)\n>>> sp.matmul(vec)\ntensor([[0.9078],\n        [1.3180],\n        [0.0000]], dtype=torch.float64)\n",
        "Question": "How to use The simplest way of constructing a sparse CSR tensor from a strided or sparse COO\ntensor is to usetensor._to_sparse_csr(). Any zeros in the (strided) tensor will\nbe interpreted as missing values in the sparse tensor:The sparse matrix-vector multiplication can be performed with thetensor.matmul()method. This is currently the only math operation\nsupported on CSR tensors., give an example?",
        "Id": 517,
        "source": "https://pytorch.org/docs/stable/sparse.html",
        "context": " The sparse matrix-vector multiplication can be performed with thetensor.matmul()method. This is currently the only math operation\nsupported on CSR tensors."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-0.5461,  0.1347, -2.7266, -0.2746])\n>>> torch.sin(a)\ntensor([-0.5194,  0.1343, -0.4032, -0.2711])\n",
        "Question": "How to use torch.sin, give an example?",
        "Id": 518,
        "source": "https://pytorch.org/docs/stable/generated/torch.sin.html#torch.sin",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.tensor([1, 2, 4, 7, 11, 16], dtype=torch.float)\n>>> torch.gradient(t)\ntensor([1. , 1.5, 2.5, 3.5, 4.5, 5. ])\n>>> coords = torch.tensor([0., 1., 1.5, 3.5, 4., 6.], dtype=torch.float)\n>>> torch.gradient(t, spacing=(coords,))\ntensor([1. ,  3. ,  3.5,  6.7,  6.9,  2.5])\n",
        "Question": "How to use torch.gradient, give an example?",
        "Id": 519,
        "source": "https://pytorch.org/docs/stable/generated/torch.gradient.html#torch.gradient",
        "context": " "
    },
    {
        "Answer": ">>> input = torch.randint(0, 8, (5,), dtype=torch.int64)\n>>> weights = torch.linspace(0, 1, steps=5)\n>>> input, weights\n(tensor([4, 3, 6, 3, 4]),\n tensor([ 0.0000,  0.2500,  0.5000,  0.7500,  1.0000])\n\n>>> torch.bincount(input)\ntensor([0, 0, 0, 2, 2, 0, 1])\n\n>>> input.bincount(weights)\ntensor([0.0000, 0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.5000])\n",
        "Question": "How to use torch.bincount, give an example?",
        "Id": 520,
        "source": "https://pytorch.org/docs/stable/generated/torch.bincount.html#torch.bincount",
        "context": " The number of bins (size 1) is one larger than the largest value ininputunlessinputis empty, in which case the result is a\ntensor of size 0. Ifminlengthis specified, the number of bins is at leastminlengthand ifinputis empty, then the result is tensor of sizeminlengthfilled with zeros. Ifnis the value at positioni,out[n]+=weights[i]ifweightsis specified elseout[n]+=1."
    },
    {
        "Answer": ">>> torch.conj(torch.tensor([-1 + 1j, -2 + 2j, 3 - 3j]))\ntensor([-1 - 1j, -2 - 2j, 3 + 3j])\n",
        "Question": "How to use torch.conj, give an example?",
        "Id": 521,
        "source": "https://pytorch.org/docs/stable/generated/torch.conj.html#torch.conj",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(5)\n>>> t\ntensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])\n>>> torch.positive(t)\ntensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])\n",
        "Question": "How to use torch.positive, give an example?",
        "Id": 522,
        "source": "https://pytorch.org/docs/stable/generated/torch.positive.html#torch.positive",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.2341,  0.2539, -0.6256, -0.6448])\n>>> torch.atan(a)\ntensor([ 0.2299,  0.2487, -0.5591, -0.5727])\n",
        "Question": "How to use torch.atan, give an example?",
        "Id": 523,
        "source": "https://pytorch.org/docs/stable/generated/torch.atan.html#torch.atan",
        "context": " "
    },
    {
        "Answer": ">>> torch.tensor([[0.1, 1.2], [2.2, 3.1], [4.9, 5.2]])\ntensor([[ 0.1000,  1.2000],\n        [ 2.2000,  3.1000],\n        [ 4.9000,  5.2000]])\n\n>>> torch.tensor([0, 1])  # Type inference on data\ntensor([ 0,  1])\n\n>>> torch.tensor([[0.11111, 0.222222, 0.3333333]],\n...              dtype=torch.float64,\n...              device=torch.device('cuda:0'))  # creates a torch.cuda.DoubleTensor\ntensor([[ 0.1111,  0.2222,  0.3333]], dtype=torch.float64, device='cuda:0')\n\n>>> torch.tensor(3.14159)  # Create a scalar (zero-dimensional tensor)\ntensor(3.1416)\n\n>>> torch.tensor([])  # Create an empty tensor (of size (0,))\ntensor([])\n",
        "Question": "How to use torch.tensor, give an example?",
        "Id": 524,
        "source": "https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.triu_indices(3, 3)\n>>> a\ntensor([[0, 0, 0, 1, 1, 2],\n        [0, 1, 2, 1, 2, 2]])\n\n>>> a = torch.triu_indices(4, 3, -1)\n>>> a\ntensor([[0, 0, 0, 1, 1, 1, 2, 2, 3],\n        [0, 1, 2, 0, 1, 2, 1, 2, 2]])\n\n>>> a = torch.triu_indices(4, 3, 1)\n>>> a\ntensor([[0, 0, 1],\n        [1, 2, 2]])\n",
        "Question": "How to use torch.triu_indices, give an example?",
        "Id": 525,
        "source": "https://pytorch.org/docs/stable/generated/torch.triu_indices.html#torch.triu_indices",
        "context": " The argumentoffsetcontrols which diagonal to consider. Ifoffset= 0, all elements on and above the main diagonal are\nretained. A positive value excludes just as many diagonals above the main\ndiagonal, and similarly a negative value includes just as many diagonals below\nthe main diagonal. The main diagonal are the set of indices{(i,i)}\\lbrace (i, i) \\rbrace{(i,i)}fori\u2208[0,min\u2061{d1,d2}\u22121]i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]i\u2208[0,min{d1\u200b,d2\u200b}\u22121]whered1,d2d_{1}, d_{2}d1\u200b,d2\u200bare the dimensions of the matrix."
    },
    {
        "Answer": ">>> torch.remainder(torch.tensor([-3., -2, -1, 1, 2, 3]), 2)\ntensor([ 1.,  0.,  1.,  1.,  0.,  1.])\n>>> torch.remainder(torch.tensor([1, 2, 3, 4, 5]), 1.5)\ntensor([ 1.0000,  0.5000,  0.0000,  1.0000,  0.5000])\n",
        "Question": "How to use torch.remainder, give an example?",
        "Id": 526,
        "source": "https://pytorch.org/docs/stable/generated/torch.remainder.html#torch.remainder",
        "context": " Supportsbroadcasting to a common shape,type promotion, and integer and float inputs."
    },
    {
        "Answer": ">>> torch.eye(3)\ntensor([[ 1.,  0.,  0.],\n        [ 0.,  1.,  0.],\n        [ 0.,  0.,  1.]])\n",
        "Question": "How to use torch.eye, give an example?",
        "Id": 527,
        "source": "https://pytorch.org/docs/stable/generated/torch.eye.html#torch.eye",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 3.4742,  0.5466, -0.8008, -0.9079])\n>>> torch.trunc(a)\ntensor([ 3.,  0., -0., -0.])\n",
        "Question": "How to use torch.trunc, give an example?",
        "Id": 528,
        "source": "https://pytorch.org/docs/stable/generated/torch.trunc.html#torch.trunc",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([ 0.8419,  0.8003,  0.9971,  0.5287,  0.0490])\n\n\n>>> torch.log2(a)\ntensor([-0.2483, -0.3213, -0.0042, -0.9196, -4.3504])\n",
        "Question": "How to use torch.log2, give an example?",
        "Id": 529,
        "source": "https://pytorch.org/docs/stable/generated/torch.log2.html#torch.log2",
        "context": " "
    },
    {
        "Answer": ">>> i = torch.tensor([[0, 1, 1],\n...                   [2, 0, 2]])\n>>> v = torch.tensor([3, 4, 5], dtype=torch.float32)\n>>> torch.sparse_coo_tensor(i, v, [2, 4])\ntensor(indices=tensor([[0, 1, 1],\n                       [2, 0, 2]]),\n       values=tensor([3., 4., 5.]),\n       size=(2, 4), nnz=3, layout=torch.sparse_coo)\n\n>>> torch.sparse_coo_tensor(i, v)  # Shape inference\ntensor(indices=tensor([[0, 1, 1],\n                       [2, 0, 2]]),\n       values=tensor([3., 4., 5.]),\n       size=(2, 3), nnz=3, layout=torch.sparse_coo)\n\n>>> torch.sparse_coo_tensor(i, v, [2, 4],\n...                         dtype=torch.float64,\n...                         device=torch.device('cuda:0'))\ntensor(indices=tensor([[0, 1, 1],\n                       [2, 0, 2]]),\n       values=tensor([3., 4., 5.]),\n       device='cuda:0', size=(2, 4), nnz=3, dtype=torch.float64,\n       layout=torch.sparse_coo)\n\n# Create an empty sparse tensor with the following invariants:\n#   1. sparse_dim + dense_dim = len(SparseTensor.shape)\n#   2. SparseTensor._indices().shape = (sparse_dim, nnz)\n#   3. SparseTensor._values().shape = (nnz, SparseTensor.shape[sparse_dim:])\n#\n# For instance, to create an empty sparse tensor with nnz = 0, dense_dim = 0 and\n# sparse_dim = 1 (hence indices is a 2D tensor of shape = (1, 0))\n>>> S = torch.sparse_coo_tensor(torch.empty([1, 0]), [], [1])\ntensor(indices=tensor([], size=(1, 0)),\n       values=tensor([], size=(0,)),\n       size=(1,), nnz=0, layout=torch.sparse_coo)\n\n# and to create an empty sparse tensor with nnz = 0, dense_dim = 1 and\n# sparse_dim = 1\n>>> S = torch.sparse_coo_tensor(torch.empty([1, 0]), torch.empty([0, 2]), [1, 2])\ntensor(indices=tensor([], size=(1, 0)),\n       values=tensor([], size=(0, 2)),\n       size=(1, 2), nnz=0, layout=torch.sparse_coo)\n",
        "Question": "How to use torch.sparse_coo_tensor, give an example?",
        "Id": 530,
        "source": "https://pytorch.org/docs/stable/generated/torch.sparse_coo_tensor.html#torch.sparse_coo_tensor",
        "context": " "
    },
    {
        "Answer": ">>> torch.logical_or(torch.tensor([True, False, True]), torch.tensor([True, False, False]))\ntensor([ True, False,  True])\n>>> a = torch.tensor([0, 1, 10, 0], dtype=torch.int8)\n>>> b = torch.tensor([4, 0, 1, 0], dtype=torch.int8)\n>>> torch.logical_or(a, b)\ntensor([ True,  True,  True, False])\n>>> torch.logical_or(a.double(), b.double())\ntensor([ True,  True,  True, False])\n>>> torch.logical_or(a.double(), b)\ntensor([ True,  True,  True, False])\n>>> torch.logical_or(a, b, out=torch.empty(4, dtype=torch.bool))\ntensor([ True,  True,  True, False])\n",
        "Question": "How to use torch.logical_or, give an example?",
        "Id": 531,
        "source": "https://pytorch.org/docs/stable/generated/torch.logical_or.html#torch.logical_or",
        "context": " "
    },
    {
        "Answer": "X = torch.linalg.solve(A, B)\n",
        "Question": "How to use torch.solve, give an example?",
        "Id": 532,
        "source": "https://pytorch.org/docs/stable/generated/torch.solve.html#torch.solve",
        "context": " torch.solve()is deprecated in favor oftorch.linalg.solve()and will be removed in a future PyTorch release.torch.linalg.solve()has its arguments reversed and does not return the\nLU factorization of the input. To get the LU factorization seetorch.lu(),\nwhich may be used withtorch.lu_solve()andtorch.lu_unpack().X=torch.solve(B,A).solutionshould be replaced with"
    },
    {
        "Answer": ">>> A = torch.tensor([[6.80, -2.11,  5.66,  5.97,  8.23],\n...                   [-6.05, -3.30,  5.36, -4.44,  1.08],\n...                   [-0.45,  2.58, -2.70,  0.27,  9.04],\n...                   [8.32,  2.71,  4.35,  -7.17,  2.14],\n...                   [-9.67, -5.14, -7.26,  6.08, -6.87]]).t()\n>>> B = torch.tensor([[4.02,  6.19, -8.22, -7.57, -3.03],\n...                   [-1.56,  4.00, -8.67,  1.75,  2.86],\n...                   [9.81, -4.09, -4.57, -8.61,  8.99]]).t()\n>>> X, LU = torch.solve(B, A)\n>>> torch.dist(B, torch.mm(A, X))\ntensor(1.00000e-06 *\n       7.0977)\n\n>>> # Batched solver example\n>>> A = torch.randn(2, 3, 1, 4, 4)\n>>> B = torch.randn(2, 3, 1, 4, 6)\n>>> X, LU = torch.solve(B, A)\n>>> torch.dist(B, A.matmul(X))\ntensor(1.00000e-06 *\n   3.6386)\n",
        "Question": "How  Supports real-valued and complex-valued inputs., give an example?",
        "Id": 533,
        "source": "https://pytorch.org/docs/stable/generated/torch.solve.html#torch.solve",
        "context": " Supports real-valued and complex-valued inputs."
    },
    {
        "Answer": ">>> a = torch.arange(-0.5, 1, 0.5)\n>>> a\ntensor([-0.5000,  0.0000,  0.5000])\n>>> torch.special.entr(a)\ntensor([  -inf, 0.0000, 0.3466])\n",
        "Question": "How  , give an example?",
        "Id": 534,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erf(torch.tensor([0, -1., 10.]))\ntensor([ 0.0000, -0.8427,  1.0000])\n",
        "Question": "How  , give an example?",
        "Id": 535,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n",
        "Question": "How  , give an example?",
        "Id": 536,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n",
        "Question": "How  , give an example?",
        "Id": 537,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(4)\n>>> t\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n>>> torch.special.expit(t)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
        "Question": "How  , give an example?",
        "Id": 538,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n",
        "Question": "How  , give an example?",
        "Id": 539,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\ntensor([ 1.,  2.,  8., 16.])\n",
        "Question": "How  , give an example?",
        "Id": 540,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.special.gammaln(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How  , give an example?",
        "Id": 541,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.i0e(torch.arange(5, dtype=torch.float32))\ntensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])\n",
        "Question": "How  , give an example?",
        "Id": 542,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n>>> torch.special.logit(a, eps=1e-6)\ntensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
        "Question": "How  , give an example?",
        "Id": 543,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.special.xlog1py(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.special.xlog1py(x, y)\ntensor([1.3863, 2.1972, 2.0794])\n>>> torch.special.xlog1py(x, 4)\ntensor([1.6094, 3.2189, 4.8283])\n>>> torch.special.xlog1py(2, y)\ntensor([2.7726, 2.1972, 1.3863])\n",
        "Question": "How  Similar to SciPy\u2019sscipy.special.xlog1py., give an example?",
        "Id": 544,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.logit",
        "context": " Similar to SciPy\u2019sscipy.special.xlog1py."
    },
    {
        "Answer": ">>> x = torch.tensor([1, 2, 3, 5])\n>>> torch.vander(x)\ntensor([[  1,   1,   1,   1],\n        [  8,   4,   2,   1],\n        [ 27,   9,   3,   1],\n        [125,  25,   5,   1]])\n>>> torch.vander(x, N=3)\ntensor([[ 1,  1,  1],\n        [ 4,  2,  1],\n        [ 9,  3,  1],\n        [25,  5,  1]])\n>>> torch.vander(x, N=3, increasing=True)\ntensor([[ 1,  1,  1],\n        [ 1,  2,  4],\n        [ 1,  3,  9],\n        [ 1,  5, 25]])\n",
        "Question": "How to use torch.vander, give an example?",
        "Id": 545,
        "source": "https://pytorch.org/docs/stable/generated/torch.vander.html#torch.vander",
        "context": " The columns of the output matrix are elementwise powers of the input vectorx(N\u22121),x(N\u22122),...,x0x^{(N-1)}, x^{(N-2)}, ..., x^0x(N\u22121),x(N\u22122),...,x0.\nIf increasing is True, the order of the columns is reversedx0,x1,...,x(N\u22121)x^0, x^1, ..., x^{(N-1)}x0,x1,...,x(N\u22121). Such a\nmatrix with a geometric progression in each row is named for Alexandre-Theophile Vandermonde."
    },
    {
        "Answer": ">>> x = torch.arange(9.)\n>>> mantissa, exponent = torch.frexp(x)\n>>> mantissa\ntensor([0.0000, 0.5000, 0.5000, 0.7500, 0.5000, 0.6250, 0.7500, 0.8750, 0.5000])\n>>> exponent\ntensor([0, 1, 2, 2, 3, 3, 3, 3, 4], dtype=torch.int32)\n>>> torch.ldexp(mantissa, exponent)\ntensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])\n",
        "Question": "How to use torch.frexp, give an example?",
        "Id": 546,
        "source": "https://pytorch.org/docs/stable/generated/torch.frexp.html#torch.frexp",
        "context": " Supports float inputs."
    },
    {
        "Answer": ">>> t = torch.randn(1, 3)\n>>> t1 = torch.randn(3, 1)\n>>> t2 = torch.randn(1, 3)\n>>> torch.addcdiv(t, t1, t2, value=0.1)\ntensor([[-0.2312, -3.6496,  0.1312],\n        [-1.0428,  3.4292, -0.1030],\n        [-0.5369, -0.9829,  0.0430]])\n",
        "Question": "How to use torch.addcdiv, give an example?",
        "Id": 547,
        "source": "https://pytorch.org/docs/stable/generated/torch.addcdiv.html#torch.addcdiv",
        "context": " For inputs of typeFloatTensororDoubleTensor,valuemust be\na real number, otherwise an integer."
    },
    {
        "Answer": ">>> t = torch.randn(3,2,1)\n>>> t\ntensor([[[-0.3362],\n        [-0.8437]],\n\n        [[-0.9627],\n        [ 0.1727]],\n\n        [[ 0.5173],\n        [-0.1398]]])\n>>> torch.moveaxis(t, 1, 0).shape\ntorch.Size([2, 3, 1])\n>>> torch.moveaxis(t, 1, 0)\ntensor([[[-0.3362],\n        [-0.9627],\n        [ 0.5173]],\n\n        [[-0.8437],\n        [ 0.1727],\n        [-0.1398]]])\n>>> torch.moveaxis(t, (1, 2), (0, 1)).shape\ntorch.Size([2, 1, 3])\n>>> torch.moveaxis(t, (1, 2), (0, 1))\ntensor([[[-0.3362, -0.9627,  0.5173]],\n\n        [[-0.8437,  0.1727, -0.1398]]])\n",
        "Question": "How to use torch.moveaxis, give an example?",
        "Id": 548,
        "source": "https://pytorch.org/docs/stable/generated/torch.moveaxis.html#torch.moveaxis",
        "context": " This function is equivalent to NumPy\u2019s moveaxis function."
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.lgamma(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How to use torch.lgamma, give an example?",
        "Id": 549,
        "source": "https://pytorch.org/docs/stable/generated/torch.lgamma.html#torch.lgamma",
        "context": " "
    },
    {
        "Answer": ">>> import torch\n>>>\n>>> def callback(fut):\n>>>     print(f\"This will run after the future has finished.\")\n>>>     print(fut.wait())\n>>>\n>>> fut = torch.futures.Future()\n>>> fut.add_done_callback(callback)\n>>> fut.set_result(5)\n>>>\n>>> # Outputs are:\n>>> This will run after the future has finished.\n>>> 5\n",
        "Question": "How to use torch.futures.Future.add_done_callback, give an example?",
        "Id": 550,
        "source": "https://pytorch.org/docs/stable/futures.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch\n>>>\n>>> fut = torch.futures.Future()\n>>> fut.set_exception(ValueError(\"foo\"))\n>>> fut.wait()\n>>>\n>>> # Output:\n>>> # This will run after the future has finished.\n>>> ValueError: foo\n",
        "Question": "How to use torch.futures.Future.set_exception, give an example?",
        "Id": 551,
        "source": "https://pytorch.org/docs/stable/futures.html",
        "context": " "
    },
    {
        "Answer": ">>> import threading\n>>> import time\n>>> import torch\n>>>\n>>> def slow_set_future(fut, value):\n>>>     time.sleep(0.5)\n>>>     fut.set_result(value)\n>>>\n>>> fut = torch.futures.Future()\n>>> t = threading.Thread(\n>>>     target=slow_set_future,\n>>>     args=(fut, torch.ones(2) * 3)\n>>> )\n>>> t.start()\n>>>\n>>> print(fut.wait())  # tensor([3., 3.])\n>>> t.join()\n",
        "Question": "How to use torch.futures.Future.set_result, give an example?",
        "Id": 552,
        "source": "https://pytorch.org/docs/stable/futures.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch\n>>>\n>>> def callback(fut):\n>>>     print(f\"RPC return value is {fut.wait()}.\")\n>>>\n>>> fut = torch.futures.Future()\n>>> # The inserted callback will print the return value when\n>>> # receiving the response from \"worker1\"\n>>> cb_fut = fut.then(callback)\n>>> chain_cb_fut = cb_fut.then(\n>>>     lambda x : print(f\"Chained cb done. {x.wait()}\")\n>>> )\n>>> fut.set_result(5)\n>>>\n>>> # Outputs are:\n>>> # RPC return value is 5.\n>>> # Chained cb done. None\n",
        "Question": "How to use torch.futures.Future.then, give an example?",
        "Id": 553,
        "source": "https://pytorch.org/docs/stable/futures.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch\n>>>\n>>> fut0 = torch.futures.Future()\n>>> fut1 = torch.futures.Future()\n>>>\n>>> fut = torch.futures.collect_all([fut0, fut1])\n>>>\n>>> fut0.set_result(0)\n>>> fut1.set_result(1)\n>>>\n>>> fut_list = fut.wait()\n>>> print(f\"fut0 result = {fut_list[0].wait()}\")\n>>> print(f\"fut1 result = {fut_list[1].wait()}\")\n>>> # outputs:\n>>> # fut0 result = 0\n>>> # fut1 result = 1\n",
        "Question": "How to use torch.futures.collect_all, give an example?",
        "Id": 554,
        "source": "https://pytorch.org/docs/stable/futures.html",
        "context": " "
    },
    {
        "Answer": ">>> torch.fmod(torch.tensor([-3., -2, -1, 1, 2, 3]), 2)\ntensor([-1., -0., -1.,  1.,  0.,  1.])\n>>> torch.fmod(torch.tensor([1, 2, 3, 4, 5]), 1.5)\ntensor([1.0000, 0.5000, 0.0000, 1.0000, 0.5000])\n",
        "Question": "How to use torch.fmod, give an example?",
        "Id": 555,
        "source": "https://pytorch.org/docs/stable/generated/torch.fmod.html#torch.fmod",
        "context": " Supportsbroadcasting to a common shape,type promotion, and integer and float inputs."
    },
    {
        "Answer": ">>> x = torch.randn(4)\n>>> x\ntensor([-1.5393, -0.8675,  0.5916,  1.6321])\n>>> y = torch.randn(4)\n>>> y\ntensor([ 0.0967, -1.0511,  0.6295,  0.8360])\n>>> torch.dist(x, y, 3.5)\ntensor(1.6727)\n>>> torch.dist(x, y, 3)\ntensor(1.6973)\n>>> torch.dist(x, y, 0)\ntensor(inf)\n>>> torch.dist(x, y, 1)\ntensor(2.6537)\n",
        "Question": "How to use torch.dist, give an example?",
        "Id": 556,
        "source": "https://pytorch.org/docs/stable/generated/torch.dist.html#torch.dist",
        "context": " The shapes ofinputandothermust bebroadcastable."
    },
    {
        "Answer": ">>> a=torch.empty((2,3), dtype=torch.int32, device = 'cuda')\n>>> torch.empty_like(a)\ntensor([[0, 0, 0],\n        [0, 0, 0]], device='cuda:0', dtype=torch.int32)\n",
        "Question": "How to use torch.empty, give an example?",
        "Id": 557,
        "source": "https://pytorch.org/docs/stable/generated/torch.empty.html#torch.empty",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([1., 2., float('nan'), 4.])\n>>> torch.nansum(a)\ntensor(7.)\n",
        "Question": "How to use torch.nansum, give an example?",
        "Id": 558,
        "source": "https://pytorch.org/docs/stable/generated/torch.nansum.html#torch.nansum",
        "context": " "
    },
    {
        "Answer": ">>> torch.nansum(torch.tensor([1., float(\"nan\")]))\n1.0\n>>> a = torch.tensor([[1, 2], [3., float(\"nan\")]])\n>>> torch.nansum(a)\ntensor(6.)\n>>> torch.nansum(a, dim=0)\ntensor([4., 2.])\n>>> torch.nansum(a, dim=1)\ntensor([3., 3.])\n",
        "Question": "How  IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimension(s)dimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in the\noutput tensor having 1 (orlen(dim)) fewer dimension(s)., give an example?",
        "Id": 559,
        "source": "https://pytorch.org/docs/stable/generated/torch.nansum.html#torch.nansum",
        "context": " IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimension(s)dimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in the\noutput tensor having 1 (orlen(dim)) fewer dimension(s)."
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a\ntensor([[-1.0854,  1.1431, -0.1752],\n        [ 0.8536, -0.0905,  0.0360],\n        [ 0.6927, -0.3735, -0.4945]])\n\n\n>>> torch.diagonal(a, 0)\ntensor([-1.0854, -0.0905, -0.4945])\n\n\n>>> torch.diagonal(a, 1)\ntensor([ 1.1431,  0.0360])\n\n\n>>> x = torch.randn(2, 5, 4, 2)\n>>> torch.diagonal(x, offset=-1, dim1=1, dim2=2)\ntensor([[[-1.2631,  0.3755, -1.5977, -1.8172],\n         [-1.1065,  1.0401, -0.2235, -0.7938]],\n\n        [[-1.7325, -0.3081,  0.6166,  0.2335],\n         [ 1.0500,  0.7336, -0.3836, -1.1015]]])\n",
        "Question": "How to use torch.diagonal, give an example?",
        "Id": 560,
        "source": "https://pytorch.org/docs/stable/generated/torch.diagonal.html#torch.diagonal",
        "context": " Applyingtorch.diag_embed()to the output of this function with\nthe same arguments yields a diagonal matrix with the diagonal entries\nof the input. However,torch.diag_embed()has different default\ndimensions, so those need to be explicitly specified."
    },
    {
        "Answer": ">>> torch.le(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[True, False], [True, True]])\n",
        "Question": "How to use torch.le, give an example?",
        "Id": 561,
        "source": "https://pytorch.org/docs/stable/generated/torch.le.html#torch.le",
        "context": " The second argument can be a number or a tensor whose shape isbroadcastablewith the first argument."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 562,
        "source": "https://pytorch.org/docs/stable/torch.html#locally-disabling-gradient-computation",
        "context": " "
    },
    {
        "Answer": ">>> torch.rand(4)\ntensor([ 0.5204,  0.2503,  0.3525,  0.5673])\n>>> torch.rand(2, 3)\ntensor([[ 0.8237,  0.5781,  0.6879],\n        [ 0.3816,  0.7249,  0.0998]])\n",
        "Question": "How to use torch.rand, give an example?",
        "Id": 563,
        "source": "https://pytorch.org/docs/stable/generated/torch.rand.html#torch.rand",
        "context": " The shape of the tensor is defined by the variable argumentsize."
    },
    {
        "Answer": ">>> t = torch.tensor([[10, 30, 20], [60, 40, 50]])\n>>> max_idx = torch.argmax(t)\n>>> torch.take_along_dim(t, max_idx)\ntensor([60])\n>>> sorted_idx = torch.argsort(t, dim=1)\n>>> torch.take_along_dim(t, sorted_idx, dim=1)\ntensor([[10, 20, 30],\n        [40, 50, 60]])\n",
        "Question": "How to use torch.take_along_dim, give an example?",
        "Id": 564,
        "source": "https://pytorch.org/docs/stable/generated/torch.take_along_dim.html#torch.take_along_dim",
        "context": " Functions that return indices along a dimension, liketorch.argmax()andtorch.argsort(),\nare designed to work with this function. See the examples below."
    },
    {
        "Answer": ">>> a = torch.tensor([-float('inf'), float('inf'), 1.2])\n>>> torch.isposinf(a)\ntensor([False,  True, False])\n",
        "Question": "How to use torch.isposinf, give an example?",
        "Id": 565,
        "source": "https://pytorch.org/docs/stable/generated/torch.isposinf.html#torch.isposinf",
        "context": " "
    },
    {
        "Answer": ">>> torch.logical_and(torch.tensor([True, False, True]), torch.tensor([True, False, False]))\ntensor([ True, False, False])\n>>> a = torch.tensor([0, 1, 10, 0], dtype=torch.int8)\n>>> b = torch.tensor([4, 0, 1, 0], dtype=torch.int8)\n>>> torch.logical_and(a, b)\ntensor([False, False,  True, False])\n>>> torch.logical_and(a.double(), b.double())\ntensor([False, False,  True, False])\n>>> torch.logical_and(a.double(), b)\ntensor([False, False,  True, False])\n>>> torch.logical_and(a, b, out=torch.empty(4, dtype=torch.bool))\ntensor([False, False,  True, False])\n",
        "Question": "How to use torch.logical_and, give an example?",
        "Id": 566,
        "source": "https://pytorch.org/docs/stable/generated/torch.logical_and.html#torch.logical_and",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(5)\n>>> a\ntensor([ 0.0090, -0.2262, -0.0682, -0.2866,  0.3940])\n>>> torch.neg(a)\ntensor([-0.0090,  0.2262,  0.0682,  0.2866, -0.3940])\n",
        "Question": "How to use torch.neg, give an example?",
        "Id": 567,
        "source": "https://pytorch.org/docs/stable/generated/torch.neg.html#torch.neg",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.arange(1., 10.).view(3, 3)\n>>> x\ntensor([[ 1.,  2.,  3.],\n        [ 4.,  5.,  6.],\n        [ 7.,  8.,  9.]])\n>>> torch.trace(x)\ntensor(15.)\n",
        "Question": "How to use torch.trace, give an example?",
        "Id": 568,
        "source": "https://pytorch.org/docs/stable/generated/torch.trace.html#torch.trace",
        "context": " "
    },
    {
        "Answer": "import torch.distributed as dist\n\n# Use address of one of the machines\ndist.init_process_group(backend, init_method='tcp://10.1.1.20:23456',\n                        rank=args.rank, world_size=4)\n",
        "Question": "How to use There are two ways to initialize using TCP, both requiring a network address\nreachable from all processes and a desiredworld_size. The first way\nrequires specifying an address that belongs to the rank 0 process. This\ninitialization method requires that all processes have manually specified ranks.Note that multicast address is not supported anymore in the latest distributed\npackage.group_nameis deprecated as well., give an example?",
        "Id": 569,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Note that multicast address is not supported anymore in the latest distributed\npackage.group_nameis deprecated as well."
    },
    {
        "Answer": "import torch.distributed as dist\n\n# rank should always be specified\ndist.init_process_group(backend, init_method='file:///mnt/nfs/sharedfile',\n                        world_size=4, rank=args.rank)\n",
        "Question": "How to use Another initialization method makes use of a file system that is shared and\nvisible from all machines in a group, along with a desiredworld_size. The URL should start\nwithfile://and contain a path to a non-existent file (in an existing\ndirectory) on a shared file system. File-system initialization will automatically\ncreate that file if it doesn\u2019t exist, but will not delete the file. Therefore, it\nis your responsibility to make sure that the file is cleaned up before the nextinit_process_group()call on the same file path/name.Note that automatic rank assignment is not supported anymore in the latest\ndistributed package andgroup_nameis deprecated as well., give an example?",
        "Id": 570,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Note that automatic rank assignment is not supported anymore in the latest\ndistributed package andgroup_nameis deprecated as well."
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> # Run on process 1 (server)\n>>> server_store = dist.TCPStore(\"127.0.0.1\", 1234, 2, True, timedelta(seconds=30))\n>>> # Run on process 2 (client)\n>>> client_store = dist.TCPStore(\"127.0.0.1\", 1234, 2, False)\n>>> # Use any of the store methods from either the client or server after initialization\n>>> server_store.set(\"first_key\", \"first_value\")\n>>> client_store.get(\"first_key\")\n",
        "Question": "How to use Distributed Key Value Store, give an example?",
        "Id": 571,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> store = dist.HashStore()\n>>> # store can be used from other threads\n>>> # Use any of the store methods after initialization\n>>> store.set(\"first_key\", \"first_value\")\n",
        "Question": "How  , give an example?",
        "Id": 572,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> store1 = dist.FileStore(\"/tmp/filestore\", 2)\n>>> store2 = dist.FileStore(\"/tmp/filestore\", 2)\n>>> # Use any of the store methods from either the client or server after initialization\n>>> store1.set(\"first_key\", \"first_value\")\n>>> store2.get(\"first_key\")\n",
        "Question": "How  , give an example?",
        "Id": 573,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> store = dist.TCPStore(\"127.0.0.1\", 0, 1, True, timedelta(seconds=30))\n>>> store.set(\"first_key\", \"first_value\")\n>>> # Should return \"first_value\"\n>>> store.get(\"first_key\")\n",
        "Question": "How to use torch.distributed.Store.set, give an example?",
        "Id": 574,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> store = dist.TCPStore(\"127.0.0.1\", 0, 1, True, timedelta(seconds=30))\n>>> store.set(\"first_key\", \"first_value\")\n>>> # Should return \"first_value\"\n>>> store.get(\"first_key\")\n",
        "Question": "How to use torch.distributed.Store.get, give an example?",
        "Id": 575,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> # Using TCPStore as an example, other store types can also be used\n>>> store = dist.TCPStore(\"127.0.0.1\", 0, 1, True, timedelta(seconds=30))\n>>> store.add(\"first_key\", 1)\n>>> store.add(\"first_key\", 6)\n>>> # Should return 7\n>>> store.get(\"first_key\")\n",
        "Question": "How to use torch.distributed.Store.add, give an example?",
        "Id": 576,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> # Using TCPStore as an example, other store types can also be used\n>>> store = dist.TCPStore(\"127.0.0.1\", 0, 1, True, timedelta(seconds=30))\n>>> # This will throw an exception after 30 seconds\n>>> store.wait([\"bad_key\"])\n",
        "Question": "How to use torch.distributed.Store.wait, give an example?",
        "Id": 577,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> # Using TCPStore as an example, other store types can also be used\n>>> store = dist.TCPStore(\"127.0.0.1\", 0, 1, True, timedelta(seconds=30))\n>>> # This will throw an exception after 10 seconds\n>>> store.wait([\"bad_key\"], timedelta(seconds=10))\n",
        "Question": "How  , give an example?",
        "Id": 578,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> # Using TCPStore as an example, other store types can also be used\n>>> store = dist.TCPStore(\"127.0.0.1\", 0, 1, True, timedelta(seconds=30))\n>>> store.set(\"first_key\", \"first_value\")\n>>> # This should return 2\n>>> store.num_keys()\n",
        "Question": "How to use torch.distributed.Store.num_keys, give an example?",
        "Id": 579,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> # Using TCPStore as an example, HashStore can also be used\n>>> store = dist.TCPStore(\"127.0.0.1\", 0, 1, True, timedelta(seconds=30))\n>>> store.set(\"first_key\")\n>>> # This should return true\n>>> store.delete_key(\"first_key\")\n>>> # This should return false\n>>> store.delete_key(\"bad_key\")\n",
        "Question": "How to use torch.distributed.Store.delete_key, give an example?",
        "Id": 580,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> import torch.distributed as dist\n>>> from datetime import timedelta\n>>> # Using TCPStore as an example, other store types can also be used\n>>> store = dist.TCPStore(\"127.0.0.1\", 0, 1, True, timedelta(seconds=30))\n>>> store.set_timeout(timedelta(seconds=10))\n>>> # This will throw an exception after 10 seconds\n>>> store.wait([\"bad_key\"])\n",
        "Question": "How to use torch.distributed.Store.set_timeout, give an example?",
        "Id": 581,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": "# Code runs on each rank.\ndist.init_process_group(\"nccl\", rank=rank, world_size=2)\noutput = torch.tensor([rank]).cuda(rank)\ns = torch.cuda.Stream()\nhandle = dist.all_reduce(output, async_op=True)\n# Wait ensures the operation is enqueued, but not necessarily complete.\nhandle.wait()\n# Using result on non-default stream.\nwith torch.cuda.stream(s):\n    s.wait_stream(torch.cuda.default_stream())\n    output.add_(100)\nif rank == 0:\n    # if the explicit call to wait_stream was omitted, the output below will be\n    # non-deterministically 1 or 101, depending on whether the allreduce overwrote\n    # the value after the add completed.\n    print(output)\n",
        "Question": "How to use The following code can serve as a reference regarding semantics for CUDA operations when using distributed collectives.\nIt shows the explicit need to synchronize when using collective outputs on different CUDA streams:, give an example?",
        "Id": 582,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " The following code can serve as a reference regarding semantics for CUDA operations when using distributed collectives.\nIt shows the explicit need to synchronize when using collective outputs on different CUDA streams:"
    },
    {
        "Answer": ">>> # Note: Process group initialization omitted on each rank.\n>>> import torch.distributed as dist\n>>> if dist.get_rank() == 0:\n>>>     # Assumes world_size of 3.\n>>>     objects = [\"foo\", 12, {1: 2}] # any picklable object\n>>> else:\n>>>     objects = [None, None, None]\n>>> dist.broadcast_object_list(objects, src=0)\n>>> broadcast_objects\n['foo', 12, {1: 2}]\n",
        "Question": "How to use torch.distributed.broadcast_object_list, give an example?",
        "Id": 583,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> # All tensors below are of torch.int64 type.\n>>> # We have 2 process groups, 2 ranks.\n>>> tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank\n>>> tensor\ntensor([1, 2]) # Rank 0\ntensor([3, 4]) # Rank 1\n>>> dist.all_reduce(tensor, op=ReduceOp.SUM)\n>>> tensor\ntensor([4, 6]) # Rank 0\ntensor([4, 6]) # Rank 1\n",
        "Question": "How to use torch.distributed.all_reduce, give an example?",
        "Id": 584,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Complex tensors are supported."
    },
    {
        "Answer": ">>> # All tensors below are of torch.cfloat type.\n>>> # We have 2 process groups, 2 ranks.\n>>> tensor = torch.tensor([1+1j, 2+2j], dtype=torch.cfloat) + 2 * rank * (1+1j)\n>>> tensor\ntensor([1.+1.j, 2.+2.j]) # Rank 0\ntensor([3.+3.j, 4.+4.j]) # Rank 1\n>>> dist.all_reduce(tensor, op=ReduceOp.SUM)\n>>> tensor\ntensor([4.+4.j, 6.+6.j]) # Rank 0\ntensor([4.+4.j, 6.+6.j]) # Rank 1\n",
        "Question": "How  Complex tensors are supported., give an example?",
        "Id": 585,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Complex tensors are supported."
    },
    {
        "Answer": ">>> # All tensors below are of torch.int64 dtype.\n>>> # We have 2 process groups, 2 ranks.\n>>> tensor_list = [torch.zero(2, dtype=torch.int64) for _ in range(2)]\n>>> tensor_list\n[tensor([0, 0]), tensor([0, 0])] # Rank 0 and 1\n>>> tensor = torch.arange(2, dtype=torch.int64) + 1 + 2 * rank\n>>> tensor\ntensor([1, 2]) # Rank 0\ntensor([3, 4]) # Rank 1\n>>> dist.all_gather(tensor_list, tensor)\n>>> tensor_list\n[tensor([1, 2]), tensor([3, 4])] # Rank 0\n[tensor([1, 2]), tensor([3, 4])] # Rank 1\n",
        "Question": "How to use torch.distributed.all_gather, give an example?",
        "Id": 586,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Complex tensors are supported."
    },
    {
        "Answer": ">>> # All tensors below are of torch.cfloat dtype.\n>>> # We have 2 process groups, 2 ranks.\n>>> tensor_list = [torch.zero(2, dtype=torch.cfloat) for _ in range(2)]\n>>> tensor_list\n[tensor([0.+0.j, 0.+0.j]), tensor([0.+0.j, 0.+0.j])] # Rank 0 and 1\n>>> tensor = torch.tensor([1+1j, 2+2j], dtype=torch.cfloat) + 2 * rank * (1+1j)\n>>> tensor\ntensor([1.+1.j, 2.+2.j]) # Rank 0\ntensor([3.+3.j, 4.+4.j]) # Rank 1\n>>> dist.all_gather(tensor_list, tensor)\n>>> tensor_list\n[tensor([1.+1.j, 2.+2.j]), tensor([3.+3.j, 4.+4.j])] # Rank 0\n[tensor([1.+1.j, 2.+2.j]), tensor([3.+3.j, 4.+4.j])] # Rank 1\n",
        "Question": "How  Complex tensors are supported., give an example?",
        "Id": 587,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Complex tensors are supported."
    },
    {
        "Answer": ">>> # Note: Process group initialization omitted on each rank.\n>>> import torch.distributed as dist\n>>> # Assumes world_size of 3.\n>>> gather_objects = [\"foo\", 12, {1: 2}] # any picklable object\n>>> output = [None for _ in gather_objects]\n>>> dist.all_gather_object(output, gather_objects[dist.get_rank()])\n>>> output\n['foo', 12, {1: 2}]\n",
        "Question": "How to use torch.distributed.all_gather_object, give an example?",
        "Id": 588,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> # Note: Process group initialization omitted on each rank.\n>>> import torch.distributed as dist\n>>> # Assumes world_size of 3.\n>>> gather_objects = [\"foo\", 12, {1: 2}] # any picklable object\n>>> output = [None for _ in gather_objects]\n>>> dist.gather_object(\n        gather_objects[dist.get_rank()],\n        output if dist.get_rank() == 0 else None,\n        dst=0\n    )\n>>> # On rank 0\n>>> output\n['foo', 12, {1: 2}]\n",
        "Question": "How to use torch.distributed.gather_object, give an example?",
        "Id": 589,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> # Note: Process group initialization omitted on each rank.\n>>> import torch.distributed as dist\n>>> if dist.get_rank() == 0:\n>>>     # Assumes world_size of 3.\n>>>     objects = [\"foo\", 12, {1: 2}] # any picklable object\n>>> else:\n>>>     # Can be any list on non-src ranks, elements are not used.\n>>>     objects = [None, None, None]\n>>> output_list = [None]\n>>> dist.scatter_object_list(output_list, objects, src=0)\n>>> # Rank i gets objects[i]. For example, on rank 2:\n>>> output_list\n[{1: 2}]\n",
        "Question": "How to use torch.distributed.scatter_object_list, give an example?",
        "Id": 590,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> input = torch.arange(4) + rank * 4\n>>> input = list(input.chunk(4))\n>>> input\n[tensor([0]), tensor([1]), tensor([2]), tensor([3])]     # Rank 0\n[tensor([4]), tensor([5]), tensor([6]), tensor([7])]     # Rank 1\n[tensor([8]), tensor([9]), tensor([10]), tensor([11])]   # Rank 2\n[tensor([12]), tensor([13]), tensor([14]), tensor([15])] # Rank 3\n>>> output = list(torch.empty([4], dtype=torch.int64).chunk(4))\n>>> dist.all_to_all(output, input)\n>>> output\n[tensor([0]), tensor([4]), tensor([8]), tensor([12])]    # Rank 0\n[tensor([1]), tensor([5]), tensor([9]), tensor([13])]    # Rank 1\n[tensor([2]), tensor([6]), tensor([10]), tensor([14])]   # Rank 2\n[tensor([3]), tensor([7]), tensor([11]), tensor([15])]   # Rank 3\n",
        "Question": "How to use torch.distributed.all_to_all, give an example?",
        "Id": 591,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> # Essentially, it is similar to following operation:\n>>> scatter_list = input\n>>> gather_list  = output\n>>> for i in range(world_size):\n>>>   dist.scatter(gather_list[i], scatter_list if i == rank else [], src = i)\n",
        "Question": "How  , give an example?",
        "Id": 592,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": ">>> input\ntensor([0, 1, 2, 3, 4, 5])                                       # Rank 0\ntensor([10, 11, 12, 13, 14, 15, 16, 17, 18])                     # Rank 1\ntensor([20, 21, 22, 23, 24])                                     # Rank 2\ntensor([30, 31, 32, 33, 34, 35, 36])                             # Rank 3\n>>> input_splits\n[2, 2, 1, 1]                                                     # Rank 0\n[3, 2, 2, 2]                                                     # Rank 1\n[2, 1, 1, 1]                                                     # Rank 2\n[2, 2, 2, 1]                                                     # Rank 3\n>>> output_splits\n[2, 3, 2, 2]                                                     # Rank 0\n[2, 2, 1, 2]                                                     # Rank 1\n[1, 2, 1, 2]                                                     # Rank 2\n[1, 2, 1, 1]                                                     # Rank 3\n>>> input = list(input.split(input_splits))\n>>> input\n[tensor([0, 1]), tensor([2, 3]), tensor([4]), tensor([5])]                   # Rank 0\n[tensor([10, 11, 12]), tensor([13, 14]), tensor([15, 16]), tensor([17, 18])] # Rank 1\n[tensor([20, 21]), tensor([22]), tensor([23]), tensor([24])]                 # Rank 2\n[tensor([30, 31]), tensor([32, 33]), tensor([34, 35]), tensor([36])]         # Rank 3\n>>> output = ...\n>>> dist.all_to_all(output, input)\n>>> output\n[tensor([0, 1]), tensor([10, 11, 12]), tensor([20, 21]), tensor([30, 31])]   # Rank 0\n[tensor([2, 3]), tensor([13, 14]), tensor([22]), tensor([32, 33])]           # Rank 1\n[tensor([4]), tensor([15, 16]), tensor([23]), tensor([34, 35])]              # Rank 2\n[tensor([5]), tensor([17, 18]), tensor([24]), tensor([36])]                  # Rank 3\n",
        "Question": "How  , give an example?",
        "Id": 593,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " "
    },
    {
        "Answer": "import torch\nimport torch.distributed as dist\nwith torch.profiler():\n    tensor = torch.randn(20, 10)\n    dist.all_reduce(tensor)\n",
        "Question": "How to use Note that you can usetorch.profiler(recommended, only available after 1.8.1)  ortorch.autograd.profilerto profile collective communication and point-to-point communication APIs mentioned here. All out-of-the-box backends (gloo,nccl,mpi) are supported and collective communication usage will be rendered as expected in profiling output/traces. Profiling your code is the same as any regular torch operator:, give an example?",
        "Id": 594,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Note that you can usetorch.profiler(recommended, only available after 1.8.1)  ortorch.autograd.profilerto profile collective communication and point-to-point communication APIs mentioned here. All out-of-the-box backends (gloo,nccl,mpi) are supported and collective communication usage will be rendered as expected in profiling output/traces. Profiling your code is the same as any regular torch operator:"
    },
    {
        "Answer": "import torch\nimport torch.distributed as dist\n\ndist.init_process_group(backend=\"nccl\",\n                        init_method=\"file:///distributed_test\",\n                        world_size=2,\n                        rank=0)\ntensor_list = []\nfor dev_idx in range(torch.cuda.device_count()):\n    tensor_list.append(torch.FloatTensor([1]).cuda(dev_idx))\n\ndist.all_reduce_multigpu(tensor_list)\n",
        "Question": "How to use For example, if the system we use for distributed training has 2 nodes, each\nof which has 8 GPUs. On each of the 16 GPUs, there is a tensor that we would\nlike to all-reduce. The following code can serve as a reference:Code running on Node 0, give an example?",
        "Id": 595,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " For example, if the system we use for distributed training has 2 nodes, each\nof which has 8 GPUs. On each of the 16 GPUs, there is a tensor that we would\nlike to all-reduce. The following code can serve as a reference:Code running on Node 0"
    },
    {
        "Answer": "import torch\nimport torch.distributed as dist\n\ndist.init_process_group(backend=\"nccl\",\n                        init_method=\"file:///distributed_test\",\n                        world_size=2,\n                        rank=1)\ntensor_list = []\nfor dev_idx in range(torch.cuda.device_count()):\n    tensor_list.append(torch.FloatTensor([1]).cuda(dev_idx))\n\ndist.all_reduce_multigpu(tensor_list)\n",
        "Question": "How to use Code running on Node 0Code running on Node 1, give an example?",
        "Id": 596,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Code running on Node 0Code running on Node 1"
    },
    {
        "Answer": ">>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3 and all other\n           arguments of your training script)\n",
        "Question": "How to use In both cases of single-node distributed training or multi-node distributed\ntraining, this utility will launch the given number of processes per node\n(--nproc_per_node). If used for GPU training, this number needs to be less\nor equal to the number of GPUs on the current system (nproc_per_node),\nand each process will be operating on a single GPU fromGPU 0 to\nGPU (nproc_per_node - 1).How to use this module:, give an example?",
        "Id": 597,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " In both cases of single-node distributed training or multi-node distributed\ntraining, this utility will launch the given number of processes per node\n(--nproc_per_node). If used for GPU training, this number needs to be less\nor equal to the number of GPUs on the current system (nproc_per_node),\nand each process will be operating on a single GPU fromGPU 0 to\nGPU (nproc_per_node - 1).How to use this module:"
    },
    {
        "Answer": ">>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=0 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\n",
        "Question": "How to use How to use this module:Node 1:(IP: 192.168.1.1, and has a free port: 1234), give an example?",
        "Id": 598,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " How to use this module:Node 1:(IP: 192.168.1.1, and has a free port: 1234)"
    },
    {
        "Answer": ">>> python -m torch.distributed.launch --nproc_per_node=NUM_GPUS_YOU_HAVE\n           --nnodes=2 --node_rank=1 --master_addr=\"192.168.1.1\"\n           --master_port=1234 YOUR_TRAINING_SCRIPT.py (--arg1 --arg2 --arg3\n           and all other arguments of your training script)\n",
        "Question": "How to use Node 1:(IP: 192.168.1.1, and has a free port: 1234)Node 2:, give an example?",
        "Id": 599,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Node 1:(IP: 192.168.1.1, and has a free port: 1234)Node 2:"
    },
    {
        "Answer": ">>> python -m torch.distributed.launch --help\n",
        "Question": "How  Node 1:(IP: 192.168.1.1, and has a free port: 1234)Node 2:, give an example?",
        "Id": 600,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Node 1:(IP: 192.168.1.1, and has a free port: 1234)Node 2:"
    },
    {
        "Answer": ">>> import argparse\n>>> parser = argparse.ArgumentParser()\n>>> parser.add_argument(\"--local_rank\", type=int)\n>>> args = parser.parse_args()\n",
        "Question": "How to use 2. In your training program, you must parse the command-line argument:--local_rank=LOCAL_PROCESS_RANK, which will be provided by this module.\nIf your training program uses GPUs, you should ensure that your code only\nruns on the GPU device of LOCAL_PROCESS_RANK. This can be done by:Parsing the local_rank argument, give an example?",
        "Id": 601,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " 2. In your training program, you must parse the command-line argument:--local_rank=LOCAL_PROCESS_RANK, which will be provided by this module.\nIf your training program uses GPUs, you should ensure that your code only\nruns on the GPU device of LOCAL_PROCESS_RANK. This can be done by:Parsing the local_rank argument"
    },
    {
        "Answer": ">>> torch.cuda.set_device(args.local_rank)  # before your code runs\n",
        "Question": "How to use Parsing the local_rank argumentSet your device to local rank using either, give an example?",
        "Id": 602,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Parsing the local_rank argumentSet your device to local rank using either"
    },
    {
        "Answer": ">>> with torch.cuda.device(args.local_rank):\n>>>    # your code to run\n",
        "Question": "How to use Set your device to local rank using eitheror, give an example?",
        "Id": 603,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " Set your device to local rank using eitheror"
    },
    {
        "Answer": "torch.distributed.init_process_group(backend='YOUR BACKEND',\n                                     init_method='env://')\n",
        "Question": "How to use or3. In your training program, you are supposed to call the following function\nat the beginning to start the distributed backend. You need to make sure that\nthe init_method usesenv://, which is the only supportedinit_methodby this module., give an example?",
        "Id": 604,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " or3. In your training program, you are supposed to call the following function\nat the beginning to start the distributed backend. You need to make sure that\nthe init_method usesenv://, which is the only supportedinit_methodby this module."
    },
    {
        "Answer": "model = torch.nn.parallel.DistributedDataParallel(model,\n                                                  device_ids=[args.local_rank],\n                                                  output_device=args.local_rank)\n",
        "Question": "How to use 3. In your training program, you are supposed to call the following function\nat the beginning to start the distributed backend. You need to make sure that\nthe init_method usesenv://, which is the only supportedinit_methodby this module.4. In your training program, you can either use regular distributed functions\nor usetorch.nn.parallel.DistributedDataParallel()module. If your\ntraining program uses GPUs for training and you would like to usetorch.nn.parallel.DistributedDataParallel()module,\nhere is how to configure it., give an example?",
        "Id": 605,
        "source": "https://pytorch.org/docs/stable/distributed.html",
        "context": " 3. In your training program, you are supposed to call the following function\nat the beginning to start the distributed backend. You need to make sure that\nthe init_method usesenv://, which is the only supportedinit_methodby this module.4. In your training program, you can either use regular distributed functions\nor usetorch.nn.parallel.DistributedDataParallel()module. If your\ntraining program uses GPUs for training and you would like to usetorch.nn.parallel.DistributedDataParallel()module,\nhere is how to configure it."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-0.6341, -1.4208, -1.0900,  0.5826])\n>>> torch.ceil(a)\ntensor([-0., -1., -1.,  1.])\n",
        "Question": "How to use torch.ceil, give an example?",
        "Id": 606,
        "source": "https://pytorch.org/docs/stable/generated/torch.ceil.html#torch.ceil",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 607,
        "source": "https://pytorch.org/docs/stable/torch.html#comparison-ops",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a\ntensor([[ 0.9478,  0.9158, -1.1295],\n        [ 0.9701,  0.7346, -1.8044],\n        [-0.2337,  0.0557,  0.6929]])\n>>> torch.linalg.det(a)\ntensor(0.0934)\n\n>>> out = torch.empty(0)\n>>> torch.linalg.det(a, out=out)\ntensor(0.0934)\n>>> out\ntensor(0.0934)\n\n>>> a = torch.randn(3, 2, 2)\n>>> a\ntensor([[[ 0.9254, -0.6213],\n         [-0.5787,  1.6843]],\n\n        [[ 0.3242, -0.9665],\n         [ 0.4539, -0.0887]],\n\n        [[ 1.1336, -0.4025],\n         [-0.7089,  0.9032]]])\n>>> torch.linalg.det(a)\ntensor([1.1990, 0.4099, 0.7386])\n",
        "Question": "How to use torch.linalg.det, give an example?",
        "Id": 608,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.det.html#torch.linalg.det",
        "context": " Supports input of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and ifAis a batch of matrices then\nthe output has the same batch dimensions."
    },
    {
        "Answer": ">>> torch.nonzero(torch.tensor([1, 1, 1, 0, 1]))\ntensor([[ 0],\n        [ 1],\n        [ 2],\n        [ 4]])\n>>> torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n...                             [0.0, 0.4, 0.0, 0.0],\n...                             [0.0, 0.0, 1.2, 0.0],\n...                             [0.0, 0.0, 0.0,-0.4]]))\ntensor([[ 0,  0],\n        [ 1,  1],\n        [ 2,  2],\n        [ 3,  3]])\n>>> torch.nonzero(torch.tensor([1, 1, 1, 0, 1]), as_tuple=True)\n(tensor([0, 1, 2, 4]),)\n>>> torch.nonzero(torch.tensor([[0.6, 0.0, 0.0, 0.0],\n...                             [0.0, 0.4, 0.0, 0.0],\n...                             [0.0, 0.0, 1.2, 0.0],\n...                             [0.0, 0.0, 0.0,-0.4]]), as_tuple=True)\n(tensor([0, 1, 2, 3]), tensor([0, 1, 2, 3]))\n>>> torch.nonzero(torch.tensor(5), as_tuple=True)\n(tensor([0]),)\n",
        "Question": "How to use torch.nonzero, give an example?",
        "Id": 609,
        "source": "https://pytorch.org/docs/stable/generated/torch.nonzero.html#torch.nonzero",
        "context": " As a special case, wheninputhas zero dimensions and a nonzero scalar\nvalue, it is treated as a one-dimensional tensor with one element."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-0.4595, -2.1219, -1.4314,  0.7298])\n>>> torch.reciprocal(a)\ntensor([-2.1763, -0.4713, -0.6986,  1.3702])\n",
        "Question": "How to use torch.reciprocal, give an example?",
        "Id": 610,
        "source": "https://pytorch.org/docs/stable/generated/torch.reciprocal.html#torch.reciprocal",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 611,
        "source": "https://pytorch.org/docs/stable/torch.html#",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.randn(3, 4)\n>>> sorted, indices = torch.sort(x)\n>>> sorted\ntensor([[-0.2162,  0.0608,  0.6719,  2.3332],\n        [-0.5793,  0.0061,  0.6058,  0.9497],\n        [-0.5071,  0.3343,  0.9553,  1.0960]])\n>>> indices\ntensor([[ 1,  0,  2,  3],\n        [ 3,  1,  0,  2],\n        [ 0,  3,  1,  2]])\n\n>>> sorted, indices = torch.sort(x, 0)\n>>> sorted\ntensor([[-0.5071, -0.2162,  0.6719, -0.5793],\n        [ 0.0608,  0.0061,  0.9497,  0.3343],\n        [ 0.6058,  0.9553,  1.0960,  2.3332]])\n>>> indices\ntensor([[ 2,  0,  0,  1],\n        [ 0,  1,  1,  2],\n        [ 1,  2,  2,  0]])\n>>> x = torch.tensor([0, 1] * 9)\n>>> x.sort()\ntorch.return_types.sort(\n    values=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n    indices=tensor([ 2, 16,  4,  6, 14,  8,  0, 10, 12,  9, 17, 15, 13, 11,  7,  5,  3,  1]))\n>>> x.sort(stable=True)\ntorch.return_types.sort(\n    values=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n    indices=tensor([ 0,  2,  4,  6,  8, 10, 12, 14, 16,  1,  3,  5,  7,  9, 11, 13, 15, 17]))\n",
        "Question": "How to use torch.sort, give an example?",
        "Id": 612,
        "source": "https://pytorch.org/docs/stable/generated/torch.sort.html#torch.sort",
        "context": " A namedtuple of (values, indices) is returned, where thevaluesare the\nsorted values andindicesare the indices of the elements in the originalinputtensor."
    },
    {
        "Answer": ">>> a = torch.randint(10, (4,))\n>>> a\ntensor([6, 4, 7, 1])\n>>> torch.float_power(a, 2)\ntensor([36., 16., 49.,  1.], dtype=torch.float64)\n\n>>> a = torch.arange(1, 5)\n>>> a\ntensor([ 1,  2,  3,  4])\n>>> exp = torch.tensor([2, -3, 4, -5])\n>>> exp\ntensor([ 2, -3,  4, -5])\n>>> torch.float_power(a, exp)\ntensor([1.0000e+00, 1.2500e-01, 8.1000e+01, 9.7656e-04], dtype=torch.float64)\n",
        "Question": "How to use torch.float_power, give an example?",
        "Id": 613,
        "source": "https://pytorch.org/docs/stable/generated/torch.float_power.html#torch.float_power",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(2, 3)\n>>> torch.diag_embed(a)\ntensor([[[ 1.5410,  0.0000,  0.0000],\n         [ 0.0000, -0.2934,  0.0000],\n         [ 0.0000,  0.0000, -2.1788]],\n\n        [[ 0.5684,  0.0000,  0.0000],\n         [ 0.0000, -1.0845,  0.0000],\n         [ 0.0000,  0.0000, -1.3986]]])\n\n>>> torch.diag_embed(a, offset=1, dim1=0, dim2=2)\ntensor([[[ 0.0000,  1.5410,  0.0000,  0.0000],\n         [ 0.0000,  0.5684,  0.0000,  0.0000]],\n\n        [[ 0.0000,  0.0000, -0.2934,  0.0000],\n         [ 0.0000,  0.0000, -1.0845,  0.0000]],\n\n        [[ 0.0000,  0.0000,  0.0000, -2.1788],\n         [ 0.0000,  0.0000,  0.0000, -1.3986]],\n\n        [[ 0.0000,  0.0000,  0.0000,  0.0000],\n         [ 0.0000,  0.0000,  0.0000,  0.0000]]])\n",
        "Question": "How to use torch.diag_embed, give an example?",
        "Id": 614,
        "source": "https://pytorch.org/docs/stable/generated/torch.diag_embed.html#torch.diag_embed",
        "context": " Applyingtorch.diagonal()to the output of this function with\nthe same arguments yields a matrix identical to input. However,torch.diagonal()has different default dimensions, so those\nneed to be explicitly specified."
    },
    {
        "Answer": ">>> torch.frac(torch.tensor([1, 2.5, -3.2]))\ntensor([ 0.0000,  0.5000, -0.2000])\n",
        "Question": "How to use torch.frac, give an example?",
        "Id": 615,
        "source": "https://pytorch.org/docs/stable/generated/torch.frac.html#torch.frac",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(2, 2)\n>>> h, tau = torch.geqrf(a)\n>>> q = torch.linalg.householder_product(h, tau)\n>>> torch.allclose(q, torch.linalg.qr(a)[0])\nTrue\n\n>>> h = torch.randn(3, 2, 2, dtype=torch.complex128)\n>>> tau = torch.randn(3, 1, dtype=torch.complex128)\n>>> q = torch.linalg.householder_product(h, tau)\n>>> q\ntensor([[[ 1.8034+0.4184j,  0.2588-1.0174j],\n        [-0.6853+0.7953j,  2.0790+0.5620j]],\n\n        [[ 1.4581+1.6989j, -1.5360+0.1193j],\n        [ 1.3877-0.6691j,  1.3512+1.3024j]],\n\n        [[ 1.4766+0.5783j,  0.0361+0.6587j],\n        [ 0.6396+0.1612j,  1.3693+0.4481j]]], dtype=torch.complex128)\n",
        "Question": "How to use torch.linalg.householder_product, give an example?",
        "Id": 616,
        "source": "https://pytorch.org/docs/stable/generated/torch.linalg.householder_product.html#torch.linalg.householder_product",
        "context": " Supports inputs of float, double, cfloat and cdouble dtypes.\nAlso supports batches of matrices, and if the inputs are batches of matrices then\nthe output has the same batch dimensions."
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a\ntensor([[-1.0813, -0.8619,  0.7105],\n        [ 0.0935,  0.1380,  2.2112],\n        [-0.3409, -0.9828,  0.0289]])\n>>> torch.tril(a)\ntensor([[-1.0813,  0.0000,  0.0000],\n        [ 0.0935,  0.1380,  0.0000],\n        [-0.3409, -0.9828,  0.0289]])\n\n>>> b = torch.randn(4, 6)\n>>> b\ntensor([[ 1.2219,  0.5653, -0.2521, -0.2345,  1.2544,  0.3461],\n        [ 0.4785, -0.4477,  0.6049,  0.6368,  0.8775,  0.7145],\n        [ 1.1502,  3.2716, -1.1243, -0.5413,  0.3615,  0.6864],\n        [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0978]])\n>>> torch.tril(b, diagonal=1)\ntensor([[ 1.2219,  0.5653,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.4785, -0.4477,  0.6049,  0.0000,  0.0000,  0.0000],\n        [ 1.1502,  3.2716, -1.1243, -0.5413,  0.0000,  0.0000],\n        [-0.0614, -0.7344, -1.3164, -0.7648, -1.4024,  0.0000]])\n>>> torch.tril(b, diagonal=-1)\ntensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 0.4785,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n        [ 1.1502,  3.2716,  0.0000,  0.0000,  0.0000,  0.0000],\n        [-0.0614, -0.7344, -1.3164,  0.0000,  0.0000,  0.0000]])\n",
        "Question": "How to use torch.tril, give an example?",
        "Id": 617,
        "source": "https://pytorch.org/docs/stable/generated/torch.tril.html#torch.tril",
        "context": " The argumentdiagonalcontrols which diagonal to consider. Ifdiagonal= 0, all elements on and below the main diagonal are\nretained. A positive value includes just as many diagonals above the main\ndiagonal, and similarly a negative value excludes just as many diagonals below\nthe main diagonal. The main diagonal are the set of indices{(i,i)}\\lbrace (i, i) \\rbrace{(i,i)}fori\u2208[0,min\u2061{d1,d2}\u22121]i \\in [0, \\min\\{d_{1}, d_{2}\\} - 1]i\u2208[0,min{d1\u200b,d2\u200b}\u22121]whered1,d2d_{1}, d_{2}d1\u200b,d2\u200bare the dimensions of the matrix."
    },
    {
        "Answer": ">>> torch.i0(torch.arange(5, dtype=torch.float32))\ntensor([ 1.0000,  1.2661,  2.2796,  4.8808, 11.3019])\n",
        "Question": "How to use torch.i0, give an example?",
        "Id": 618,
        "source": "https://pytorch.org/docs/stable/generated/torch.i0.html#torch.i0",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([1, 2, 3])\n>>> b = torch.tensor([4, 5, 6])\n>>> torch.hstack((a,b))\ntensor([1, 2, 3, 4, 5, 6])\n>>> a = torch.tensor([[1],[2],[3]])\n>>> b = torch.tensor([[4],[5],[6]])\n>>> torch.hstack((a,b))\ntensor([[1, 4],\n        [2, 5],\n        [3, 6]])\n",
        "Question": "How to use torch.hstack, give an example?",
        "Id": 619,
        "source": "https://pytorch.org/docs/stable/generated/torch.hstack.html#torch.hstack",
        "context": " This is equivalent to concatenation along the first axis for 1-D tensors, and along the second axis for all other tensors."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.4331,  1.2475,  0.6834, -0.2791])\n>>> torch.pow(a, 2)\ntensor([ 0.1875,  1.5561,  0.4670,  0.0779])\n>>> exp = torch.arange(1., 5.)\n\n>>> a = torch.arange(1., 5.)\n>>> a\ntensor([ 1.,  2.,  3.,  4.])\n>>> exp\ntensor([ 1.,  2.,  3.,  4.])\n>>> torch.pow(a, exp)\ntensor([   1.,    4.,   27.,  256.])\n",
        "Question": "How to use torch.pow, give an example?",
        "Id": 620,
        "source": "https://pytorch.org/docs/stable/generated/torch.pow.html#torch.pow",
        "context": " Whenexponentis a tensor, the shapes ofinputandexponentmust bebroadcastable."
    },
    {
        "Answer": ">>> exp = torch.arange(1., 5.)\n>>> base = 2\n>>> torch.pow(base, exp)\ntensor([  2.,   4.,   8.,  16.])\n",
        "Question": "How  The operation applied is:, give an example?",
        "Id": 621,
        "source": "https://pytorch.org/docs/stable/generated/torch.pow.html#torch.pow",
        "context": " The operation applied is:"
    },
    {
        "Answer": ">>> a = torch.arange(-0.5, 1, 0.5)\n>>> a\ntensor([-0.5000,  0.0000,  0.5000])\n>>> torch.special.entr(a)\ntensor([  -inf, 0.0000, 0.3466])\n",
        "Question": "How  , give an example?",
        "Id": 622,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erf(torch.tensor([0, -1., 10.]))\ntensor([ 0.0000, -0.8427,  1.0000])\n",
        "Question": "How  , give an example?",
        "Id": 623,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n",
        "Question": "How  , give an example?",
        "Id": 624,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n",
        "Question": "How  , give an example?",
        "Id": 625,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(4)\n>>> t\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n>>> torch.special.expit(t)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
        "Question": "How  , give an example?",
        "Id": 626,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n",
        "Question": "How  , give an example?",
        "Id": 627,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\ntensor([ 1.,  2.,  8., 16.])\n",
        "Question": "How  , give an example?",
        "Id": 628,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.special.gammaln(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How  , give an example?",
        "Id": 629,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.i0e(torch.arange(5, dtype=torch.float32))\ntensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])\n",
        "Question": "How  , give an example?",
        "Id": 630,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n>>> torch.special.logit(a, eps=1e-6)\ntensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
        "Question": "How  , give an example?",
        "Id": 631,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.special.xlog1py(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.special.xlog1py(x, y)\ntensor([1.3863, 2.1972, 2.0794])\n>>> torch.special.xlog1py(x, 4)\ntensor([1.6094, 3.2189, 4.8283])\n>>> torch.special.xlog1py(2, y)\ntensor([2.7726, 2.1972, 1.3863])\n",
        "Question": "How  Similar to SciPy\u2019sscipy.special.xlog1py., give an example?",
        "Id": 632,
        "source": "https://pytorch.org/docs/stable/special.html",
        "context": " Similar to SciPy\u2019sscipy.special.xlog1py."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-0.8166,  1.5308, -0.2530, -0.2091])\n>>> torch.floor(a)\ntensor([-1.,  1., -1., -1.])\n",
        "Question": "How to use torch.floor, give an example?",
        "Id": 633,
        "source": "https://pytorch.org/docs/stable/generated/torch.floor.html#torch.floor",
        "context": " "
    },
    {
        "Answer": ">>> import torch\n>>> x = torch.ones(1, 2, 3, requires_grad=True)\n>>> with torch.inference_mode():\n...   y = x * x\n>>> y.requires_grad\nFalse\n>>> y._version\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nRuntimeError: Inference tensors do not track version counter.\n>>> @torch.inference_mode()\n... def func(x):\n...   return x * x\n>>> out = func(x)\n>>> out.requires_grad\nFalse\n",
        "Question": "How to use inference mode, give an example?",
        "Id": 634,
        "source": "https://pytorch.org/docs/stable/generated/torch.inference_mode.html#torch.inference_mode",
        "context": " "
    },
    {
        "Answer": ">>> a = numpy.array([1, 2, 3])\n>>> t = torch.as_tensor(a)\n>>> t\ntensor([ 1,  2,  3])\n>>> t[0] = -1\n>>> a\narray([-1,  2,  3])\n\n>>> a = numpy.array([1, 2, 3])\n>>> t = torch.as_tensor(a, device=torch.device('cuda'))\n>>> t\ntensor([ 1,  2,  3])\n>>> t[0] = -1\n>>> a\narray([1,  2,  3])\n",
        "Question": "How to use torch.as_tensor, give an example?",
        "Id": 635,
        "source": "https://pytorch.org/docs/stable/generated/torch.as_tensor.html#torch.as_tensor",
        "context": " "
    },
    {
        "Answer": ">>> y = torch.randn((2, 3))\n>>> y\ntensor([[-2.1156,  0.6857, -0.2700],\n        [-1.2145,  0.5540,  2.0431]])\n>>> x = torch.tensor([[1, 3, 4], [1, 2, 3]])\n>>> torch.trapz(y, x)\ntensor([-1.2220,  0.9683])\n",
        "Question": "How to use torch.trapz, give an example?",
        "Id": 636,
        "source": "https://pytorch.org/docs/stable/generated/torch.trapz.html#torch.trapz",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(3)\n>>> a\ntensor([ 0.2015, -0.4255,  2.6087])\n>>> torch.mul(a, 100)\ntensor([  20.1494,  -42.5491,  260.8663])\n",
        "Question": "How to use torch.mul, give an example?",
        "Id": 637,
        "source": "https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul",
        "context": " Ifinputis of typeFloatTensororDoubleTensor,othershould be a real number, otherwise it should be an integer"
    },
    {
        "Answer": ">>> a = torch.randn(4, 1)\n>>> a\ntensor([[ 1.1207],\n        [-0.3137],\n        [ 0.0700],\n        [ 0.8378]])\n>>> b = torch.randn(1, 4)\n>>> b\ntensor([[ 0.5146,  0.1216, -0.5244,  2.2382]])\n>>> torch.mul(a, b)\ntensor([[ 0.5767,  0.1363, -0.5877,  2.5083],\n        [-0.1614, -0.0382,  0.1645, -0.7021],\n        [ 0.0360,  0.0085, -0.0367,  0.1567],\n        [ 0.4312,  0.1019, -0.4394,  1.8753]])\n",
        "Question": "How  The shapes ofinputandothermust bebroadcastable., give an example?",
        "Id": 638,
        "source": "https://pytorch.org/docs/stable/generated/torch.mul.html#torch.mul",
        "context": " The shapes ofinputandothermust bebroadcastable."
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> torch.logsumexp(a, 1)\ntensor([ 0.8442,  1.4322,  0.8711])\n",
        "Question": "How to use torch.logsumexp, give an example?",
        "Id": 639,
        "source": "https://pytorch.org/docs/stable/generated/torch.logsumexp.html#torch.logsumexp",
        "context": " IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimension(s)dimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in the\noutput tensor having 1 (orlen(dim)) fewer dimension(s)."
    },
    {
        "Answer": ">>> a = torch.randn(1, 3)\n>>> a\ntensor([[ 0.6763,  0.7445, -2.2369]])\n>>> torch.max(a)\ntensor(0.7445)\n",
        "Question": "How to use torch.max, give an example?",
        "Id": 640,
        "source": "https://pytorch.org/docs/stable/generated/torch.max.html#torch.max",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[-1.2360, -0.2942, -0.1222,  0.8475],\n        [ 1.1949, -1.1127, -2.2379, -0.6702],\n        [ 1.5717, -0.9207,  0.1297, -1.8768],\n        [-0.6172,  1.0036, -0.6060, -0.2432]])\n>>> torch.max(a, 1)\ntorch.return_types.max(values=tensor([0.8475, 1.1949, 1.5717, 1.0036]), indices=tensor([3, 0, 0, 1]))\n",
        "Question": "How  IfkeepdimisTrue, the output tensors are of the same size\nasinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput., give an example?",
        "Id": 641,
        "source": "https://pytorch.org/docs/stable/generated/torch.max.html#torch.max",
        "context": " IfkeepdimisTrue, the output tensors are of the same size\nasinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting\nin the output tensors having 1 fewer dimension thaninput."
    },
    {
        "Answer": ">>> state_dict = torch.hub.load_state_dict_from_url('https://s3.amazonaws.com/pytorch/models/resnet18-5c106cde.pth')\n",
        "Question": "How to use torch.utils.model_zoo.load_url, give an example?",
        "Id": 642,
        "source": "https://pytorch.org/docs/stable/model_zoo.html",
        "context": " If the object is already present inmodel_dir, it\u2019s deserialized and\nreturned.\nThe default value ofmodel_diris<hub_dir>/checkpointswherehub_diris the directory returned byget_dir()."
    },
    {
        "Answer": ">>> a = torch.randn(1, 3)\n>>> a\ntensor([[ 0.2294, -0.5481,  1.3288]])\n>>> torch.mean(a)\ntensor(0.3367)\n",
        "Question": "How to use torch.mean, give an example?",
        "Id": 643,
        "source": "https://pytorch.org/docs/stable/generated/torch.mean.html#torch.mean",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[-0.3841,  0.6320,  0.4254, -0.7384],\n        [-0.9644,  1.0131, -0.6549, -1.4279],\n        [-0.2951, -1.3350, -0.7694,  0.5600],\n        [ 1.0842, -0.9580,  0.3623,  0.2343]])\n>>> torch.mean(a, 1)\ntensor([-0.0163, -0.5085, -0.4599,  0.1807])\n>>> torch.mean(a, 1, True)\ntensor([[-0.0163],\n        [-0.5085],\n        [-0.4599],\n        [ 0.1807]])\n",
        "Question": "How  IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimension(s)dimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in the\noutput tensor having 1 (orlen(dim)) fewer dimension(s)., give an example?",
        "Id": 644,
        "source": "https://pytorch.org/docs/stable/generated/torch.mean.html#torch.mean",
        "context": " IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimension(s)dimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in the\noutput tensor having 1 (orlen(dim)) fewer dimension(s)."
    },
    {
        "Answer": ">>> a = torch.randn(2, 3)\n>>> a\ntensor([[ 0.0795, -1.2117,  0.9765],\n        [ 1.1707,  0.6706,  0.4884]])\n>>> q = torch.tensor([0.25, 0.5, 0.75])\n>>> torch.quantile(a, q, dim=1, keepdim=True)\ntensor([[[-0.5661],\n        [ 0.5795]],\n\n        [[ 0.0795],\n        [ 0.6706]],\n\n        [[ 0.5280],\n        [ 0.9206]]])\n>>> torch.quantile(a, q, dim=1, keepdim=True).shape\ntorch.Size([3, 2, 1])\n>>> a = torch.arange(4.)\n>>> a\ntensor([0., 1., 2., 3.])\n",
        "Question": "How to use torch.quantile, give an example?",
        "Id": 645,
        "source": "https://pytorch.org/docs/stable/generated/torch.quantile.html#torch.quantile",
        "context": " Ifqis a 1D tensor, the first dimension of the output represents the quantiles and has size\nequal to the size ofq, the remaining dimensions are what remains from the reduction."
    },
    {
        "Answer": ">>> torch.vdot(torch.tensor([2, 3]), torch.tensor([2, 1]))\ntensor(7)\n>>> a = torch.tensor((1 +2j, 3 - 1j))\n>>> b = torch.tensor((2 +1j, 4 - 0j))\n>>> torch.vdot(a, b)\ntensor([16.+1.j])\n>>> torch.vdot(b, a)\ntensor([16.-1.j])\n",
        "Question": "How to use torch.vdot, give an example?",
        "Id": 646,
        "source": "https://pytorch.org/docs/stable/generated/torch.vdot.html#torch.vdot",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.1606, -1.4267, -1.0899, -1.0250 ])\n>>> torch.asinh(a)\ntensor([ 0.1599, -1.1534, -0.9435, -0.8990 ])\n",
        "Question": "How to use torch.asinh, give an example?",
        "Id": 647,
        "source": "https://pytorch.org/docs/stable/generated/torch.asinh.html#torch.asinh",
        "context": " "
    },
    {
        "Answer": "X = torch.linalg.lstsq(A, B).solution\n",
        "Question": "How to use torch.lstsq, give an example?",
        "Id": 648,
        "source": "https://pytorch.org/docs/stable/generated/torch.lstsq.html#torch.lstsq",
        "context": " torch.lstsq()is deprecated in favor oftorch.linalg.lstsq()and will be removed in a future PyTorch release.torch.linalg.lstsq()has reversed arguments and does not return the QR decomposition in the returned tuple,\n(it returns other information about the problem).\nThe returnedsolutionintorch.lstsq()stores the residuals of the solution in the\nlastm - ncolumns in the casem > n. Intorch.linalg.lstsq(), the residuals\nare in the field \u2018residuals\u2019 of the returned named tuple.Unpacking the solution as``X = torch.lstsq(B, A).solution[:A.size(1)]`` should be replaced with"
    },
    {
        "Answer": ">>> A = torch.tensor([[1., 1, 1],\n...                   [2, 3, 4],\n...                   [3, 5, 2],\n...                   [4, 2, 5],\n...                   [5, 4, 3]])\n>>> B = torch.tensor([[-10., -3],\n...                   [ 12, 14],\n...                   [ 14, 12],\n...                   [ 16, 16],\n...                   [ 18, 16]])\n>>> X, _ = torch.lstsq(B, A)\n>>> X\ntensor([[  2.0000,   1.0000],\n        [  1.0000,   1.0000],\n        [  1.0000,   2.0000],\n        [ 10.9635,   4.8501],\n        [  8.9332,   5.2418]])\n",
        "Question": "How  Returned tensorXXXhas shape(max\u2061(m,n)\u00d7k)(\\max(m, n) \\times k)(max(m,n)\u00d7k). The firstnnnrows ofXXXcontains the solution. Ifm\u2265nm \\geq nm\u2265n, the residual sum of squares\nfor the solution in each column is given by the sum of squares of elements in the\nremainingm\u2212nm - nm\u2212nrows of that column., give an example?",
        "Id": 649,
        "source": "https://pytorch.org/docs/stable/generated/torch.lstsq.html#torch.lstsq",
        "context": " Returned tensorXXXhas shape(max\u2061(m,n)\u00d7k)(\\max(m, n) \\times k)(max(m,n)\u00d7k). The firstnnnrows ofXXXcontains the solution. Ifm\u2265nm \\geq nm\u2265n, the residual sum of squares\nfor the solution in each column is given by the sum of squares of elements in the\nremainingm\u2212nm - nm\u2212nrows of that column."
    },
    {
        "Answer": ">>> x=torch.randn(4, dtype=torch.cfloat)\n>>> x\ntensor([(0.4737-0.3839j), (-0.2098-0.6699j), (0.3470-0.9451j), (-0.5174-1.3136j)])\n>>> torch.view_as_real(x)\ntensor([[ 0.4737, -0.3839],\n        [-0.2098, -0.6699],\n        [ 0.3470, -0.9451],\n        [-0.5174, -1.3136]])\n",
        "Question": "How to use torch.view_as_real, give an example?",
        "Id": 650,
        "source": "https://pytorch.org/docs/stable/generated/torch.view_as_real.html#torch.view_as_real",
        "context": " "
    },
    {
        "Answer": ">>> torch.isfinite(torch.tensor([1, float('inf'), 2, float('-inf'), float('nan')]))\ntensor([True,  False,  True,  False,  False])\n",
        "Question": "How to use torch.isfinite, give an example?",
        "Id": 651,
        "source": "https://pytorch.org/docs/stable/generated/torch.isfinite.html#torch.isfinite",
        "context": " Real values are finite when they are not NaN, negative infinity, or infinity.\nComplex values are finite when both their real and imaginary parts are finite."
    },
    {
        "Answer": ">>> x = torch.arange(4).view(2, 2)\n>>> x\ntensor([[0, 1],\n        [2, 3]])\n>>> torch.flipud(x)\ntensor([[2, 3],\n        [0, 1]])\n",
        "Question": "How to use torch.flipud, give an example?",
        "Id": 652,
        "source": "https://pytorch.org/docs/stable/generated/torch.flipud.html#torch.flipud",
        "context": " Flip the entries in each column in the up/down direction.\nRows are preserved, but appear in a different order than before."
    },
    {
        "Answer": ">>> torch.full((2, 3), 3.141592)\ntensor([[ 3.1416,  3.1416,  3.1416],\n        [ 3.1416,  3.1416,  3.1416]])\n",
        "Question": "How to use torch.full, give an example?",
        "Id": 653,
        "source": "https://pytorch.org/docs/stable/generated/torch.full.html#torch.full",
        "context": " "
    },
    {
        "Answer": ">>> g_cpu = torch.Generator()\n>>> g_cuda = torch.Generator(device='cuda')\n",
        "Question": "How to use torch.Generator, give an example?",
        "Id": 654,
        "source": "https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator",
        "context": " "
    },
    {
        "Answer": ">>> g_cpu = torch.Generator()\n>>> g_cpu.device\ndevice(type='cpu')\n",
        "Question": "How  Gets the current device of the generator., give an example?",
        "Id": 655,
        "source": "https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator",
        "context": " Gets the current device of the generator."
    },
    {
        "Answer": ">>> g_cpu = torch.Generator()\n>>> g_cpu.get_state()\n",
        "Question": "How to use torch.Generator.get_state, give an example?",
        "Id": 656,
        "source": "https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator",
        "context": " "
    },
    {
        "Answer": ">>> g_cpu = torch.Generator()\n>>> g_cpu.initial_seed()\n2147483647\n",
        "Question": "How to use torch.Generator.initial_seed, give an example?",
        "Id": 657,
        "source": "https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator",
        "context": " "
    },
    {
        "Answer": ">>> g_cpu = torch.Generator()\n>>> g_cpu.manual_seed(2147483647)\n",
        "Question": "How to use torch.Generator.manual_seed, give an example?",
        "Id": 658,
        "source": "https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator",
        "context": " "
    },
    {
        "Answer": ">>> g_cpu = torch.Generator()\n>>> g_cpu.seed()\n1516516984916\n",
        "Question": "How to use torch.Generator.seed, give an example?",
        "Id": 659,
        "source": "https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator",
        "context": " "
    },
    {
        "Answer": ">>> g_cpu = torch.Generator()\n>>> g_cpu_other = torch.Generator()\n>>> g_cpu.set_state(g_cpu_other.get_state())\n",
        "Question": "How to use torch.Generator.set_state, give an example?",
        "Id": 660,
        "source": "https://pytorch.org/docs/stable/generated/torch.Generator.html#torch.Generator",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([[180.0, -180.0], [360.0, -360.0], [90.0, -90.0]])\n>>> torch.deg2rad(a)\ntensor([[ 3.1416, -3.1416],\n        [ 6.2832, -6.2832],\n        [ 1.5708, -1.5708]])\n",
        "Question": "How to use torch.deg2rad, give an example?",
        "Id": 661,
        "source": "https://pytorch.org/docs/stable/generated/torch.deg2rad.html#torch.deg2rad",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([[-0.8166, -1.3802, -0.3560]])\n>>> torch.var_mean(a, unbiased=False)\n(tensor(0.1754), tensor(-0.8509))\n",
        "Question": "How to use torch.var_mean, give an example?",
        "Id": 662,
        "source": "https://pytorch.org/docs/stable/generated/torch.var_mean.html#torch.var_mean",
        "context": " IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction."
    },
    {
        "Answer": ">>> real = torch.tensor([1, 2], dtype=torch.float32)\n>>> imag = torch.tensor([3, 4], dtype=torch.float32)\n>>> z = torch.complex(real, imag)\n>>> z\ntensor([(1.+3.j), (2.+4.j)])\n>>> z.dtype\ntorch.complex64\n",
        "Question": "How to use torch.complex, give an example?",
        "Id": 663,
        "source": "https://pytorch.org/docs/stable/generated/torch.complex.html#torch.complex",
        "context": " "
    },
    {
        "Answer": ">>> A = torch.randn(2, 2).triu()\n>>> A\ntensor([[ 1.1527, -1.0753],\n        [ 0.0000,  0.7986]])\n>>> b = torch.randn(2, 3)\n>>> b\ntensor([[-0.0210,  2.3513, -1.5492],\n        [ 1.5429,  0.7403, -1.0243]])\n>>> torch.triangular_solve(b, A)\ntorch.return_types.triangular_solve(\nsolution=tensor([[ 1.7841,  2.9046, -2.5405],\n        [ 1.9320,  0.9270, -1.2826]]),\ncloned_coefficient=tensor([[ 1.1527, -1.0753],\n        [ 0.0000,  0.7986]]))\n",
        "Question": "How to use torch.triangular_solve, give an example?",
        "Id": 664,
        "source": "https://pytorch.org/docs/stable/generated/torch.triangular_solve.html#torch.triangular_solve",
        "context": " Supports input of float, double, cfloat and cdouble data types."
    },
    {
        "Answer": ">>> torch.ones(2, 3)\ntensor([[ 1.,  1.,  1.],\n        [ 1.,  1.,  1.]])\n\n>>> torch.ones(5)\ntensor([ 1.,  1.,  1.,  1.,  1.])\n",
        "Question": "How to use torch.ones, give an example?",
        "Id": 665,
        "source": "https://pytorch.org/docs/stable/generated/torch.ones.html#torch.ones",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.randn(())\n>>> x\ntensor(0.1995)\n>>> torch.t(x)\ntensor(0.1995)\n>>> x = torch.randn(3)\n>>> x\ntensor([ 2.4320, -0.4608,  0.7702])\n>>> torch.t(x)\ntensor([ 2.4320, -0.4608,  0.7702])\n>>> x = torch.randn(2, 3)\n>>> x\ntensor([[ 0.4875,  0.9158, -0.5872],\n        [ 0.3938, -0.6929,  0.6932]])\n>>> torch.t(x)\ntensor([[ 0.4875,  0.3938],\n        [ 0.9158, -0.6929],\n        [-0.5872,  0.6932]])\n",
        "Question": "How to use torch.t, give an example?",
        "Id": 666,
        "source": "https://pytorch.org/docs/stable/generated/torch.t.html#torch.t",
        "context": " 0-D and 1-D tensors are returned as is. When input is a 2-D tensor this\nis equivalent totranspose(input,0,1)."
    },
    {
        "Answer": ">>> a = torch.arange(-0.5, 1, 0.5)\n>>> a\ntensor([-0.5000,  0.0000,  0.5000])\n>>> torch.special.entr(a)\ntensor([  -inf, 0.0000, 0.3466])\n",
        "Question": "How  , give an example?",
        "Id": 667,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erf(torch.tensor([0, -1., 10.]))\ntensor([ 0.0000, -0.8427,  1.0000])\n",
        "Question": "How  , give an example?",
        "Id": 668,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n",
        "Question": "How  , give an example?",
        "Id": 669,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n",
        "Question": "How  , give an example?",
        "Id": 670,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(4)\n>>> t\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n>>> torch.special.expit(t)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
        "Question": "How  , give an example?",
        "Id": 671,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n",
        "Question": "How  , give an example?",
        "Id": 672,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\ntensor([ 1.,  2.,  8., 16.])\n",
        "Question": "How  , give an example?",
        "Id": 673,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.special.gammaln(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How  , give an example?",
        "Id": 674,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.i0e(torch.arange(5, dtype=torch.float32))\ntensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])\n",
        "Question": "How  , give an example?",
        "Id": 675,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n>>> torch.special.logit(a, eps=1e-6)\ntensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
        "Question": "How  , give an example?",
        "Id": 676,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.special.xlog1py(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.special.xlog1py(x, y)\ntensor([1.3863, 2.1972, 2.0794])\n>>> torch.special.xlog1py(x, 4)\ntensor([1.6094, 3.2189, 4.8283])\n>>> torch.special.xlog1py(2, y)\ntensor([2.7726, 2.1972, 1.3863])\n",
        "Question": "How  Similar to SciPy\u2019sscipy.special.xlog1py., give an example?",
        "Id": 677,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expm1",
        "context": " Similar to SciPy\u2019sscipy.special.xlog1py."
    },
    {
        "Answer": ">>> torch.gt(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[False, True], [False, False]])\n",
        "Question": "How to use torch.gt, give an example?",
        "Id": 678,
        "source": "https://pytorch.org/docs/stable/generated/torch.gt.html#torch.gt",
        "context": " The second argument can be a number or a tensor whose shape isbroadcastablewith the first argument."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.9920,  0.6077,  0.9734, -1.0362])\n>>> torch.round(a)\ntensor([ 1.,  1.,  1., -1.])\n",
        "Question": "How to use torch.round, give an example?",
        "Id": 679,
        "source": "https://pytorch.org/docs/stable/generated/torch.round.html#torch.round",
        "context": " "
    },
    {
        "Answer": "- Nathan Halko, Per-Gunnar Martinsson, and Joel Tropp, Finding\n  structure with randomness: probabilistic algorithms for\n  constructing approximate matrix decompositions,\n  arXiv:0909.4061 [math.NA; math.PR], 2009 (available at\n  `arXiv <http://arxiv.org/abs/0909.4061>`_).\n",
        "Question": "How to use torch.pca_lowrank, give an example?",
        "Id": 680,
        "source": "https://pytorch.org/docs/stable/generated/torch.pca_lowrank.html#torch.pca_lowrank",
        "context": " This function returns a namedtuple(U,S,V)which is the\nnearly optimal approximation of a singular value decomposition of\na centered matrixAAAsuch thatA=Udiag(S)VTA = U diag(S) V^TA=Udiag(S)VT.References:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n>>> torch.narrow(x, 0, 0, 2)\ntensor([[ 1,  2,  3],\n        [ 4,  5,  6]])\n>>> torch.narrow(x, 1, 1, 2)\ntensor([[ 2,  3],\n        [ 5,  6],\n        [ 8,  9]])\n",
        "Question": "How to use torch.narrow, give an example?",
        "Id": 681,
        "source": "https://pytorch.org/docs/stable/generated/torch.narrow.html#torch.narrow",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(1, 3)\n>>> a\ntensor([[ 0.6750,  1.0857,  1.7197]])\n>>> torch.min(a)\ntensor(0.6750)\n",
        "Question": "How to use torch.min, give an example?",
        "Id": 682,
        "source": "https://pytorch.org/docs/stable/generated/torch.min.html#torch.min",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[-0.6248,  1.1334, -1.1899, -0.2803],\n        [-1.4644, -0.2635, -0.3651,  0.6134],\n        [ 0.2457,  0.0384,  1.0128,  0.7015],\n        [-0.1153,  2.9849,  2.1458,  0.5788]])\n>>> torch.min(a, 1)\ntorch.return_types.min(values=tensor([-1.1899, -1.4644,  0.0384, -0.1153]), indices=tensor([2, 0, 1, 0]))\n",
        "Question": "How  IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensors having 1 fewer dimension thaninput., give an example?",
        "Id": 683,
        "source": "https://pytorch.org/docs/stable/generated/torch.min.html#torch.min",
        "context": " IfkeepdimisTrue, the output tensors are of the same size asinputexcept in the dimensiondimwhere they are of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensors having 1 fewer dimension thaninput."
    },
    {
        "Answer": ">>> weights = torch.tensor([0, 10, 3, 0], dtype=torch.float) # create a tensor of weights\n>>> torch.multinomial(weights, 2)\ntensor([1, 2])\n>>> torch.multinomial(weights, 4) # ERROR!\nRuntimeError: invalid argument 2: invalid multinomial distribution (with replacement=False,\nnot enough non-negative category to sample) at ../aten/src/TH/generic/THTensorRandom.cpp:320\n>>> torch.multinomial(weights, 4, replacement=True)\ntensor([ 2,  1,  1,  1])\n",
        "Question": "How to use torch.multinomial, give an example?",
        "Id": 684,
        "source": "https://pytorch.org/docs/stable/generated/torch.multinomial.html#torch.multinomial",
        "context": " If not, they are drawn without replacement, which means that when a\nsample index is drawn for a row, it cannot be drawn again for that row."
    },
    {
        "Answer": "import torch\nfrom torch import nn\n\nclass MyLinear(nn.Module):\n  def __init__(self, in_features, out_features):\n    super().__init__()\n    self.weight = nn.Parameter(torch.randn(in_features, out_features))\n    self.bias = nn.Parameter(torch.randn(out_features))\n\n  def forward(self, input):\n    return (input @ self.weight) + self.bias\n",
        "Question": "How to use To get started, let\u2019s look at a simpler, custom version of PyTorch\u2019sLinearmodule.\nThis module applies an affine transformation to its input., give an example?",
        "Id": 685,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " To get started, let\u2019s look at a simpler, custom version of PyTorch\u2019sLinearmodule.\nThis module applies an affine transformation to its input."
    },
    {
        "Answer": "m = MyLinear(4, 3)\nsample_input = torch.randn(4)\nm(sample_input)\n: tensor([-0.3037, -1.0413, -4.2057], grad_fn=<AddBackward0>)\n",
        "Question": "How to use This simple module has the following fundamental characteristics of modules:This simple module demonstrates how modules package state and computation together. Instances of this module can be\nconstructed and called:, give an example?",
        "Id": 686,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " This simple module has the following fundamental characteristics of modules:This simple module demonstrates how modules package state and computation together. Instances of this module can be\nconstructed and called:"
    },
    {
        "Answer": "for parameter in m.named_parameters():\n  print(parameter)\n: ('weight', Parameter containing:\ntensor([[ 1.0597,  1.1796,  0.8247],\n        [-0.5080, -1.2635, -1.1045],\n        [ 0.0593,  0.2469, -1.4299],\n        [-0.4926, -0.5457,  0.4793]], requires_grad=True))\n('bias', Parameter containing:\ntensor([ 0.3634,  0.2015, -0.8525], requires_grad=True))\n",
        "Question": "How to use Note that the module itself is callable, and that calling it invokes itsforward()function.\nThis name is in reference to the concepts of \u201cforward pass\u201d and \u201cbackward pass\u201d, which apply to each module.\nThe \u201cforward pass\u201d is responsible for applying the computation represented by the module\nto the given input(s) (as shown in the above snippet). The \u201cbackward pass\u201d computes gradients of\nmodule outputs with respect to its inputs, which can be used for \u201ctraining\u201d parameters through gradient\ndescent methods. PyTorch\u2019s autograd system automatically takes care of this backward pass computation, so it\nis not required to manually implement abackward()function for each module. The process of training\nmodule parameters through successive forward / backward passes is covered in detail inNeural Network Training with Modules.The full set of parameters registered by the module can be iterated through via a call toparameters()ornamed_parameters(),\nwhere the latter includes each parameter\u2019s name:, give an example?",
        "Id": 687,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " Note that the module itself is callable, and that calling it invokes itsforward()function.\nThis name is in reference to the concepts of \u201cforward pass\u201d and \u201cbackward pass\u201d, which apply to each module.\nThe \u201cforward pass\u201d is responsible for applying the computation represented by the module\nto the given input(s) (as shown in the above snippet). The \u201cbackward pass\u201d computes gradients of\nmodule outputs with respect to its inputs, which can be used for \u201ctraining\u201d parameters through gradient\ndescent methods. PyTorch\u2019s autograd system automatically takes care of this backward pass computation, so it\nis not required to manually implement abackward()function for each module. The process of training\nmodule parameters through successive forward / backward passes is covered in detail inNeural Network Training with Modules.The full set of parameters registered by the module can be iterated through via a call toparameters()ornamed_parameters(),\nwhere the latter includes each parameter\u2019s name:"
    },
    {
        "Answer": "net = nn.Sequential(\n  MyLinear(4, 3),\n  nn.ReLU(),\n  MyLinear(3, 1)\n)\n\nsample_input = torch.randn(4)\nnet(sample_input)\n: tensor([-0.6749], grad_fn=<AddBackward0>)\n",
        "Question": "How to use Modules can contain other modules, making them useful building blocks for developing more elaborate functionality.\nThe simplest way to do this is using theSequentialmodule. It allows us to chain together\nmultiple modules:, give an example?",
        "Id": 688,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " Modules can contain other modules, making them useful building blocks for developing more elaborate functionality.\nThe simplest way to do this is using theSequentialmodule. It allows us to chain together\nmultiple modules:"
    },
    {
        "Answer": "import torch.nn.functional as F\n\nclass Net(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.l0 = MyLinear(4, 3)\n    self.l1 = MyLinear(3, 1)\n  def forward(self, x):\n    x = self.l0(x)\n    x = F.relu(x)\n    x = self.l1(x)\n    return x\n",
        "Question": "How to use In general, it is recommended to define a custom module for anything beyond the simplest use cases, as this gives\nfull flexibility on how submodules are used for a module\u2019s computation.For example, here\u2019s a simple neural network implemented as a custom module:, give an example?",
        "Id": 689,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " In general, it is recommended to define a custom module for anything beyond the simplest use cases, as this gives\nfull flexibility on how submodules are used for a module\u2019s computation.For example, here\u2019s a simple neural network implemented as a custom module:"
    },
    {
        "Answer": "net = Net()\nfor child in net.named_children():\n  print(child)\n: ('l0', MyLinear())\n('l1', MyLinear())\n",
        "Question": "How to use For example, here\u2019s a simple neural network implemented as a custom module:This module is composed of two \u201cchildren\u201d or \u201csubmodules\u201d (l0andl1) that define the layers of\nthe neural network and are utilized for computation within the module\u2019sforward()method. Immediate\nchildren of a module can be iterated through via a call tochildren()ornamed_children():, give an example?",
        "Id": 690,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " For example, here\u2019s a simple neural network implemented as a custom module:This module is composed of two \u201cchildren\u201d or \u201csubmodules\u201d (l0andl1) that define the layers of\nthe neural network and are utilized for computation within the module\u2019sforward()method. Immediate\nchildren of a module can be iterated through via a call tochildren()ornamed_children():"
    },
    {
        "Answer": "class BigNet(nn.Module):\n  def __init__(self):\n    super().__init__()\n    self.l1 = MyLinear(5, 4)\n    self.net = Net()\n  def forward(self, x):\n    return self.net(self.l1(x))\n\nbig_net = BigNet()\nfor module in big_net.named_modules():\n  print(module)\n: ('', BigNet(\n  (l1): MyLinear()\n  (net): Net(\n    (l0): MyLinear()\n    (l1): MyLinear()\n  )\n))\n('l1', MyLinear())\n('net', Net(\n  (l0): MyLinear()\n  (l1): MyLinear()\n))\n('net.l0', MyLinear())\n('net.l1', MyLinear())\n",
        "Question": "How to use This module is composed of two \u201cchildren\u201d or \u201csubmodules\u201d (l0andl1) that define the layers of\nthe neural network and are utilized for computation within the module\u2019sforward()method. Immediate\nchildren of a module can be iterated through via a call tochildren()ornamed_children():To go deeper than just the immediate children,modules()andnamed_modules()recursivelyiterate through a module and its child modules:, give an example?",
        "Id": 691,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " This module is composed of two \u201cchildren\u201d or \u201csubmodules\u201d (l0andl1) that define the layers of\nthe neural network and are utilized for computation within the module\u2019sforward()method. Immediate\nchildren of a module can be iterated through via a call tochildren()ornamed_children():To go deeper than just the immediate children,modules()andnamed_modules()recursivelyiterate through a module and its child modules:"
    },
    {
        "Answer": "class DynamicNet(nn.Module):\n  def __init__(self, num_layers):\n    super().__init__()\n    self.linears = nn.ModuleList(\n      [MyLinear(4, 4) for _ in range(num_layers)])\n    self.activations = nn.ModuleDict({\n      'relu': nn.ReLU(),\n      'lrelu': nn.LeakyReLU()\n    })\n    self.final = MyLinear(4, 1)\n  def forward(self, x, act):\n    for linear in self.linears:\n      x = linear(x)\n    x = self.activations[act](x)\n    x = self.final(x)\n    return x\n\ndynamic_net = DynamicNet(3)\nsample_input = torch.randn(4)\noutput = dynamic_net(sample_input, 'relu')\n",
        "Question": "How to use To go deeper than just the immediate children,modules()andnamed_modules()recursivelyiterate through a module and its child modules:Sometimes, it\u2019s necessary for a module to dynamically define submodules.\nTheModuleListandModuleDictmodules are useful here; they\nregister submodules from a list or dict:, give an example?",
        "Id": 692,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " To go deeper than just the immediate children,modules()andnamed_modules()recursivelyiterate through a module and its child modules:Sometimes, it\u2019s necessary for a module to dynamically define submodules.\nTheModuleListandModuleDictmodules are useful here; they\nregister submodules from a list or dict:"
    },
    {
        "Answer": "for parameter in dynamic_net.named_parameters():\n  print(parameter)\n: ('linears.0.weight', Parameter containing:\ntensor([[-1.2051,  0.7601,  1.1065,  0.1963],\n        [ 3.0592,  0.4354,  1.6598,  0.9828],\n        [-0.4446,  0.4628,  0.8774,  1.6848],\n        [-0.1222,  1.5458,  1.1729,  1.4647]], requires_grad=True))\n('linears.0.bias', Parameter containing:\ntensor([ 1.5310,  1.0609, -2.0940,  1.1266], requires_grad=True))\n('linears.1.weight', Parameter containing:\ntensor([[ 2.1113, -0.0623, -1.0806,  0.3508],\n        [-0.0550,  1.5317,  1.1064, -0.5562],\n        [-0.4028, -0.6942,  1.5793, -1.0140],\n        [-0.0329,  0.1160, -1.7183, -1.0434]], requires_grad=True))\n('linears.1.bias', Parameter containing:\ntensor([ 0.0361, -0.9768, -0.3889,  1.1613], requires_grad=True))\n('linears.2.weight', Parameter containing:\ntensor([[-2.6340, -0.3887, -0.9979,  0.0767],\n        [-0.3526,  0.8756, -1.5847, -0.6016],\n        [-0.3269, -0.1608,  0.2897, -2.0829],\n        [ 2.6338,  0.9239,  0.6943, -1.5034]], requires_grad=True))\n('linears.2.bias', Parameter containing:\ntensor([ 1.0268,  0.4489, -0.9403,  0.1571], requires_grad=True))\n('final.weight', Parameter containing:\ntensor([[ 0.2509], [-0.5052], [ 0.3088], [-1.4951]], requires_grad=True))\n('final.bias', Parameter containing:\ntensor([0.3381], requires_grad=True))\n",
        "Question": "How to use Sometimes, it\u2019s necessary for a module to dynamically define submodules.\nTheModuleListandModuleDictmodules are useful here; they\nregister submodules from a list or dict:For any given module, its parameters consist of its direct parameters as well as the parameters of all submodules.\nThis means that calls toparameters()andnamed_parameters()will\nrecursively include child parameters, allowing for convenient optimization of all parameters within the network:, give an example?",
        "Id": 693,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " Sometimes, it\u2019s necessary for a module to dynamically define submodules.\nTheModuleListandModuleDictmodules are useful here; they\nregister submodules from a list or dict:For any given module, its parameters consist of its direct parameters as well as the parameters of all submodules.\nThis means that calls toparameters()andnamed_parameters()will\nrecursively include child parameters, allowing for convenient optimization of all parameters within the network:"
    },
    {
        "Answer": "# Move all parameters to a CUDA device\ndynamic_net.to(device='cuda')\n\n# Change precision of all parameters\ndynamic_net.to(dtype=torch.float64)\n\ndynamic_net(torch.randn(5, device='cuda', dtype=torch.float64))\n: tensor([6.5166], device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
        "Question": "How to use For any given module, its parameters consist of its direct parameters as well as the parameters of all submodules.\nThis means that calls toparameters()andnamed_parameters()will\nrecursively include child parameters, allowing for convenient optimization of all parameters within the network:It\u2019s also easy to move all parameters to a different device or change their precision usingto():, give an example?",
        "Id": 694,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " For any given module, its parameters consist of its direct parameters as well as the parameters of all submodules.\nThis means that calls toparameters()andnamed_parameters()will\nrecursively include child parameters, allowing for convenient optimization of all parameters within the network:It\u2019s also easy to move all parameters to a different device or change their precision usingto():"
    },
    {
        "Answer": "# Create the network (from previous section) and optimizer\nnet = Net()\noptimizer = torch.optim.SGD(net.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)\n\n# Run a sample training loop that \"teaches\" the network\n# to output the constant zero function\nfor _ in range(10000):\n  input = torch.randn(4)\n  output = net(input)\n  loss = torch.abs(output)\n  net.zero_grad()\n  loss.backward()\n  optimizer.step()\n",
        "Question": "How to use Once a network is built, it has to be trained, and its parameters can be easily optimized with one of PyTorch\u2019s\nOptimizers fromtorch.optim:, give an example?",
        "Id": 695,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " Once a network is built, it has to be trained, and its parameters can be easily optimized with one of PyTorch\u2019s\nOptimizers fromtorch.optim:"
    },
    {
        "Answer": "print(net.l1.weight)\n: Parameter containing:\ntensor([[-0.0013],\n        [ 0.0030],\n        [-0.0008]], requires_grad=True)\n",
        "Question": "How to use In this simplified example, the network learns to simply output zero, as any non-zero output is \u201cpenalized\u201d according\nto its absolute value by employingtorch.abs()as a loss function. While this is not a very interesting task, the\nkey parts of training are present:After the above snippet has been run, note that the network\u2019s parameters have changed. In particular, examining the\nvalue ofl1\u2019sweightparameter shows that its values are now much closer to 0 (as may be expected):, give an example?",
        "Id": 696,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " In this simplified example, the network learns to simply output zero, as any non-zero output is \u201cpenalized\u201d according\nto its absolute value by employingtorch.abs()as a loss function. While this is not a very interesting task, the\nkey parts of training are present:After the above snippet has been run, note that the network\u2019s parameters have changed. In particular, examining the\nvalue ofl1\u2019sweightparameter shows that its values are now much closer to 0 (as may be expected):"
    },
    {
        "Answer": "# Save the module\ntorch.save(net.state_dict(), 'net.pt')\n\n...\n\n# Load the module later on\nnew_net = Net()\nnew_net.load_state_dict(torch.load('net.pt'))\n: <All keys matched successfully>\n",
        "Question": "How to use In the previous section, we demonstrated training a module\u2019s \u201cparameters\u201d, or learnable aspects of computation.\nNow, if we want to save the trained model to disk, we can do so by saving itsstate_dict(i.e. \u201cstate dictionary\u201d):, give an example?",
        "Id": 697,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " In the previous section, we demonstrated training a module\u2019s \u201cparameters\u201d, or learnable aspects of computation.\nNow, if we want to save the trained model to disk, we can do so by saving itsstate_dict(i.e. \u201cstate dictionary\u201d):"
    },
    {
        "Answer": "class RunningMean(nn.Module):\n  def __init__(self, num_features, momentum=0.9):\n    super().__init__()\n    self.momentum = momentum\n    self.register_buffer('mean', torch.zeros(num_features))\n  def forward(self, x):\n    self.mean = self.momentum * self.mean + (1.0 - self.momentum) * x\n    return self.mean\n",
        "Question": "How to use A module\u2019sstate_dictcontains state that affects its computation. This includes, but is not limited to, the\nmodule\u2019s parameters. For some modules, it may be useful to have state beyond parameters that affects module\ncomputation but is not learnable. For such cases, PyTorch provides the concept of \u201cbuffers\u201d, both \u201cpersistent\u201d\nand \u201cnon-persistent\u201d. Following is an overview of the various types of state a module can have:As a motivating example for the use of buffers, consider a simple module that maintains a running mean. We want\nthe current value of the running mean to be considered part of the module\u2019sstate_dictso that it will be\nrestored when loading a serialized form of the module, but we don\u2019t want it to be learnable.\nThis snippet shows how to useregister_buffer()to accomplish this:, give an example?",
        "Id": 698,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " A module\u2019sstate_dictcontains state that affects its computation. This includes, but is not limited to, the\nmodule\u2019s parameters. For some modules, it may be useful to have state beyond parameters that affects module\ncomputation but is not learnable. For such cases, PyTorch provides the concept of \u201cbuffers\u201d, both \u201cpersistent\u201d\nand \u201cnon-persistent\u201d. Following is an overview of the various types of state a module can have:As a motivating example for the use of buffers, consider a simple module that maintains a running mean. We want\nthe current value of the running mean to be considered part of the module\u2019sstate_dictso that it will be\nrestored when loading a serialized form of the module, but we don\u2019t want it to be learnable.\nThis snippet shows how to useregister_buffer()to accomplish this:"
    },
    {
        "Answer": "m = RunningMean(4)\nfor _ in range(10):\n  input = torch.randn(4)\n  m(input)\n\nprint(m.state_dict())\n: OrderedDict([('mean', tensor([ 0.1041, -0.1113, -0.0647,  0.1515]))]))\n\n# Serialized form will contain the 'mean' tensor\ntorch.save(m.state_dict(), 'mean.pt')\n\nm_loaded = RunningMean(4)\nm_loaded.load_state_dict(torch.load('mean.pt'))\nassert(torch.all(m.mean == m_loaded.mean))\n",
        "Question": "How to use As a motivating example for the use of buffers, consider a simple module that maintains a running mean. We want\nthe current value of the running mean to be considered part of the module\u2019sstate_dictso that it will be\nrestored when loading a serialized form of the module, but we don\u2019t want it to be learnable.\nThis snippet shows how to useregister_buffer()to accomplish this:Now, the current value of the running mean is considered part of the module\u2019sstate_dictand will be properly restored when loading the module from disk:, give an example?",
        "Id": 699,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " As a motivating example for the use of buffers, consider a simple module that maintains a running mean. We want\nthe current value of the running mean to be considered part of the module\u2019sstate_dictso that it will be\nrestored when loading a serialized form of the module, but we don\u2019t want it to be learnable.\nThis snippet shows how to useregister_buffer()to accomplish this:Now, the current value of the running mean is considered part of the module\u2019sstate_dictand will be properly restored when loading the module from disk:"
    },
    {
        "Answer": "self.register_buffer('unserialized_thing', torch.randn(5), persistent=False)\n",
        "Question": "How to use Now, the current value of the running mean is considered part of the module\u2019sstate_dictand will be properly restored when loading the module from disk:As mentioned previously, buffers can be left out of the module\u2019sstate_dictby marking them as non-persistent:, give an example?",
        "Id": 700,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " Now, the current value of the running mean is considered part of the module\u2019sstate_dictand will be properly restored when loading the module from disk:As mentioned previously, buffers can be left out of the module\u2019sstate_dictby marking them as non-persistent:"
    },
    {
        "Answer": "# Moves all module parameters and buffers to the specified device / dtype\nm.to(device='cuda', dtype=torch.float64)\n",
        "Question": "How to use As mentioned previously, buffers can be left out of the module\u2019sstate_dictby marking them as non-persistent:Both persistent and non-persistent buffers are affected by model-wide device / dtype changes applied withto():, give an example?",
        "Id": 701,
        "source": "https://pytorch.org/docs/stable/notes/modules.html",
        "context": " As mentioned previously, buffers can be left out of the module\u2019sstate_dictby marking them as non-persistent:Both persistent and non-persistent buffers are affected by model-wide device / dtype changes applied withto():"
    },
    {
        "Answer": ">>> torch.tensor([[1., -1.], [1., -1.]])\ntensor([[ 1.0000, -1.0000],\n        [ 1.0000, -1.0000]])\n>>> torch.tensor(np.array([[1, 2, 3], [4, 5, 6]]))\ntensor([[ 1,  2,  3],\n        [ 4,  5,  6]])\n",
        "Question": "How  A tensor can be constructed from a Pythonlistor sequence using thetorch.tensor()constructor:, give an example?",
        "Id": 702,
        "source": "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
        "context": " A tensor can be constructed from a Pythonlistor sequence using thetorch.tensor()constructor:"
    },
    {
        "Answer": ">>> torch.zeros([2, 4], dtype=torch.int32)\ntensor([[ 0,  0,  0,  0],\n        [ 0,  0,  0,  0]], dtype=torch.int32)\n>>> cuda0 = torch.device('cuda:0')\n>>> torch.ones([2, 4], dtype=torch.float64, device=cuda0)\ntensor([[ 1.0000,  1.0000,  1.0000,  1.0000],\n        [ 1.0000,  1.0000,  1.0000,  1.0000]], dtype=torch.float64, device='cuda:0')\n",
        "Question": "How  A tensor of specific data type can be constructed by passing atorch.dtypeand/or atorch.deviceto a\nconstructor or tensor creation op:, give an example?",
        "Id": 703,
        "source": "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
        "context": " A tensor of specific data type can be constructed by passing atorch.dtypeand/or atorch.deviceto a\nconstructor or tensor creation op:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n>>> print(x[1][2])\ntensor(6)\n>>> x[0][1] = 8\n>>> print(x)\ntensor([[ 1,  8,  3],\n        [ 4,  5,  6]])\n",
        "Question": "How  For more information about building Tensors, seeCreation OpsThe contents of a tensor can be accessed and modified using Python\u2019s indexing\nand slicing notation:, give an example?",
        "Id": 704,
        "source": "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
        "context": " For more information about building Tensors, seeCreation OpsThe contents of a tensor can be accessed and modified using Python\u2019s indexing\nand slicing notation:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1]])\n>>> x\ntensor([[ 1]])\n>>> x.item()\n1\n>>> x = torch.tensor(2.5)\n>>> x\ntensor(2.5000)\n>>> x.item()\n2.5\n",
        "Question": "How  The contents of a tensor can be accessed and modified using Python\u2019s indexing\nand slicing notation:Usetorch.Tensor.item()to get a Python number from a tensor containing a\nsingle value:, give an example?",
        "Id": 705,
        "source": "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
        "context": " The contents of a tensor can be accessed and modified using Python\u2019s indexing\nand slicing notation:Usetorch.Tensor.item()to get a Python number from a tensor containing a\nsingle value:"
    },
    {
        "Answer": ">>> x = torch.tensor([[1., -1.], [1., 1.]], requires_grad=True)\n>>> out = x.pow(2).sum()\n>>> out.backward()\n>>> x.grad\ntensor([[ 2.0000, -2.0000],\n        [ 2.0000,  2.0000]])\n",
        "Question": "How  For more information about indexing, seeIndexing, Slicing, Joining, Mutating OpsA tensor can be created withrequires_grad=Trueso thattorch.autogradrecords operations on them for automatic differentiation., give an example?",
        "Id": 706,
        "source": "https://pytorch.org/docs/stable/tensors.html#torch.Tensor",
        "context": " For more information about indexing, seeIndexing, Slicing, Joining, Mutating OpsA tensor can be created withrequires_grad=Trueso thattorch.autogradrecords operations on them for automatic differentiation."
    },
    {
        "Answer": ">>> x = torch.arange(8).view(2, 2, 2)\n>>> x\ntensor([[[ 0,  1],\n         [ 2,  3]],\n\n        [[ 4,  5],\n         [ 6,  7]]])\n>>> torch.flip(x, [0, 1])\ntensor([[[ 6,  7],\n         [ 4,  5]],\n\n        [[ 2,  3],\n         [ 0,  1]]])\n",
        "Question": "How to use torch.flip, give an example?",
        "Id": 707,
        "source": "https://pytorch.org/docs/stable/generated/torch.flip.html#torch.flip",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(-0.5, 1, 0.5)\n>>> a\ntensor([-0.5000,  0.0000,  0.5000])\n>>> torch.special.entr(a)\ntensor([  -inf, 0.0000, 0.3466])\n",
        "Question": "How  , give an example?",
        "Id": 708,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erf(torch.tensor([0, -1., 10.]))\ntensor([ 0.0000, -0.8427,  1.0000])\n",
        "Question": "How  , give an example?",
        "Id": 709,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n",
        "Question": "How  , give an example?",
        "Id": 710,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n",
        "Question": "How  , give an example?",
        "Id": 711,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(4)\n>>> t\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n>>> torch.special.expit(t)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
        "Question": "How  , give an example?",
        "Id": 712,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n",
        "Question": "How  , give an example?",
        "Id": 713,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\ntensor([ 1.,  2.,  8., 16.])\n",
        "Question": "How  , give an example?",
        "Id": 714,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.special.gammaln(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How  , give an example?",
        "Id": 715,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.i0e(torch.arange(5, dtype=torch.float32))\ntensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])\n",
        "Question": "How  , give an example?",
        "Id": 716,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n>>> torch.special.logit(a, eps=1e-6)\ntensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
        "Question": "How  , give an example?",
        "Id": 717,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.special.xlog1py(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.special.xlog1py(x, y)\ntensor([1.3863, 2.1972, 2.0794])\n>>> torch.special.xlog1py(x, 4)\ntensor([1.6094, 3.2189, 4.8283])\n>>> torch.special.xlog1py(2, y)\ntensor([2.7726, 2.1972, 1.3863])\n",
        "Question": "How  Similar to SciPy\u2019sscipy.special.xlog1py., give an example?",
        "Id": 718,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.erfc",
        "context": " Similar to SciPy\u2019sscipy.special.xlog1py."
    },
    {
        "Answer": "U, S, Vh = torch.linalg.svd(A, full_matrices=not some)\nV = Vh.transpose(-2, -1).conj()\n",
        "Question": "How to use torch.svd, give an example?",
        "Id": 719,
        "source": "https://pytorch.org/docs/stable/generated/torch.svd.html#torch.svd",
        "context": " torch.svd()is deprecated in favor oftorch.linalg.svd()and will be removed in a future PyTorch release.U,S,V=torch.svd(A,some=some,compute_uv=True)(default) should be replaced with"
    },
    {
        "Answer": "S = torch.svdvals(A)\n",
        "Question": "How  U,S,V=torch.svd(A,some=some,compute_uv=True)(default) should be replaced with_,S,_=torch.svd(A,some=some,compute_uv=False)should be replaced with, give an example?",
        "Id": 720,
        "source": "https://pytorch.org/docs/stable/generated/torch.svd.html#torch.svd",
        "context": " U,S,V=torch.svd(A,some=some,compute_uv=True)(default) should be replaced with_,S,_=torch.svd(A,some=some,compute_uv=False)should be replaced with"
    },
    {
        "Answer": ">>> a = torch.randn(5, 3)\n>>> a\ntensor([[ 0.2364, -0.7752,  0.6372],\n        [ 1.7201,  0.7394, -0.0504],\n        [-0.3371, -1.0584,  0.5296],\n        [ 0.3550, -0.4022,  1.5569],\n        [ 0.2445, -0.0158,  1.1414]])\n>>> u, s, v = torch.svd(a)\n>>> u\ntensor([[ 0.4027,  0.0287,  0.5434],\n        [-0.1946,  0.8833,  0.3679],\n        [ 0.4296, -0.2890,  0.5261],\n        [ 0.6604,  0.2717, -0.2618],\n        [ 0.4234,  0.2481, -0.4733]])\n>>> s\ntensor([2.3289, 2.0315, 0.7806])\n>>> v\ntensor([[-0.0199,  0.8766,  0.4809],\n        [-0.5080,  0.4054, -0.7600],\n        [ 0.8611,  0.2594, -0.4373]])\n>>> torch.dist(a, torch.mm(torch.mm(u, torch.diag(s)), v.t()))\ntensor(8.6531e-07)\n>>> a_big = torch.randn(7, 5, 3)\n>>> u, s, v = torch.svd(a_big)\n>>> torch.dist(a_big, torch.matmul(torch.matmul(u, torch.diag_embed(s)), v.transpose(-2, -1)))\ntensor(2.6503e-06)\n",
        "Question": "How  Supportsinputof float, double, cfloat and cdouble data types.\nThe dtypes ofUandVare the same asinput\u2019s.Swill\nalways be real-valued, even ifinputis complex., give an example?",
        "Id": 721,
        "source": "https://pytorch.org/docs/stable/generated/torch.svd.html#torch.svd",
        "context": " Supportsinputof float, double, cfloat and cdouble data types.\nThe dtypes ofUandVare the same asinput\u2019s.Swill\nalways be real-valued, even ifinputis complex."
    },
    {
        "Answer": ">>> x=torch.randn(4, dtype=torch.cfloat)\n>>> x\ntensor([(0.3100+0.3553j), (-0.5445-0.7896j), (-1.6492-0.0633j), (-0.0638-0.8119j)])\n>>> x.real\ntensor([ 0.3100, -0.5445, -1.6492, -0.0638])\n",
        "Question": "How to use torch.real, give an example?",
        "Id": 722,
        "source": "https://pytorch.org/docs/stable/generated/torch.real.html#torch.real",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.xlogy(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.xlogy(x, y)\ntensor([1.0986, 1.3863, 0.0000])\n>>> torch.xlogy(x, 4)\ntensor([1.3863, 2.7726, 4.1589])\n>>> torch.xlogy(2, y)\ntensor([2.1972, 1.3863, 0.0000])\n",
        "Question": "How to use torch.xlogy, give an example?",
        "Id": 723,
        "source": "https://pytorch.org/docs/stable/generated/torch.xlogy.html#torch.xlogy",
        "context": " Similar to SciPy\u2019sscipy.special.xlogy."
    },
    {
        "Answer": ">>> x = torch.tensor([[-1.0, 0.0], [1.0, 2.0]])\n>>> torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8)\ntensor([[-1.,  0.],\n        [ 1.,  2.]], size=(2, 2), dtype=torch.quint8,\n       quantization_scheme=torch.per_channel_affine,\n       scale=tensor([0.1000, 0.0100], dtype=torch.float64),\n       zero_point=tensor([10,  0]), axis=0)\n>>> torch.quantize_per_channel(x, torch.tensor([0.1, 0.01]), torch.tensor([10, 0]), 0, torch.quint8).int_repr()\ntensor([[  0,  10],\n        [100, 200]], dtype=torch.uint8)\n",
        "Question": "How to use torch.quantize_per_channel, give an example?",
        "Id": 724,
        "source": "https://pytorch.org/docs/stable/generated/torch.quantize_per_channel.html#torch.quantize_per_channel",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([1.], requires_grad=True)\n>>> with torch.no_grad():\n...   with torch.enable_grad():\n...     y = x * 2\n>>> y.requires_grad\nTrue\n>>> y.backward()\n>>> x.grad\n>>> @torch.enable_grad()\n... def doubler(x):\n...     return x * 2\n>>> with torch.no_grad():\n...     z = doubler(x)\n>>> z.requires_grad\nTrue\n",
        "Question": "How to use torch.enable_grad, give an example?",
        "Id": 725,
        "source": "https://pytorch.org/docs/stable/generated/torch.enable_grad.html#torch.enable_grad",
        "context": " Also functions as a decorator. (Make sure to instantiate with parenthesis.)"
    },
    {
        "Answer": "L_complex = torch.linalg.eigvals(A)\n",
        "Question": "How to use torch.eig, give an example?",
        "Id": 726,
        "source": "https://pytorch.org/docs/stable/generated/torch.eig.html#torch.eig",
        "context": " torch.eig()is deprecated in favor oftorch.linalg.eig()and will be removed in a future PyTorch release.torch.linalg.eig()returns complex tensors of dtypecfloatorcdoublerather than real tensors mimicking complex tensors.L,_=torch.eig(A)should be replaced with"
    },
    {
        "Answer": "L_complex, V_complex = torch.linalg.eig(A)\n",
        "Question": "How  L,_=torch.eig(A)should be replaced withL,V=torch.eig(A,eigenvectors=True)should be replaced with, give an example?",
        "Id": 727,
        "source": "https://pytorch.org/docs/stable/generated/torch.eig.html#torch.eig",
        "context": " L,_=torch.eig(A)should be replaced withL,V=torch.eig(A,eigenvectors=True)should be replaced with"
    },
    {
        "Answer": "Trivial example with a diagonal matrix. By default, only eigenvalues are computed:\n\n>>> a = torch.diag(torch.tensor([1, 2, 3], dtype=torch.double))\n>>> e, v = torch.eig(a)\n>>> e\ntensor([[1., 0.],\n        [2., 0.],\n        [3., 0.]], dtype=torch.float64)\n>>> v\ntensor([], dtype=torch.float64)\n\nCompute also the eigenvectors:\n\n>>> e, v = torch.eig(a, eigenvectors=True)\n>>> e\ntensor([[1., 0.],\n        [2., 0.],\n        [3., 0.]], dtype=torch.float64)\n>>> v\ntensor([[1., 0., 0.],\n        [0., 1., 0.],\n        [0., 0., 1.]], dtype=torch.float64)\n",
        "Question": "How  , give an example?",
        "Id": 728,
        "source": "https://pytorch.org/docs/stable/generated/torch.eig.html#torch.eig",
        "context": " "
    },
    {
        "Answer": "DataLoader(dataset, batch_size=1, shuffle=False, sampler=None,\n           batch_sampler=None, num_workers=0, collate_fn=None,\n           pin_memory=False, drop_last=False, timeout=0,\n           worker_init_fn=None, *, prefetch_factor=2,\n           persistent_workers=False)\n",
        "Question": "How to use At the heart of PyTorch data loading utility is thetorch.utils.data.DataLoaderclass.  It represents a Python iterable over a dataset, with support forThese options are configured by the constructor arguments of aDataLoader, which has signature:, give an example?",
        "Id": 729,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " These options are configured by the constructor arguments of aDataLoader, which has signature:"
    },
    {
        "Answer": "for indices in batch_sampler:\n    yield collate_fn([dataset[i] for i in indices])\n",
        "Question": "How to use After fetching a list of samples using the indices from sampler, the function\npassed as thecollate_fnargument is used to collate lists of samples\ninto batches.In this case, loading from a map-style dataset is roughly equivalent with:, give an example?",
        "Id": 730,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " After fetching a list of samples using the indices from sampler, the function\npassed as thecollate_fnargument is used to collate lists of samples\ninto batches.In this case, loading from a map-style dataset is roughly equivalent with:"
    },
    {
        "Answer": "dataset_iter = iter(dataset)\nfor indices in batch_sampler:\n    yield collate_fn([next(dataset_iter) for _ in indices])\n",
        "Question": "How to use In this case, loading from a map-style dataset is roughly equivalent with:and loading from an iterable-style dataset is roughly equivalent with:, give an example?",
        "Id": 731,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " In this case, loading from a map-style dataset is roughly equivalent with:and loading from an iterable-style dataset is roughly equivalent with:"
    },
    {
        "Answer": "for index in sampler:\n    yield collate_fn(dataset[index])\n",
        "Question": "How to use When automatic batching is disabled, the defaultcollate_fnsimply\nconverts NumPy arrays into PyTorch Tensors, and keeps everything else untouched.In this case, loading from a map-style dataset is roughly equivalent with:, give an example?",
        "Id": 732,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " When automatic batching is disabled, the defaultcollate_fnsimply\nconverts NumPy arrays into PyTorch Tensors, and keeps everything else untouched.In this case, loading from a map-style dataset is roughly equivalent with:"
    },
    {
        "Answer": "for data in iter(dataset):\n    yield collate_fn(data)\n",
        "Question": "How  In this case, loading from a map-style dataset is roughly equivalent with:and loading from an iterable-style dataset is roughly equivalent with:, give an example?",
        "Id": 733,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " In this case, loading from a map-style dataset is roughly equivalent with:and loading from an iterable-style dataset is roughly equivalent with:"
    },
    {
        "Answer": "class SimpleCustomBatch:\n    def __init__(self, data):\n        transposed_data = list(zip(*data))\n        self.inp = torch.stack(transposed_data[0], 0)\n        self.tgt = torch.stack(transposed_data[1], 0)\n\n    # custom memory pinning method on custom type\n    def pin_memory(self):\n        self.inp = self.inp.pin_memory()\n        self.tgt = self.tgt.pin_memory()\n        return self\n\ndef collate_wrapper(batch):\n    return SimpleCustomBatch(batch)\n\ninps = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\ntgts = torch.arange(10 * 5, dtype=torch.float32).view(10, 5)\ndataset = TensorDataset(inps, tgts)\n\nloader = DataLoader(dataset, batch_size=2, collate_fn=collate_wrapper,\n                    pin_memory=True)\n\nfor batch_ndx, sample in enumerate(loader):\n    print(sample.inp.is_pinned())\n    print(sample.tgt.is_pinned())\n",
        "Question": "How to use See the example below., give an example?",
        "Id": 734,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " See the example below."
    },
    {
        "Answer": ">>> class MyIterableDataset(torch.utils.data.IterableDataset):\n...     def __init__(self, start, end):\n...         super(MyIterableDataset).__init__()\n...         assert end > start, \"this example code only works with end >= start\"\n...         self.start = start\n...         self.end = end\n...\n...     def __iter__(self):\n...         worker_info = torch.utils.data.get_worker_info()\n...         if worker_info is None:  # single-process data loading, return the full iterator\n...             iter_start = self.start\n...             iter_end = self.end\n...         else:  # in a worker process\n...             # split workload\n...             per_worker = int(math.ceil((self.end - self.start) / float(worker_info.num_workers)))\n...             worker_id = worker_info.id\n...             iter_start = self.start + worker_id * per_worker\n...             iter_end = min(iter_start + per_worker, self.end)\n...         return iter(range(iter_start, iter_end))\n...\n>>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].\n>>> ds = MyIterableDataset(start=3, end=7)\n\n>>> # Single-process loading\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=0)))\n[3, 4, 5, 6]\n\n>>> # Mult-process loading with two worker processes\n>>> # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=2)))\n[3, 5, 4, 6]\n\n>>> # With even more workers\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=20)))\n[3, 4, 5, 6]\n",
        "Question": "How to use torch.utils.data.IterableDataset, give an example?",
        "Id": 735,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " When a subclass is used withDataLoader, each\nitem in the dataset will be yielded from theDataLoaderiterator. Whennum_workers>0, each worker process will have a\ndifferent copy of the dataset object, so it is often desired to configure\neach copy independently to avoid having duplicate data returned from the\nworkers.get_worker_info(), when called in a worker\nprocess, returns information about the worker. It can be used in either the\ndataset\u2019s__iter__()method or theDataLoader\u2018sworker_init_fnoption to modify each copy\u2019s behavior."
    },
    {
        "Answer": ">>> class MyIterableDataset(torch.utils.data.IterableDataset):\n...     def __init__(self, start, end):\n...         super(MyIterableDataset).__init__()\n...         assert end > start, \"this example code only works with end >= start\"\n...         self.start = start\n...         self.end = end\n...\n...     def __iter__(self):\n...         return iter(range(self.start, self.end))\n...\n>>> # should give same set of data as range(3, 7), i.e., [3, 4, 5, 6].\n>>> ds = MyIterableDataset(start=3, end=7)\n\n>>> # Single-process loading\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=0)))\n[3, 4, 5, 6]\n>>>\n>>> # Directly doing multi-process loading yields duplicate data\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=2)))\n[3, 3, 4, 4, 5, 5, 6, 6]\n\n>>> # Define a `worker_init_fn` that configures each dataset copy differently\n>>> def worker_init_fn(worker_id):\n...     worker_info = torch.utils.data.get_worker_info()\n...     dataset = worker_info.dataset  # the dataset copy in this worker process\n...     overall_start = dataset.start\n...     overall_end = dataset.end\n...     # configure the dataset to only process the split workload\n...     per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers)))\n...     worker_id = worker_info.id\n...     dataset.start = overall_start + worker_id * per_worker\n...     dataset.end = min(dataset.start + per_worker, overall_end)\n...\n\n>>> # Mult-process loading with the custom `worker_init_fn`\n>>> # Worker 0 fetched [3, 4].  Worker 1 fetched [5, 6].\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=2, worker_init_fn=worker_init_fn)))\n[3, 5, 4, 6]\n\n>>> # With even more workers\n>>> print(list(torch.utils.data.DataLoader(ds, num_workers=20, worker_init_fn=worker_init_fn)))\n[3, 4, 5, 6]\n",
        "Question": "How  , give an example?",
        "Id": 736,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " "
    },
    {
        "Answer": ">>> random_split(range(10), [3, 7], generator=torch.Generator().manual_seed(42))\n",
        "Question": "How to use torch.utils.data.random_split, give an example?",
        "Id": 737,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " Randomly split a dataset into non-overlapping new datasets of given lengths.\nOptionally fix the generator for reproducible results, e.g.:"
    },
    {
        "Answer": ">>> list(WeightedRandomSampler([0.1, 0.9, 0.4, 0.7, 3.0, 0.6], 5, replacement=True))\n[4, 4, 1, 4, 5]\n>>> list(WeightedRandomSampler([0.9, 0.4, 0.05, 0.2, 0.3, 0.1], 5, replacement=False))\n[0, 1, 4, 3, 2]\n",
        "Question": "How to use torch.utils.data.WeightedRandomSampler, give an example?",
        "Id": 738,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " "
    },
    {
        "Answer": ">>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=False))\n[[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]]\n>>> list(BatchSampler(SequentialSampler(range(10)), batch_size=3, drop_last=True))\n[[0, 1, 2], [3, 4, 5], [6, 7, 8]]\n",
        "Question": "How to use torch.utils.data.BatchSampler, give an example?",
        "Id": 739,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " "
    },
    {
        "Answer": ">>> sampler = DistributedSampler(dataset) if is_distributed else None\n>>> loader = DataLoader(dataset, shuffle=(sampler is None),\n...                     sampler=sampler)\n>>> for epoch in range(start_epoch, n_epochs):\n...     if is_distributed:\n...         sampler.set_epoch(epoch)\n...     train(loader)\n",
        "Question": "How to use torch.utils.data.distributed.DistributedSampler, give an example?",
        "Id": 740,
        "source": "https://pytorch.org/docs/stable/data.html",
        "context": " It is especially useful in conjunction withtorch.nn.parallel.DistributedDataParallel. In such a case, each\nprocess can pass aDistributedSamplerinstance as aDataLoadersampler, and load a subset of the\noriginal dataset that is exclusive to it."
    },
    {
        "Answer": ">>> a = torch.randn(1, 3)\n>>> a\ntensor([[ 0.1133, -0.9567,  0.2958]])\n>>> torch.sum(a)\ntensor(-0.5475)\n",
        "Question": "How to use torch.sum, give an example?",
        "Id": 741,
        "source": "https://pytorch.org/docs/stable/generated/torch.sum.html#torch.sum",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4, 4)\n>>> a\ntensor([[ 0.0569, -0.2475,  0.0737, -0.3429],\n        [-0.2993,  0.9138,  0.9337, -1.6864],\n        [ 0.1132,  0.7892, -0.1003,  0.5688],\n        [ 0.3637, -0.9906, -0.4752, -1.5197]])\n>>> torch.sum(a, 1)\ntensor([-0.4598, -0.1381,  1.3708, -2.6217])\n>>> b = torch.arange(4 * 5 * 6).view(4, 5, 6)\n>>> torch.sum(b, (2, 1))\ntensor([  435.,  1335.,  2235.,  3135.])\n",
        "Question": "How  IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimension(s)dimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in the\noutput tensor having 1 (orlen(dim)) fewer dimension(s)., give an example?",
        "Id": 742,
        "source": "https://pytorch.org/docs/stable/generated/torch.sum.html#torch.sum",
        "context": " IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimension(s)dimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in the\noutput tensor having 1 (orlen(dim)) fewer dimension(s)."
    },
    {
        "Answer": ">>> torch.bitwise_not(torch.tensor([-1, -2, 3], dtype=torch.int8))\ntensor([ 0,  1, -4], dtype=torch.int8)\n",
        "Question": "How to use torch.bitwise_not, give an example?",
        "Id": 743,
        "source": "https://pytorch.org/docs/stable/generated/torch.bitwise_not.html#torch.bitwise_not",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.arange(16.0).reshape(4,4)\n>>> t\ntensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.]])\n>>> torch.vsplit(t, 2)\n(tensor([[0., 1., 2., 3.],\n         [4., 5., 6., 7.]]),\n tensor([[ 8.,  9., 10., 11.],\n         [12., 13., 14., 15.]]))\n>>> torch.vsplit(t, [3, 6])\n(tensor([[ 0.,  1.,  2.,  3.],\n         [ 4.,  5.,  6.,  7.],\n         [ 8.,  9., 10., 11.]]),\n tensor([[12., 13., 14., 15.]]),\n tensor([], size=(0, 4)))\n",
        "Question": "How to use torch.vsplit, give an example?",
        "Id": 744,
        "source": "https://pytorch.org/docs/stable/generated/torch.vsplit.html#torch.vsplit",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.arange(16.0).reshape(4,4)\n>>> t\ntensor([[ 0.,  1.,  2.,  3.],\n        [ 4.,  5.,  6.,  7.],\n        [ 8.,  9., 10., 11.],\n        [12., 13., 14., 15.]])\n>>> torch.hsplit(t, 2)\n(tensor([[ 0.,  1.],\n         [ 4.,  5.],\n         [ 8.,  9.],\n         [12., 13.]]),\n tensor([[ 2.,  3.],\n         [ 6.,  7.],\n         [10., 11.],\n         [14., 15.]]))\n>>> torch.hsplit(t, [3, 6])\n(tensor([[ 0.,  1.,  2.],\n         [ 4.,  5.,  6.],\n         [ 8.,  9., 10.],\n         [12., 13., 14.]]),\n tensor([[ 3.],\n         [ 7.],\n         [11.],\n         [15.]]),\n tensor([], size=(4, 0)))\n",
        "Question": "How to use torch.hsplit, give an example?",
        "Id": 745,
        "source": "https://pytorch.org/docs/stable/generated/torch.hsplit.html#torch.hsplit",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(-0.5, 1, 0.5)\n>>> a\ntensor([-0.5000,  0.0000,  0.5000])\n>>> torch.special.entr(a)\ntensor([  -inf, 0.0000, 0.3466])\n",
        "Question": "How  , give an example?",
        "Id": 746,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erf(torch.tensor([0, -1., 10.]))\ntensor([ 0.0000, -0.8427,  1.0000])\n",
        "Question": "How  , give an example?",
        "Id": 747,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfc(torch.tensor([0, -1., 10.]))\ntensor([ 1.0000, 1.8427,  0.0000])\n",
        "Question": "How  , give an example?",
        "Id": 748,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.erfinv(torch.tensor([0, 0.5, -1.]))\ntensor([ 0.0000,  0.4769,    -inf])\n",
        "Question": "How  , give an example?",
        "Id": 749,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.randn(4)\n>>> t\ntensor([ 0.9213,  1.0887, -0.8858, -1.7683])\n>>> torch.special.expit(t)\ntensor([ 0.7153,  0.7481,  0.2920,  0.1458])\n",
        "Question": "How  , give an example?",
        "Id": 750,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.expm1(torch.tensor([0, math.log(2.)]))\ntensor([ 0.,  1.])\n",
        "Question": "How  , give an example?",
        "Id": 751,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.exp2(torch.tensor([0, math.log2(2.), 3, 4]))\ntensor([ 1.,  2.,  8., 16.])\n",
        "Question": "How  , give an example?",
        "Id": 752,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.arange(0.5, 2, 0.5)\n>>> torch.special.gammaln(a)\ntensor([ 0.5724,  0.0000, -0.1208])\n",
        "Question": "How  , give an example?",
        "Id": 753,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> torch.special.i0e(torch.arange(5, dtype=torch.float32))\ntensor([1.0000, 0.4658, 0.3085, 0.2430, 0.2070])\n",
        "Question": "How  , give an example?",
        "Id": 754,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(5)\n>>> a\ntensor([0.2796, 0.9331, 0.6486, 0.1523, 0.6516])\n>>> torch.special.logit(a, eps=1e-6)\ntensor([-0.9466,  2.6352,  0.6131, -1.7169,  0.6261])\n",
        "Question": "How  , give an example?",
        "Id": 755,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(5,)\n>>> y = torch.tensor([-1, 0, 1, float('inf'), float('nan')])\n>>> torch.special.xlog1py(x, y)\ntensor([0., 0., 0., 0., nan])\n>>> x = torch.tensor([1, 2, 3])\n>>> y = torch.tensor([3, 2, 1])\n>>> torch.special.xlog1py(x, y)\ntensor([1.3863, 2.1972, 2.0794])\n>>> torch.special.xlog1py(x, 4)\ntensor([1.6094, 3.2189, 4.8283])\n>>> torch.special.xlog1py(2, y)\ntensor([2.7726, 2.1972, 1.3863])\n",
        "Question": "How  Similar to SciPy\u2019sscipy.special.xlog1py., give an example?",
        "Id": 756,
        "source": "https://pytorch.org/docs/stable/special.html#torch.special.expit",
        "context": " Similar to SciPy\u2019sscipy.special.xlog1py."
    },
    {
        "Answer": ">>> x = torch.arange(4).view(2, 2)\n>>> x\ntensor([[0, 1],\n        [2, 3]])\n>>> torch.fliplr(x)\ntensor([[1, 0],\n        [3, 2]])\n",
        "Question": "How to use torch.fliplr, give an example?",
        "Id": 757,
        "source": "https://pytorch.org/docs/stable/generated/torch.fliplr.html#torch.fliplr",
        "context": " Flip the entries in each row in the left/right direction.\nColumns are preserved, but appear in a different order than before."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.1632,  1.1835, -0.6979, -0.7325])\n>>> torch.cosh(a)\ntensor([ 1.0133,  1.7860,  1.2536,  1.2805])\n",
        "Question": "How to use torch.cosh, give an example?",
        "Id": 758,
        "source": "https://pytorch.org/docs/stable/generated/torch.cosh.html#torch.cosh",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([[3.142, -3.142], [6.283, -6.283], [1.570, -1.570]])\n>>> torch.rad2deg(a)\ntensor([[ 180.0233, -180.0233],\n        [ 359.9894, -359.9894],\n        [  89.9544,  -89.9544]])\n",
        "Question": "How to use torch.rad2deg, give an example?",
        "Id": 759,
        "source": "https://pytorch.org/docs/stable/generated/torch.rad2deg.html#torch.rad2deg",
        "context": " "
    },
    {
        "Answer": ">>> torch.broadcast_shapes((2,), (3, 1), (1, 1, 1))\ntorch.Size([1, 3, 2])\n",
        "Question": "How to use torch.broadcast_shapes, give an example?",
        "Id": 760,
        "source": "https://pytorch.org/docs/stable/generated/torch.broadcast_shapes.html#torch.broadcast_shapes",
        "context": " This is equivalent totorch.broadcast_tensors(*map(torch.empty,shapes))[0].shapebut avoids the need create to intermediate tensors. This is useful for\nbroadcasting tensors of common batch shape but different rightmost shape,\ne.g. to broadcast mean vectors with covariance matrices."
    },
    {
        "Answer": ">>> torch.get_default_dtype()  # initial default for floating point is torch.float32\ntorch.float32\n>>> torch.set_default_dtype(torch.float64)\n>>> torch.get_default_dtype()  # default is now changed to torch.float64\ntorch.float64\n>>> torch.set_default_tensor_type(torch.FloatTensor)  # setting tensor type also affects this\n>>> torch.get_default_dtype()  # changed to torch.float32, the dtype for torch.FloatTensor\ntorch.float32\n",
        "Question": "How to use torch.get_default_dtype, give an example?",
        "Id": 761,
        "source": "https://pytorch.org/docs/stable/generated/torch.get_default_dtype.html#torch.get_default_dtype",
        "context": " "
    },
    {
        "Answer": ">>> a = [1, 2, 3]\n>>> b = [4, 5]\n>>> list(itertools.product(a, b))\n[(1, 4), (1, 5), (2, 4), (2, 5), (3, 4), (3, 5)]\n>>> tensor_a = torch.tensor(a)\n>>> tensor_b = torch.tensor(b)\n>>> torch.cartesian_prod(tensor_a, tensor_b)\ntensor([[1, 4],\n        [1, 5],\n        [2, 4],\n        [2, 5],\n        [3, 4],\n        [3, 5]])\n",
        "Question": "How to use torch.cartesian_prod, give an example?",
        "Id": 762,
        "source": "https://pytorch.org/docs/stable/generated/torch.cartesian_prod.html#torch.cartesian_prod",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 763,
        "source": "https://pytorch.org/docs/stable/torch.html#generators",
        "context": " "
    },
    {
        "Answer": ">>> input = torch.empty(2, 3)\n>>> torch.zeros_like(input)\ntensor([[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]])\n",
        "Question": "How to use torch.zeros_like, give an example?",
        "Id": 764,
        "source": "https://pytorch.org/docs/stable/generated/torch.zeros_like.html#torch.zeros_like",
        "context": " "
    },
    {
        "Answer": ">>> t = torch.tensor([[[1, 2],\n...                    [3, 4]],\n...                   [[5, 6],\n...                    [7, 8]]])\n>>> torch.flatten(t)\ntensor([1, 2, 3, 4, 5, 6, 7, 8])\n>>> torch.flatten(t, start_dim=1)\ntensor([[1, 2, 3, 4],\n        [5, 6, 7, 8]])\n",
        "Question": "How to use torch.flatten, give an example?",
        "Id": 765,
        "source": "https://pytorch.org/docs/stable/generated/torch.flatten.html#torch.flatten",
        "context": " Unlike NumPy\u2019s flatten, which always copies input\u2019s data, this function may return the original object, a view,\nor copy. If no dimensions are flattened, then the original objectinputis returned. Otherwise, if input can\nbe viewed as the flattened shape, then that view is returned. Finally, only if the input cannot be viewed as the\nflattened shape is input\u2019s data copied. Seetorch.Tensor.view()for details on when a view will be returned."
    },
    {
        "Answer": ">>> torch.bitwise_and(torch.tensor([-1, -2, 3], dtype=torch.int8), torch.tensor([1, 0, 3], dtype=torch.int8))\ntensor([1, 0,  3], dtype=torch.int8)\n>>> torch.bitwise_and(torch.tensor([True, True, False]), torch.tensor([False, True, False]))\ntensor([ False, True, False])\n",
        "Question": "How to use torch.bitwise_and, give an example?",
        "Id": 766,
        "source": "https://pytorch.org/docs/stable/generated/torch.bitwise_and.html#torch.bitwise_and",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([1, 0.5])\n>>> torch.digamma(a)\ntensor([-0.5772, -1.9635])\n",
        "Question": "How to use torch.digamma, give an example?",
        "Id": 767,
        "source": "https://pytorch.org/docs/stable/generated/torch.digamma.html#torch.digamma",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 768,
        "source": "https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining-mutating-ops",
        "context": " "
    },
    {
        "Answer": "import torch\n# Simple module for demonstration\nclass MyModule(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.param = torch.nn.Parameter(torch.rand(3, 4))\n        self.linear = torch.nn.Linear(4, 5)\n\n    def forward(self, x):\n        return self.linear(x + self.param).clamp(min=0.0, max=1.0)\n\nmodule = MyModule()\n\nfrom torch.fx import symbolic_trace\n# Symbolic tracing frontend - captures the semantics of the module\nsymbolic_traced : torch.fx.GraphModule = symbolic_trace(module)\n\n# High-level intermediate representation (IR) - Graph representation\nprint(symbolic_traced.graph)\n\"\"\"\ngraph(x):\n    %param : [#users=1] = self.param\n    %add_1 : [#users=1] = call_function[target=<built-in function add>](args = (%x, %param), kwargs = {})\n    %linear_1 : [#users=1] = call_module[target=linear](args = (%add_1,), kwargs = {})\n    %clamp_1 : [#users=1] = call_method[target=clamp](args = (%linear_1,), kwargs = {min: 0.0, max: 1.0})\n    return clamp_1\n\"\"\"\n\n# Code generation - valid Python code\nprint(symbolic_traced.code)\n\"\"\"\ndef forward(self, x):\n    param = self.param\n    add_1 = x + param;  x = param = None\n    linear_1 = self.linear(add_1);  add_1 = None\n    clamp_1 = linear_1.clamp(min = 0.0, max = 1.0);  linear_1 = None\n    return clamp_1\n\"\"\"\n",
        "Question": "How to use This feature is under a Beta release and its API may change.FX is a toolkit for developers to use to transformnn.Moduleinstances. FX consists of three main components: asymbolic tracer,anintermediate representation, andPython code generation. A\ndemonstration of these components in action:, give an example?",
        "Id": 769,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " FX is a toolkit for developers to use to transformnn.Moduleinstances. FX consists of three main components: asymbolic tracer,anintermediate representation, andPython code generation. A\ndemonstration of these components in action:"
    },
    {
        "Answer": "import torch\nimport torch.fx\n\ndef transform(m: nn.Module,\n              tracer_class : type = torch.fx.Tracer) -> torch.nn.Module:\n    # Step 1: Acquire a Graph representing the code in `m`\n\n    # NOTE: torch.fx.symbolic_trace is a wrapper around a call to\n    # fx.Tracer.trace and constructing a GraphModule. We'll\n    # split that out in our transform to allow the caller to\n    # customize tracing behavior.\n    graph : torch.fx.Graph = tracer_class().trace(m)\n\n    # Step 2: Modify this Graph or create a new one\n    graph = ...\n\n    # Step 3: Construct a Module to return\n    return torch.fx.GraphModule(m, graph)\n",
        "Question": "How to use What is an FX transform? Essentially, it\u2019s a function that looks like this., give an example?",
        "Id": 770,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " What is an FX transform? Essentially, it\u2019s a function that looks like this."
    },
    {
        "Answer": "import torch\nimport torch.fx\n\ndef transform(m : nn.Module) -> nn.Module:\n    gm : torch.fx.GraphModule = torch.fx.symbolic_trace(m)\n\n    # Modify gm.graph\n    # <...>\n\n    # Recompile the forward() method of `gm` from its Graph\n    gm.recompile()\n\n    return gm\n",
        "Question": "How to use NoteIt is also possible to modify an existingGraphModuleinstead of\ncreating a new one, like so:, give an example?",
        "Id": 771,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " It is also possible to modify an existingGraphModuleinstead of\ncreating a new one, like so:"
    },
    {
        "Answer": "import torch\nimport torch.fx\n\nclass MyModule(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.param = torch.nn.Parameter(torch.rand(3, 4))\n        self.linear = torch.nn.Linear(4, 5)\n\n    def forward(self, x):\n        return torch.topk(torch.sum(\n            self.linear(x + self.linear.weight).relu(), dim=-1), 3)\n\nm = MyModule()\ngm = torch.fx.symbolic_trace(m)\n\ngm.graph.print_tabular()\n",
        "Question": "How to use Full treatment of the semantics of graphs can be found in theGraphdocumentation, but we are going to cover the basics here. AGraphis\na data structure that represents a method on aGraphModule. The\ninformation that this requires is:All three of these concepts are represented withNodeinstances.\nLet\u2019s see what we mean by that with a short example:, give an example?",
        "Id": 772,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " All three of these concepts are represented withNodeinstances.\nLet\u2019s see what we mean by that with a short example:"
    },
    {
        "Answer": "import torch\nimport torch.fx\n\n# Sample module\nclass M(torch.nn.Module):\n    def forward(self, x, y):\n        return torch.add(x, y)\n\ndef transform(m: torch.nn.Module,\n              tracer_class : type = fx.Tracer) -> torch.nn.Module:\n    graph : fx.Graph = tracer_class().trace(m)\n    # FX represents its Graph as an ordered list of\n    # nodes, so we can iterate through them.\n    for node in graph.nodes:\n        # Checks if we're calling a function (i.e:\n        # torch.add)\n        if node.op == 'call_function':\n            # The target attribute is the function\n            # that call_function calls.\n            if node.target == torch.add:\n                node.target = torch.mul\n\n    graph.lint() # Does some checks to make sure the\n                 # Graph is well-formed.\n\n    return fx.GraphModule(m, graph)\n",
        "Question": "How to use One approach to building this newGraphis to directly manipulate your old\none. To aid in this, we can simply take theGraphwe obtain from symbolic\ntracing and modify it. For example, let\u2019s say we desire to replacetorch.add()calls withtorch.mul()calls., give an example?",
        "Id": 773,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " One approach to building this newGraphis to directly manipulate your old\none. To aid in this, we can simply take theGraphwe obtain from symbolic\ntracing and modify it. For example, let\u2019s say we desire to replacetorch.add()calls withtorch.mul()calls."
    },
    {
        "Answer": "# Specifies the insertion point. Any nodes added to the\n# Graph within this scope will be inserted after `node`\nwith traced.graph.inserting_after(node):\n    # Insert a new `call_function` node calling `torch.relu`\n    new_node = traced.graph.call_function(\n        torch.relu, args=(node,))\n\n    # We want all places that used the value of `node` to\n    # now use that value after the `relu` call we've added.\n    # We use the `replace_all_uses_with` API to do this.\n    node.replace_all_uses_with(new_node)\n",
        "Question": "How to use One approach to building this newGraphis to directly manipulate your old\none. To aid in this, we can simply take theGraphwe obtain from symbolic\ntracing and modify it. For example, let\u2019s say we desire to replacetorch.add()calls withtorch.mul()calls.We can also do more involvedGraphrewrites, such as\ndeleting or appending nodes. To aid in these transformations,\nFX has utility functions for transforming the graph that can\nbe found in theGraphdocumentation. An\nexample of using these APIs to append atorch.relu()call\ncan be found below., give an example?",
        "Id": 774,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " We can also do more involvedGraphrewrites, such as\ndeleting or appending nodes. To aid in these transformations,\nFX has utility functions for transforming the graph that can\nbe found in theGraphdocumentation. An\nexample of using these APIs to append atorch.relu()call\ncan be found below."
    },
    {
        "Answer": "# Note that this decomposition rule can be read as regular Python\ndef relu_decomposition(x):\n    return (x > 0) * x\n\ndecomposition_rules = {}\ndecomposition_rules[F.relu] = relu_decomposition\n\ndef decompose(model: torch.nn.Module,\n              tracer_class : type = fx.Tracer) -> torch.nn.Module:\n    \"\"\"\n    Decompose `model` into smaller constituent operations.\n    Currently,this only supports decomposing ReLU into its\n    mathematical definition: (x > 0) * x\n    \"\"\"\n    graph : fx.Graph = tracer_class().trace(model)\n    new_graph = fx.Graph()\n    env = {}\n    for node in graph.nodes:\n        if node.op == 'call_function' and node.target in decomposition_rules:\n            # By wrapping the arguments with proxies,\n            # we can dispatch to the appropriate\n            # decomposition rule and implicitly add it\n            # to the Graph by symbolically tracing it.\n            proxy_args = [\n                fx.Proxy(env[x.name]) if isinstance(x, fx.Node) else x for x in node.args]\n            output_proxy = decomposition_rules[node.target](*proxy_args)\n\n            # Operations on `Proxy` always yield new `Proxy`s, and the\n            # return value of our decomposition rule is no exception.\n            # We need to extract the underlying `Node` from the `Proxy`\n            # to use it in subsequent iterations of this transform.\n            new_node = output_proxy.node\n            env[node.name] = new_node\n        else:\n            # Default case: we don't have a decomposition rule for this\n            # node, so just copy the node over into the new graph.\n            new_node = new_graph.node_copy(node, lambda x: env[x.name])\n            env[node.name] = new_node\n    return fx.GraphModule(model, new_graph)\n",
        "Question": "How to use Another way of manipulatingGraphs is by reusing theProxymachinery used in symbolic tracing. For example, let\u2019s\nimagine that we wanted to write a transformation that decomposed\nPyTorch functions into smaller operations. It would transform everyF.relu(x)call into(x>0)*x. One possibility would be to\nperform the requisite graph rewriting to insert the comparison and\nmultiplication after theF.relu, and then clean up the originalF.relu. However, we can automate this process by usingProxyobjects to automatically record operations into theGraph.To use this method, we write the operations that we want inserted as regular\nPyTorch code and invoke that code withProxyobjects as arugments.\nTheseProxyobjects will capture the operations that are performed\non them and append them to theGraph., give an example?",
        "Id": 775,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " To use this method, we write the operations that we want inserted as regular\nPyTorch code and invoke that code withProxyobjects as arugments.\nTheseProxyobjects will capture the operations that are performed\non them and append them to theGraph."
    },
    {
        "Answer": "import torch\nimport torch.fx\nfrom torch.fx.node import Node\n\nfrom typing import Dict\n\nclass ShapeProp:\n    \"\"\"\n    Shape propagation. This class takes a `GraphModule`.\n    Then, its `propagate` method executes the `GraphModule`\n    node-by-node with the given arguments. As each operation\n    executes, the ShapeProp class stores away the shape and\n    element type for the output values of each operation on\n    the `shape` and `dtype` attributes of the operation's\n    `Node`.\n    \"\"\"\n    def __init__(self, mod):\n        self.mod = mod\n        self.graph = mod.graph\n        self.modules = dict(self.mod.named_modules())\n\n    def propagate(self, *args):\n        args_iter = iter(args)\n        env : Dict[str, Node] = {}\n\n        def load_arg(a):\n            return torch.fx.graph.map_arg(a, lambda n: env[n.name])\n\n        def fetch_attr(target : str):\n            target_atoms = target.split('.')\n            attr_itr = self.mod\n            for i, atom in enumerate(target_atoms):\n                if not hasattr(attr_itr, atom):\n                    raise RuntimeError(f\"Node referenced nonexistant target {'.'.join(target_atoms[:i])}\")\n                attr_itr = getattr(attr_itr, atom)\n            return attr_itr\n\n        for node in self.graph.nodes:\n            if node.op == 'placeholder':\n                result = next(args_iter)\n            elif node.op == 'get_attr':\n                result = fetch_attr(node.target)\n            elif node.op == 'call_function':\n                result = node.target(*load_arg(node.args), **load_arg(node.kwargs))\n            elif node.op == 'call_method':\n                self_obj, *args = load_arg(node.args)\n                kwargs = load_arg(node.kwargs)\n                result = getattr(self_obj, node.target)(*args, **kwargs)\n            elif node.op == 'call_module':\n                result = self.modules[node.target](*load_arg(node.args), **load_arg(node.kwargs))\n\n            # This is the only code specific to shape propagation.\n            # you can delete this `if` branch and this becomes\n            # a generic GraphModule interpreter.\n            if isinstance(result, torch.Tensor):\n                node.shape = result.shape\n                node.dtype = result.dtype\n\n            env[node.name] = result\n\n        return load_arg(self.graph.result)\n",
        "Question": "How to use A useful code organizational pattern in FX is to loop over all theNodes\nin aGraphand execute them. This can be used for several things including\nruntime analysis of values flowing through the graph or transformation of the code\nvia retracing withProxys. For example, suppose we want to run aGraphModuleand record thetorch.Tensorshape and dtype\nproperties on the nodes as we see them at runtime. That might look like:, give an example?",
        "Id": 776,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " A useful code organizational pattern in FX is to loop over all theNodes\nin aGraphand execute them. This can be used for several things including\nruntime analysis of values flowing through the graph or transformation of the code\nvia retracing withProxys. For example, suppose we want to run aGraphModuleand record thetorch.Tensorshape and dtype\nproperties on the nodes as we see them at runtime. That might look like:"
    },
    {
        "Answer": "import torch\nimport torch.fx\nimport torchvision.models as models\n\ndef transform(m : torch.nn.Module) -> torch.nn.Module:\n    gm = torch.fx.symbolic_trace(m)\n\n    # Imagine we're doing some transforms here\n    # <...>\n\n    gm.recompile()\n\n    return gm\n\nresnet18 = models.resnet18()\ntransformed_resnet18 = transform(resnet18)\n\ninput_image = torch.randn(5, 3, 224, 224)\n\nassert resnet18(input_image) == transformed_resnet18(input_image)\n\"\"\"\nRuntimeError: Boolean value of Tensor with more than one value is ambiguous\n\"\"\"\n",
        "Question": "How to use Because the output of most deep learning modules consists of floating\npointtorch.Tensorinstances, checking for equivalence between\nthe results of twotorch.nn.Moduleis not as straightforward\nas doing a simple equality check. To motivate this, let\u2019s use an\nexample:, give an example?",
        "Id": 777,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Because the output of most deep learning modules consists of floating\npointtorch.Tensorinstances, checking for equivalence between\nthe results of twotorch.nn.Moduleis not as straightforward\nas doing a simple equality check. To motivate this, let\u2019s use an\nexample:"
    },
    {
        "Answer": "assert torch.allclose(resnet18(input_image), transformed_resnet18(input_image))\n",
        "Question": "How to use Because the output of most deep learning modules consists of floating\npointtorch.Tensorinstances, checking for equivalence between\nthe results of twotorch.nn.Moduleis not as straightforward\nas doing a simple equality check. To motivate this, let\u2019s use an\nexample:Here, we\u2019ve tried to check equality of the values of two deep learning\nmodels with the==equality operator. However, this is not well-\ndefined both due to the issue of that operator returning a tensor\nand not a bool, but also because comparison of floating point values\nshould use a margin of error (or epsilon) to account for the\nnon-commutativity of floating point operations (seeherefor more\ndetails). We can usetorch.allclose()instead, which will give\nus an approximate comparison taking into account a relative and\nabsolute tolerance threshold:, give an example?",
        "Id": 778,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Here, we\u2019ve tried to check equality of the values of two deep learning\nmodels with the==equality operator. However, this is not well-\ndefined both due to the issue of that operator returning a tensor\nand not a bool, but also because comparison of floating point values\nshould use a margin of error (or epsilon) to account for the\nnon-commutativity of floating point operations (seeherefor more\ndetails). We can usetorch.allclose()instead, which will give\nus an approximate comparison taking into account a relative and\nabsolute tolerance threshold:"
    },
    {
        "Answer": "import torch\nimport torch.fx\nimport torchvision.models as models\n\ndef my_pass(inp: torch.nn.Module, tracer_class : type = fx.Tracer) -> torch.nn.Module:\n    graph = tracer_class().trace(inp)\n    # Transformation logic here\n    # <...>\n\n    # Return new Module\n    return fx.GraphModule(inp, graph)\n\nmy_module = models.resnet18()\nmy_module_transformed = my_pass(my_module)\n\ninput_value = torch.randn(5, 3, 224, 224)\n\n# When this line is executed at runtime, we will be dropped into an\n# interactive `pdb` prompt. We can use the `step` or `s` command to\n# step into the execution of the next line\nimport pdb; pdb.set_trace()\n\nmy_module_transformed(input_value)\n",
        "Question": "How to use Invokepdbto step into the running program. Although the code that\nrepresents theGraphis not in any source file, we can still step\ninto it manually usingpdbwhen the forward pass is invoked., give an example?",
        "Id": 779,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Invokepdbto step into the running program. Although the code that\nrepresents theGraphis not in any source file, we can still step\ninto it manually usingpdbwhen the forward pass is invoked."
    },
    {
        "Answer": "# Assume that `traced` is a GraphModule that has undergone some\n# number of transforms\n\n# Copy this code for later\nprint(traced)\n# Print the code generated from symbolic tracing. This outputs:\n\"\"\"\ndef forward(self, y):\n    x = self.x\n    add_1 = x + y;  x = y = None\n    return add_1\n\"\"\"\n\n# Subclass the original Module\nclass SubclassM(M):\n    def __init__(self):\n        super().__init__()\n\n    # Paste the generated `forward` function (the one we printed and\n    # copied above) here\n    def forward(self, y):\n        x = self.x\n        add_1 = x + y;  x = y = None\n        return add_1\n\n# Create an instance of the original, untraced Module. Then, create an\n# instance of the Module with the copied `forward` function. We can\n# now compare the output of both the original and the traced version.\npre_trace = M()\npost_trace = SubclassM()\n",
        "Question": "How to use If you\u2019d like to run the same code multiple times, then it can be\na bit tedious to step to the right code withpdb. In that case, one\napproach is to simply copy-paste the generatedforwardpass into\nyour code and examine it from there., give an example?",
        "Id": 780,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " If you\u2019d like to run the same code multiple times, then it can be\na bit tedious to step to the right code withpdb. In that case, one\napproach is to simply copy-paste the generatedforwardpass into\nyour code and examine it from there."
    },
    {
        "Answer": "m = symbolic_trace(M())\nm.to_folder(\"foo\", \"Bar\")\nfrom foo import Bar\ny = Bar()\n",
        "Question": "How to use GraphModule.to_folder()is a method inGraphModulethat allows\nyou to dump out the generated FX code to a folder. Although copying the\nforward pass into the code often suffices as inPrint the Generated Code,\nit may be easier to examine modules and parameters usingto_folder., give an example?",
        "Id": 781,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " GraphModule.to_folder()is a method inGraphModulethat allows\nyou to dump out the generated FX code to a folder. Although copying the\nforward pass into the code often suffices as inPrint the Generated Code,\nit may be easier to examine modules and parameters usingto_folder."
    },
    {
        "Answer": "# Sample Module\nclass M(torch.nn.Module):\n    def forward(self, x, y):\n        return x + y\n\n# Create an instance of `M`\nm = M()\n\n# Symbolically trace an instance of `M` (returns a GraphModule). In\n# this example, we'll only be discussing how to inspect a\n# GraphModule, so we aren't showing any sample transforms for the\n# sake of brevity.\ntraced = symbolic_trace(m)\n\n# Print the code produced by tracing the module.\nprint(traced)\n# The generated `forward` function is:\n\"\"\"\ndef forward(self, x, y):\n    add_1 = x + y;  x = y = None\n    return add_1\n\"\"\"\n\n# Print the internal Graph.\nprint(traced.graph)\n# This print-out returns:\n\"\"\"\ngraph(x, y):\n    %add_1 : [#users=1] = call_function[target=<built-in function add>](args = (%x, %y), kwargs = {})\n    return add_1\n\"\"\"\n\n# Print a tabular representation of the internal Graph.\ntraced.graph.print_tabular()\n# This gives us:\n\"\"\"\nopcode         name    target                   args      kwargs\n-------------  ------  -----------------------  --------  --------\nplaceholder    x       x                        ()        {}\nplaceholder    y       y                        ()        {}\ncall_function  add_1   <built-in function add>  (x, y)    {}\n\"\"\"\n",
        "Question": "How to use Now that we\u2019ve identified that a transformation is creating incorrect\ncode, it\u2019s time to debug the transformation itself. First, we\u2019ll check\ntheLimitations of Symbolic Tracingsection in the documentation.\nOnce we verify that tracing is working as expected, the goal\nbecomes figuring out what went wrong during ourGraphModuletransformation. There may be a quick answer inWriting Transformations, but, if not, there are several ways to\nexamine our traced module:, give an example?",
        "Id": 782,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Now that we\u2019ve identified that a transformation is creating incorrect\ncode, it\u2019s time to debug the transformation itself. First, we\u2019ll check\ntheLimitations of Symbolic Tracingsection in the documentation.\nOnce we verify that tracing is working as expected, the goal\nbecomes figuring out what went wrong during ourGraphModuletransformation. There may be a quick answer inWriting Transformations, but, if not, there are several ways to\nexamine our traced module:"
    },
    {
        "Answer": "# Sample user-defined function\ndef transform_graph(module: torch.nn.Module, tracer_class : type = fx.Tracer) -> torch.nn.Module:\n    # Get the Graph from our traced Module\n    g = tracer_class().trace(module)\n\n    \"\"\"\n    Transformations on `g` go here\n    \"\"\"\n\n    return fx.GraphModule(module, g)\n\n# Transform the Graph\ntransformed = transform_graph(traced)\n\n# Print the new code after our transforms. Check to see if it was\n# what we expected\nprint(transformed)\n",
        "Question": "How to use Using the utility functions above, we can compare our traced Module\nbefore and after we\u2019ve applied our transformations. Sometimes, a\nsimple visual comparison is enough to trace down a bug. If it\u2019s still\nnot clear what\u2019s going wrong, a debugger likepdbcan be a good\nnext step.Going off of the example above, consider the following code:, give an example?",
        "Id": 783,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Using the utility functions above, we can compare our traced Module\nbefore and after we\u2019ve applied our transformations. Sometimes, a\nsimple visual comparison is enough to trace down a bug. If it\u2019s still\nnot clear what\u2019s going wrong, a debugger likepdbcan be a good\nnext step.Going off of the example above, consider the following code:"
    },
    {
        "Answer": "def func_to_trace(x):\n    if x.sum() > 0:\n        return torch.relu(x)\n    else:\n        return torch.neg(x)\n\ntraced = torch.fx.symbolic_trace(func_to_trace)\n\"\"\"\n  <...>\n  File \"dyn.py\", line 6, in func_to_trace\n    if x.sum() > 0:\n  File \"pytorch/torch/fx/proxy.py\", line 155, in __bool__\n    return self.tracer.to_bool(self)\n  File \"pytorch/torch/fx/proxy.py\", line 85, in to_bool\n    raise TraceError('symbolically traced variables cannot be used as inputs to control flow')\ntorch.fx.proxy.TraceError: symbolically traced variables cannot be used as inputs to control flow\n\"\"\"\n",
        "Question": "How to use The main limitation of symbolic tracing is it does not currently supportdynamic control flow. That is, loops orifstatements where the\ncondition may depend on the input values of the program.For example, let\u2019s examine the following program:, give an example?",
        "Id": 784,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " For example, let\u2019s examine the following program:"
    },
    {
        "Answer": "import torch\nimport torch.fx\n\nclass MyModule(torch.nn.Module):\n    def __init__(self, do_activation : bool = False):\n        super().__init__()\n        self.do_activation = do_activation\n        self.linear = torch.nn.Linear(512, 512)\n\n    def forward(self, x):\n        x = self.linear(x)\n        # This if-statement is so-called static control flow.\n        # Its condition does not depend on any input values\n        if self.do_activation:\n            x = torch.relu(x)\n        return x\n\nwithout_activation = MyModule(do_activation=False)\nwith_activation = MyModule(do_activation=True)\n\ntraced_without_activation = torch.fx.symbolic_trace(without_activation)\nprint(traced_without_activation.code)\n\"\"\"\ndef forward(self, x):\n    linear_1 = self.linear(x);  x = None\n    return linear_1\n\"\"\"\n\ntraced_with_activation = torch.fx.symbolic_trace(with_activation)\nprint(traced_with_activation.code)\n\"\"\"\nimport torch\ndef forward(self, x):\n    linear_1 = self.linear(x);  x = None\n    relu_1 = torch.relu(linear_1);  linear_1 = None\n    return relu_1\n\"\"\"\n",
        "Question": "How to use On the other hand, so-calledstatic control flowis supported. Static\ncontrol flow is loops orifstatements whose value cannot change\nacross invocations. Typically, in PyTorch programs, this control flow\narises for code making decisions about a model\u2019s architecture based on\nhyper-parameters. As a concrete example:, give an example?",
        "Id": 785,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " On the other hand, so-calledstatic control flowis supported. Static\ncontrol flow is loops orifstatements whose value cannot change\nacross invocations. Typically, in PyTorch programs, this control flow\narises for code making decisions about a model\u2019s architecture based on\nhyper-parameters. As a concrete example:"
    },
    {
        "Answer": "def f(x, flag):\n    if flag: return x\n    else: return x*2\n\nfx.symbolic_trace(f) # Fails!\n\nfx.symbolic_trace(f, concrete_args={'flag': True})\n",
        "Question": "How to use The if-statementifself.do_activationdoes not depend on any\nfunction inputs, thus it is static.do_activationcan be considered\nto be a hyper-parameter, and the traces of different instances ofMyModulewith different values for that parameter have different\ncode. This is a valid pattern that is supported by symbolic tracing.Many instances of dynamic control flow are semantically static control\nflow. These instances can be made to support symbolic tracing by\nremoving the data dependencies on input values, for example by moving\nvalues toModuleattributes or by binding concrete values to arguments\nduring symbolic tracing:, give an example?",
        "Id": 786,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " The if-statementifself.do_activationdoes not depend on any\nfunction inputs, thus it is static.do_activationcan be considered\nto be a hyper-parameter, and the traces of different instances ofMyModulewith different values for that parameter have different\ncode. This is a valid pattern that is supported by symbolic tracing.Many instances of dynamic control flow are semantically static control\nflow. These instances can be made to support symbolic tracing by\nremoving the data dependencies on input values, for example by moving\nvalues toModuleattributes or by binding concrete values to arguments\nduring symbolic tracing:"
    },
    {
        "Answer": "import torch\nimport torch.fx\nfrom math import sqrt\n\ndef normalize(x):\n    \"\"\"\n    Normalize `x` by the size of the batch dimension\n    \"\"\"\n    return x / sqrt(len(x))\n\n# It's valid Python code\nnormalize(torch.rand(3, 4))\n\ntraced = torch.fx.symbolic_trace(normalize)\n\"\"\"\n  <...>\n  File \"sqrt.py\", line 9, in normalize\n    return x / sqrt(len(x))\n  File \"pytorch/torch/fx/proxy.py\", line 161, in __len__\n    raise RuntimeError(\"'len' is not supported in symbolic tracing by default. If you want \"\nRuntimeError: 'len' is not supported in symbolic tracing by default. If you want this call to be recorded, please call torch.fx.wrap('len') at module scope\n\"\"\"\n",
        "Question": "How to use FX uses__torch_function__as the mechanism by which it intercepts\ncalls (see thetechnical\noverviewfor more information about this). Some functions, such as builtin Python\nfunctions or those in themathmodule, are not covered by__torch_function__, but we would still like to capture them in\nsymbolic tracing. For example:, give an example?",
        "Id": 787,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " FX uses__torch_function__as the mechanism by which it intercepts\ncalls (see thetechnical\noverviewfor more information about this). Some functions, such as builtin Python\nfunctions or those in themathmodule, are not covered by__torch_function__, but we would still like to capture them in\nsymbolic tracing. For example:"
    },
    {
        "Answer": "torch.fx.wrap('len')\ntorch.fx.wrap('sqrt')\n\ntraced = torch.fx.symbolic_trace(normalize)\n\nprint(traced.code)\n\"\"\"\nimport math\ndef forward(self, x):\n    len_1 = len(x)\n    sqrt_1 = math.sqrt(len_1);  len_1 = None\n    truediv = x / sqrt_1;  x = sqrt_1 = None\n    return truediv\n\"\"\"\n",
        "Question": "How to use FX uses__torch_function__as the mechanism by which it intercepts\ncalls (see thetechnical\noverviewfor more information about this). Some functions, such as builtin Python\nfunctions or those in themathmodule, are not covered by__torch_function__, but we would still like to capture them in\nsymbolic tracing. For example:The error tells us that the built-in functionlenis not supported.\nWe can make it so that functions like this are recorded in the trace as\ndirect calls using thewrap()API:, give an example?",
        "Id": 788,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " The error tells us that the built-in functionlenis not supported.\nWe can make it so that functions like this are recorded in the trace as\ndirect calls using thewrap()API:"
    },
    {
        "Answer": "class MyCustomTracer(torch.fx.Tracer):\n    # Inside here you can override various methods\n    # to customize tracing. See the `Tracer` API\n    # reference\n    pass\n\n\n# Let's use this custom tracer to trace through this module\nclass MyModule(torch.nn.Module):\n    def forward(self, x):\n        return torch.relu(x) + torch.ones(3, 4)\n\nmod = MyModule()\n\ntraced_graph = MyCustomTracer().trace(mod)\n# trace() returns a Graph. Let's wrap it up in a\n# GraphModule to make it runnable\ntraced = torch.fx.GraphModule(mod, traced_graph)\n",
        "Question": "How to use TheTracerclass is the class that underlies the\nimplementation ofsymbolic_trace. The behavior of tracing can be\ncustomized by subclassing Tracer, like so:, give an example?",
        "Id": 789,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " TheTracerclass is the class that underlies the\nimplementation ofsymbolic_trace. The behavior of tracing can be\ncustomized by subclassing Tracer, like so:"
    },
    {
        "Answer": "class MySpecialSubmodule(torch.nn.Module):\n    def forward(self, x):\n        return torch.neg(x)\n\nclass MyModule(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = torch.nn.Linear(3, 4)\n        self.submod = MySpecialSubmodule()\n\n    def forward(self, x):\n        return self.submod(self.linear(x))\n\ntraced = torch.fx.symbolic_trace(MyModule())\nprint(traced.code)\n# `linear` is preserved as a call, yet `submod` is traced though.\n# This is because the default set of \"Leaf Modules\" includes all\n# standard `torch.nn` modules.\n\"\"\"\nimport torch\ndef forward(self, x):\n    linear_1 = self.linear(x);  x = None\n    neg_1 = torch.neg(linear_1);  linear_1 = None\n    return neg_1\n\"\"\"\n",
        "Question": "How to use Leaf Modules are the modules that appear as calls in the symbolic trace\nrather than being traced through. The default set of leaf modules is the\nset of standardtorch.nnmodule instances. For example:, give an example?",
        "Id": 790,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Leaf Modules are the modules that appear as calls in the symbolic trace\nrather than being traced through. The default set of leaf modules is the\nset of standardtorch.nnmodule instances. For example:"
    },
    {
        "Answer": "@torch.fx.wrap\ndef torch_randn(x, shape):\n    return torch.randn(shape)\n\ndef f(x):\n    return x + torch_randn(x, 5)\nfx.symbolic_trace(f)\n",
        "Question": "How to use Miscellanea, give an example?",
        "Id": 791,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " "
    },
    {
        "Answer": "def f(a, b):\n    if b == True:\n        return a\n    else:\n        return a*2\n",
        "Question": "How to use torch.fx.symbolic_trace, give an example?",
        "Id": 792,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " concrete_argsallows you to partially specialize your function, whether it\u2019s to remove control flow or data structures.For example:"
    },
    {
        "Answer": "def f(x):\n    out = 0\n    for v in x.values():\n        out += v\n    return out\nf = fx.symbolic_trace(f, concrete_args={'x': {'a': fx.PH, 'b': fx.PH, 'c': fx.PH}})\nassert f({'a': 1, 'b': 2, 'c': 4}) == 7\n",
        "Question": "How  Note that although you can still pass in different values ofb, they will be ignored.We can also useconcrete_argsto eliminate data-structure handling from\nour function. This will use pytrees to flatten your input. To avoid\noverspecializing, pass infx.PHfor values that shouldn\u2019t be\nspecialized. For example:, give an example?",
        "Id": 793,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Note that although you can still pass in different values ofb, they will be ignored.We can also useconcrete_argsto eliminate data-structure handling from\nour function. This will use pytrees to flatten your input. To avoid\noverspecializing, pass infx.PHfor values that shouldn\u2019t be\nspecialized. For example:"
    },
    {
        "Answer": "# foo/bar/baz.py\ndef my_custom_function(x, y):\n    return x * x + y * y\n\ntorch.fx.wrap('my_custom_function')\n\ndef fn_to_be_traced(x, y):\n    # When symbolic tracing, the below call to my_custom_function will be inserted into\n    # the graph rather than tracing it.\n    return my_custom_function(x, y)\n",
        "Question": "How to use torch.fx.wrap, give an example?",
        "Id": 794,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " This function can be called at module-level scope to register fn_or_name as a \u201cleaf function\u201d.\nA \u201cleaf function\u201d will be preserved as a CallFunction node in the FX trace instead of being\ntraced through:"
    },
    {
        "Answer": "# foo/bar/baz.py\n@torch.fx.wrap\ndef my_custom_function(x, y):\n    return x * x + y * y\n",
        "Question": "How  This function can also equivalently be used as a decorator:, give an example?",
        "Id": 795,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " This function can also equivalently be used as a decorator:"
    },
    {
        "Answer": "import torch\nimport torch.fx\n\nclass MyModule(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.param = torch.nn.Parameter(torch.rand(3, 4))\n        self.linear = torch.nn.Linear(4, 5)\n\n    def forward(self, x):\n        return torch.topk(torch.sum(self.linear(x + self.linear.weight).relu(), dim=-1), 3)\n\nm = MyModule()\ngm = torch.fx.symbolic_trace(m)\n",
        "Question": "How to use For example, the following code, give an example?",
        "Id": 796,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " For example, the following code"
    },
    {
        "Answer": "print(gm.graph)\n",
        "Question": "How to use Will produce the following Graph:, give an example?",
        "Id": 797,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " For example, the following codeWill produce the following Graph:"
    },
    {
        "Answer": "graph(x):\n    %linear_weight : [#users=1] = self.linear.weight\n    %add_1 : [#users=1] = call_function[target=operator.add](args = (%x, %linear_weight), kwargs = {})\n    %linear_1 : [#users=1] = call_module[target=linear](args = (%add_1,), kwargs = {})\n    %relu_1 : [#users=1] = call_method[target=relu](args = (%linear_1,), kwargs = {})\n    %sum_1 : [#users=1] = call_function[target=torch.sum](args = (%relu_1,), kwargs = {dim: -1})\n    %topk_1 : [#users=1] = call_function[target=torch.topk](args = (%sum_1, 3), kwargs = {})\n    return topk_1\n",
        "Question": "How to use API Reference, give an example?",
        "Id": 798,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " "
    },
    {
        "Answer": "def forward(self, x):\n    a = x + 1\n    return x + self.attr_1\n",
        "Question": "How to use torch.fx.Graph.eliminate_dead_code, give an example?",
        "Id": 799,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Before dead code is eliminated,afroma = x + 1below has no users\nand thus can be eliminated from the graph without having an effect."
    },
    {
        "Answer": "def forward(self, x):\n    return x + self.attr_1\n",
        "Question": "How  Before dead code is eliminated,afroma = x + 1below has no users\nand thus can be eliminated from the graph without having an effect.After dead code is eliminated,a = x + 1has been removed, and the rest\nofforwardremains., give an example?",
        "Id": 800,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Before dead code is eliminated,afroma = x + 1below has no users\nand thus can be eliminated from the graph without having an effect.After dead code is eliminated,a = x + 1has been removed, and the rest\nofforwardremains."
    },
    {
        "Answer": "with g.inserting_after(n):\n    ... # inserting after node n\n... # insert point restored to what it was previously\ng.inserting_after(n) #  set the insert point permanently\n",
        "Question": "How to use torch.fx.Graph.inserting_after, give an example?",
        "Id": 801,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Set the point at which create_node and companion methods will insert into the graph.\nWhen used within a \u2018with\u2019 statement, this will temporary set the insert point and\nthen restore it when the with statement exits:"
    },
    {
        "Answer": "with g.inserting_before(n):\n    ... # inserting before node n\n... # insert point restored to what it was previously\ng.inserting_before(n) #  set the insert point permanently\n",
        "Question": "How to use torch.fx.Graph.inserting_before, give an example?",
        "Id": 802,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Set the point at which create_node and companion methods will insert into the graph.\nWhen used within a \u2018with\u2019 statement, this will temporary set the insert point and\nthen restore it when the with statement exits:"
    },
    {
        "Answer": "# Copying all the nodes in `g` into `new_graph`\ng : torch.fx.Graph = ...\nnew_graph = torch.fx.graph()\nvalue_remap = {}\nfor node in g.nodes:\n    value_remap[node] = new_graph.node_copy(node, lambda n : value_remap[n])\n",
        "Question": "How to use torch.fx.Graph.node_copy, give an example?",
        "Id": 803,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " "
    },
    {
        "Answer": "Before: p -> self\n        bx -> x -> ax\nAfter:  p -> x -> self\n        bx -> ax\n",
        "Question": "How to use torch.fx.Node.prepend, give an example?",
        "Id": 804,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " "
    },
    {
        "Answer": "run()\n    +-- run_node\n        +-- placeholder()\n        +-- get_attr()\n        +-- call_function()\n        +-- call_method()\n        +-- call_module()\n        +-- output()\n",
        "Question": "How to use Methods in the Interpreter class can be overridden to customize\nthe behavior of execution. The map of overrideable methods\nin terms of call hierarchy:, give an example?",
        "Id": 805,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Methods in the Interpreter class can be overridden to customize\nthe behavior of execution. The map of overrideable methods\nin terms of call hierarchy:"
    },
    {
        "Answer": "class NegSigmSwapInterpreter(Interpreter):\n    def call_function(self, target : Target,\n                      args : Tuple, kwargs : Dict) -> Any:\n        if target == torch.sigmoid:\n            return torch.neg(*args, **kwargs)\n        return super().call_function(n)\n\n    def call_method(self, target : Target,\n                    args : Tuple, kwargs : Dict) -> Any:\n        if target == 'neg':\n            call_self, *args_tail = args\n            return call_self.sigmoid(*args_tail, **kwargs)\n        return super().call_method(n)\n\ndef fn(x):\n    return torch.sigmoid(x).neg()\n\ngm = torch.fx.symbolic_trace(fn)\ninput = torch.randn(3, 4)\nresult = NegSigmSwapInterpreter(gm).run(input)\ntorch.testing.assert_allclose(result, torch.neg(input).sigmoid())\n",
        "Question": "How to use Suppose we want to swap all instances oftorch.negwithtorch.sigmoidand vice versa (including theirTensormethod equivalents). We could subclass Interpreter like so:, give an example?",
        "Id": 806,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Suppose we want to swap all instances oftorch.negwithtorch.sigmoidand vice versa (including theirTensormethod equivalents). We could subclass Interpreter like so:"
    },
    {
        "Answer": "class NegSigmSwapXformer(Transformer):\n    def call_function(self, target : 'Target', args : Tuple[Argument, ...], kwargs : Dict[str, Any]) -> Any:\n        if target == torch.sigmoid:\n            return torch.neg(*args, **kwargs)\n        return super().call_function(n)\n\n    def call_method(self, target : 'Target', args : Tuple[Argument, ...], kwargs : Dict[str, Any]) -> Any:\n        if target == 'neg':\n            call_self, *args_tail = args\n            return call_self.sigmoid(*args_tail, **kwargs)\n        return super().call_method(n)\n\ndef fn(x):\n    return torch.sigmoid(x).neg()\n\ngm = torch.fx.symbolic_trace(fn)\n\ntransformed : torch.nn.Module = NegSigmSwapXformer(gm).transform()\ninput = torch.randn(3, 4)\ntorch.testing.assert_allclose(transformed(input), torch.neg(input).sigmoid())\n",
        "Question": "How to use Suppose we want to swap all instances oftorch.negwithtorch.sigmoidand vice versa (including theirTensormethod equivalents). We could subclassTransformerlike so:, give an example?",
        "Id": 807,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " Suppose we want to swap all instances oftorch.negwithtorch.sigmoidand vice versa (including theirTensormethod equivalents). We could subclassTransformerlike so:"
    },
    {
        "Answer": "class Match(NamedTuple):\n    # Node from which the match was found\n    anchor: Node\n    # Maps nodes in the pattern subgraph to nodes in the larger graph\n    nodes_map: Dict[Node, Node]\n",
        "Question": "How to use torch.fx.replace_pattern, give an example?",
        "Id": 808,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " A list ofMatchobjects representing the places\nin the original graph thatpatternwas matched to. The list\nis empty if there are no matches.Matchis defined as:"
    },
    {
        "Answer": "import torch\nfrom torch.fx import symbolic_trace, subgraph_rewriter\n\nclass M(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x, w1, w2):\n        m1 = torch.cat([w1, w2]).sum()\n        m2 = torch.cat([w1, w2]).sum()\n        return x + torch.max(m1) + torch.max(m2)\n\ndef pattern(w1, w2):\n    return torch.cat([w1, w2]).sum()\n\ndef replacement(w1, w2):\n    return torch.stack([w1, w2])\n\ntraced_module = symbolic_trace(M())\n\nsubgraph_rewriter.replace_pattern(traced_module, pattern, replacement)\n",
        "Question": "How  , give an example?",
        "Id": 809,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " "
    },
    {
        "Answer": "def pattern(x, y):\n    return torch.neg(x) + torch.relu(y)\n",
        "Question": "How  When the pattern is matched, it will be removed from the larger\nfunction and replaced byreplacement. If there are multiple\nmatches forpatternin the larger function, each non-overlapping\nmatch will be replaced. In the case of a match overlap, the first\nfound match in the set of overlapping matches will be replaced.\n(\u201cFirst\u201d here being defined as the first in a topological ordering\nof the Nodes\u2019 use-def relationships. In most cases, the first Node\nis the parameter that appears directly afterself, while the\nlast Node is whatever the function returns.)One important thing to note is that the parameters of thepatternCallable must be used in the Callable itself,\nand the parameters of thereplacementCallable must match\nthe pattern. The first rule is why, in the above code block, theforwardfunction has parametersx,w1,w2, but thepatternfunction only has parametersw1,w2.patterndoesn\u2019t usex, so it shouldn\u2019t specifyxas a parameter.\nAs an example of the second rule, consider replacing, give an example?",
        "Id": 810,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " When the pattern is matched, it will be removed from the larger\nfunction and replaced byreplacement. If there are multiple\nmatches forpatternin the larger function, each non-overlapping\nmatch will be replaced. In the case of a match overlap, the first\nfound match in the set of overlapping matches will be replaced.\n(\u201cFirst\u201d here being defined as the first in a topological ordering\nof the Nodes\u2019 use-def relationships. In most cases, the first Node\nis the parameter that appears directly afterself, while the\nlast Node is whatever the function returns.)One important thing to note is that the parameters of thepatternCallable must be used in the Callable itself,\nand the parameters of thereplacementCallable must match\nthe pattern. The first rule is why, in the above code block, theforwardfunction has parametersx,w1,w2, but thepatternfunction only has parametersw1,w2.patterndoesn\u2019t usex, so it shouldn\u2019t specifyxas a parameter.\nAs an example of the second rule, consider replacing"
    },
    {
        "Answer": "def replacement(x, y):\n    return torch.relu(x)\n",
        "Question": "How  One important thing to note is that the parameters of thepatternCallable must be used in the Callable itself,\nand the parameters of thereplacementCallable must match\nthe pattern. The first rule is why, in the above code block, theforwardfunction has parametersx,w1,w2, but thepatternfunction only has parametersw1,w2.patterndoesn\u2019t usex, so it shouldn\u2019t specifyxas a parameter.\nAs an example of the second rule, consider replacingwith, give an example?",
        "Id": 811,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " One important thing to note is that the parameters of thepatternCallable must be used in the Callable itself,\nand the parameters of thereplacementCallable must match\nthe pattern. The first rule is why, in the above code block, theforwardfunction has parametersx,w1,w2, but thepatternfunction only has parametersw1,w2.patterndoesn\u2019t usex, so it shouldn\u2019t specifyxas a parameter.\nAs an example of the second rule, consider replacingwith"
    },
    {
        "Answer": "def forward(self, x, w1, w2):\n    stack_1 = torch.stack([w1, w2])\n    sum_1 = stack_1.sum()\n    stack_2 = torch.stack([w1, w2])\n    sum_2 = stack_2.sum()\n    max_1 = torch.max(sum_1)\n    add_1 = x + max_1\n    max_2 = torch.max(sum_2)\n    add_2 = add_1 + max_2\n    return add_2\n",
        "Question": "How  In this case,replacementneeds the same number of parameters\naspattern(bothxandy), even though the parameteryisn\u2019t used inreplacement.After callingsubgraph_rewriter.replace_pattern, the generated\nPython code looks like this:, give an example?",
        "Id": 812,
        "source": "https://pytorch.org/docs/stable/fx.html",
        "context": " In this case,replacementneeds the same number of parameters\naspattern(bothxandy), even though the parameteryisn\u2019t used inreplacement.After callingsubgraph_rewriter.replace_pattern, the generated\nPython code looks like this:"
    },
    {
        "Answer": ">>> a = torch.arange(10).reshape(5,2)\n>>> a\ntensor([[0, 1],\n        [2, 3],\n        [4, 5],\n        [6, 7],\n        [8, 9]])\n>>> torch.split(a, 2)\n(tensor([[0, 1],\n         [2, 3]]),\n tensor([[4, 5],\n         [6, 7]]),\n tensor([[8, 9]]))\n>>> torch.split(a, [1,4])\n(tensor([[0, 1]]),\n tensor([[2, 3],\n         [4, 5],\n         [6, 7],\n         [8, 9]]))\n",
        "Question": "How to use torch.split, give an example?",
        "Id": 813,
        "source": "https://pytorch.org/docs/stable/generated/torch.split.html#torch.split",
        "context": " Ifsplit_size_or_sectionsis a list, thentensorwill be split\nintolen(split_size_or_sections)chunks with sizes indimaccording\ntosplit_size_or_sections."
    },
    {
        "Answer": ">>> a = torch.tensor([0.7, -1.2, 0., 2.3])\n>>> a\ntensor([ 0.7000, -1.2000,  0.0000,  2.3000])\n>>> torch.sign(a)\ntensor([ 1., -1.,  0.,  1.])\n",
        "Question": "How to use torch.sign, give an example?",
        "Id": 814,
        "source": "https://pytorch.org/docs/stable/generated/torch.sign.html#torch.sign",
        "context": " "
    },
    {
        "Answer": ">>> from setuptools import setup\n>>> from torch.utils.cpp_extension import BuildExtension, CppExtension\n>>> setup(\n        name='extension',\n        ext_modules=[\n            CppExtension(\n                name='extension',\n                sources=['extension.cpp'],\n                extra_compile_args=['-g']),\n        ],\n        cmdclass={\n            'build_ext': BuildExtension\n        })\n",
        "Question": "How to use torch.utils.cpp_extension.CppExtension, give an example?",
        "Id": 815,
        "source": "https://pytorch.org/docs/stable/cpp_extension.html",
        "context": " All arguments are forwarded to thesetuptools.Extensionconstructor."
    },
    {
        "Answer": ">>> from setuptools import setup\n>>> from torch.utils.cpp_extension import BuildExtension, CUDAExtension\n>>> setup(\n        name='cuda_extension',\n        ext_modules=[\n            CUDAExtension(\n                    name='cuda_extension',\n                    sources=['extension.cpp', 'extension_kernel.cu'],\n                    extra_compile_args={'cxx': ['-g'],\n                                        'nvcc': ['-O2']})\n        ],\n        cmdclass={\n            'build_ext': BuildExtension\n        })\n",
        "Question": "How to use torch.utils.cpp_extension.CUDAExtension, give an example?",
        "Id": 816,
        "source": "https://pytorch.org/docs/stable/cpp_extension.html",
        "context": " All arguments are forwarded to thesetuptools.Extensionconstructor."
    },
    {
        "Answer": ">>> from torch.utils.cpp_extension import load\n>>> module = load(\n        name='extension',\n        sources=['extension.cpp', 'extension_kernel.cu'],\n        extra_cflags=['-O2'],\n        verbose=True)\n",
        "Question": "How to use torch.utils.cpp_extension.load, give an example?",
        "Id": 817,
        "source": "https://pytorch.org/docs/stable/cpp_extension.html",
        "context": " CUDA support with mixed compilation is provided. Simply pass CUDA source\nfiles (.cuor.cuh) along with other sources. Such files will be\ndetected and compiled with nvcc rather than the C++ compiler. This includes\npassing the CUDA lib64 directory as a library directory, and linkingcudart. You can pass additional flags to nvcc viaextra_cuda_cflags, just like withextra_cflagsfor C++. Various\nheuristics for finding the CUDA install directory are used, which usually\nwork fine. If not, setting theCUDA_HOMEenvironment variable is the\nsafest option."
    },
    {
        "Answer": ">>> from torch.utils.cpp_extension import load_inline\n>>> source = \\'\\'\\'\nat::Tensor sin_add(at::Tensor x, at::Tensor y) {\n  return x.sin() + y.sin();\n}\n\\'\\'\\'\n>>> module = load_inline(name='inline_extension',\n                         cpp_sources=[source],\n                         functions=['sin_add'])\n",
        "Question": "How to use torch.utils.cpp_extension.load_inline, give an example?",
        "Id": 818,
        "source": "https://pytorch.org/docs/stable/cpp_extension.html",
        "context": " Seeload()for a description of arguments omitted below."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 819,
        "source": "https://pytorch.org/docs/stable/torch.html#other-operations",
        "context": " "
    },
    {
        "Answer": ">>> x = torch.tensor([1, 2, 3])\n>>> x.repeat_interleave(2)\ntensor([1, 1, 2, 2, 3, 3])\n>>> y = torch.tensor([[1, 2], [3, 4]])\n>>> torch.repeat_interleave(y, 2)\ntensor([1, 1, 2, 2, 3, 3, 4, 4])\n>>> torch.repeat_interleave(y, 3, dim=1)\ntensor([[1, 1, 1, 2, 2, 2],\n        [3, 3, 3, 4, 4, 4]])\n>>> torch.repeat_interleave(y, torch.tensor([1, 2]), dim=0)\ntensor([[1, 2],\n        [3, 4],\n        [3, 4]])\n",
        "Question": "How to use torch.repeat_interleave, give an example?",
        "Id": 820,
        "source": "https://pytorch.org/docs/stable/generated/torch.repeat_interleave.html#torch.repeat_interleave",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.0202,  1.0985,  1.3506, -0.6056])\n>>> torch.add(a, 20)\ntensor([ 20.0202,  21.0985,  21.3506,  19.3944])\n",
        "Question": "How to use torch.add, give an example?",
        "Id": 821,
        "source": "https://pytorch.org/docs/stable/generated/torch.add.html#torch.add",
        "context": " Ifinputis of type FloatTensor or DoubleTensor,othermust be\na real number, otherwise it should be an integer."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([-0.9732, -0.3497,  0.6245,  0.4022])\n>>> b = torch.randn(4, 1)\n>>> b\ntensor([[ 0.3743],\n        [-1.7724],\n        [-0.5811],\n        [-0.8017]])\n>>> torch.add(a, b, alpha=10)\ntensor([[  2.7695,   3.3930,   4.3672,   4.1450],\n        [-18.6971, -18.0736, -17.0994, -17.3216],\n        [ -6.7845,  -6.1610,  -5.1868,  -5.4090],\n        [ -8.9902,  -8.3667,  -7.3925,  -7.6147]])\n",
        "Question": "How  Ifotheris of type FloatTensor or DoubleTensor,alphamust be\na real number, otherwise it should be an integer., give an example?",
        "Id": 822,
        "source": "https://pytorch.org/docs/stable/generated/torch.add.html#torch.add",
        "context": " Ifotheris of type FloatTensor or DoubleTensor,alphamust be\na real number, otherwise it should be an integer."
    },
    {
        "Answer": ">>> mat1 = torch.eye(2)\n>>> mat2 = torch.ones(2, 2)\n>>> torch.kron(mat1, mat2)\ntensor([[1., 1., 0., 0.],\n        [1., 1., 0., 0.],\n        [0., 0., 1., 1.],\n        [0., 0., 1., 1.]])\n\n>>> mat1 = torch.eye(2)\n>>> mat2 = torch.arange(1, 5).reshape(2, 2)\n>>> torch.kron(mat1, mat2)\ntensor([[1., 2., 0., 0.],\n        [3., 4., 0., 0.],\n        [0., 0., 1., 2.],\n        [0., 0., 3., 4.]])\n",
        "Question": "How to use torch.kron, give an example?",
        "Id": 823,
        "source": "https://pytorch.org/docs/stable/generated/torch.kron.html#torch.kron",
        "context": " Supports real-valued and complex-valued inputs."
    },
    {
        "Answer": ">>> import numpy as np\n>>> abs = torch.tensor([1, 2], dtype=torch.float64)\n>>> angle = torch.tensor([np.pi / 2, 5 * np.pi / 4], dtype=torch.float64)\n>>> z = torch.polar(abs, angle)\n>>> z\ntensor([(0.0000+1.0000j), (-1.4142-1.4142j)], dtype=torch.complex128)\n",
        "Question": "How to use torch.polar, give an example?",
        "Id": 824,
        "source": "https://pytorch.org/docs/stable/generated/torch.polar.html#torch.polar",
        "context": " "
    },
    {
        "Answer": ">>> torch.use_deterministic_algorithms(True)\n\n# Forward mode nondeterministic error\n>>> torch.randn(10).index_copy(0, torch.tensor([0]), torch.randn(1))\n...\nRuntimeError: index_copy does not have a deterministic implementation...\n\n# Backward mode nondeterministic error\n>>> torch.randn(10, requires_grad=True, device='cuda').index_select(0, torch.tensor([0], device='cuda')).backward()\n...\nRuntimeError: index_add_cuda_ does not have a deterministic implementation...\n",
        "Question": "How to use torch.use_deterministic_algorithms, give an example?",
        "Id": 825,
        "source": "https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html#torch.use_deterministic_algorithms",
        "context": " Note that deterministic operations tend to have worse performance than\nnondeterministic operations."
    },
    {
        "Answer": ">>> t = torch.randn(1, 3)\n>>> t1 = torch.randn(3, 1)\n>>> t2 = torch.randn(1, 3)\n>>> torch.addcmul(t, t1, t2, value=0.1)\ntensor([[-0.8635, -0.6391,  1.6174],\n        [-0.7617, -0.5879,  1.7388],\n        [-0.8353, -0.6249,  1.6511]])\n",
        "Question": "How to use torch.addcmul, give an example?",
        "Id": 826,
        "source": "https://pytorch.org/docs/stable/generated/torch.addcmul.html#torch.addcmul",
        "context": " For inputs of typeFloatTensororDoubleTensor,valuemust be\na real number, otherwise an integer."
    },
    {
        "Answer": ">>> a = torch.tensor([9.7, float('nan'), 3.1, float('nan')])\n>>> b = torch.tensor([-2.2, 0.5, float('nan'), float('nan')])\n>>> torch.fmax(a, b)\ntensor([9.7000, 0.5000, 3.1000,    nan])\n",
        "Question": "How to use torch.fmax, give an example?",
        "Id": 827,
        "source": "https://pytorch.org/docs/stable/generated/torch.fmax.html#torch.fmax",
        "context": " Supportsbroadcasting to a common shape,type promotion, and integer and floating-point inputs."
    },
    {
        "Answer": ">>> x = torch.arange(8)\n>>> torch.tensor_split(x, 3)\n(tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7]))\n\n>>> x = torch.arange(7)\n>>> torch.tensor_split(x, 3)\n(tensor([0, 1, 2]), tensor([3, 4]), tensor([5, 6]))\n>>> torch.tensor_split(x, (1, 6))\n(tensor([0]), tensor([1, 2, 3, 4, 5]), tensor([6]))\n\n>>> x = torch.arange(14).reshape(2, 7)\n>>> x\ntensor([[ 0,  1,  2,  3,  4,  5,  6],\n        [ 7,  8,  9, 10, 11, 12, 13]])\n>>> torch.tensor_split(x, 3, dim=1)\n(tensor([[0, 1, 2],\n        [7, 8, 9]]),\n tensor([[ 3,  4],\n        [10, 11]]),\n tensor([[ 5,  6],\n        [12, 13]]))\n>>> torch.tensor_split(x, (1, 6), dim=1)\n(tensor([[0],\n        [7]]),\n tensor([[ 1,  2,  3,  4,  5],\n        [ 8,  9, 10, 11, 12]]),\n tensor([[ 6],\n        [13]]))\n",
        "Question": "How to use torch.tensor_split, give an example?",
        "Id": 828,
        "source": "https://pytorch.org/docs/stable/generated/torch.tensor_split.html#torch.tensor_split",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([[-0.8166, -1.3802, -0.3560]])\n>>> torch.std(a, unbiased=False)\ntensor(0.4188)\n",
        "Question": "How to use torch.std, give an example?",
        "Id": 829,
        "source": "https://pytorch.org/docs/stable/generated/torch.std.html#torch.std",
        "context": " IfunbiasedisTrue, Bessel\u2019s correction will be used.\nOtherwise, the sample deviation is calculated, without any correction."
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 1.4309,  1.2706, -0.8562,  0.9796])\n>>> torch.cos(a)\ntensor([ 0.1395,  0.2957,  0.6553,  0.5574])\n",
        "Question": "How to use torch.cos, give an example?",
        "Id": 830,
        "source": "https://pytorch.org/docs/stable/generated/torch.cos.html#torch.cos",
        "context": " "
    },
    {
        "Answer": "# original model\n# all tensors and computations are in floating point\nprevious_layer_fp32 -- linear_fp32 -- activation_fp32 -- next_layer_fp32\n                 /\nlinear_weight_fp32\n\n# dynamically quantized model\n# linear and LSTM weights are in int8\nprevious_layer_fp32 -- linear_int8_w_fp32_inp -- activation_fp32 -- next_layer_fp32\n                     /\n   linear_weight_int8\n",
        "Question": "How to use This is the simplest to apply form of quantization where the weights are\nquantized ahead of time but the activations are dynamically quantized\nduring inference. This is used for situations where the model execution time\nis dominated by loading weights from memory rather than computing the matrix\nmultiplications. This is true for for LSTM and Transformer type models with\nsmall batch size.Diagram:, give an example?",
        "Id": 831,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " Diagram:"
    },
    {
        "Answer": "import torch\n\n# define a floating point model\nclass M(torch.nn.Module):\n    def __init__(self):\n        super(M, self).__init__()\n        self.fc = torch.nn.Linear(4, 4)\n\n    def forward(self, x):\n        x = self.fc(x)\n        return x\n\n# create a model instance\nmodel_fp32 = M()\n# create a quantized model instance\nmodel_int8 = torch.quantization.quantize_dynamic(\n    model_fp32,  # the original model\n    {torch.nn.Linear},  # a set of layers to dynamically quantize\n    dtype=torch.qint8)  # the target dtype for quantized weights\n\n# run the model\ninput_fp32 = torch.randn(4, 4, 4, 4)\nres = model_int8(input_fp32)\n",
        "Question": "How to use Diagram:API example:, give an example?",
        "Id": 832,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " Diagram:API example:"
    },
    {
        "Answer": "# original model\n# all tensors and computations are in floating point\nprevious_layer_fp32 -- linear_fp32 -- activation_fp32 -- next_layer_fp32\n                    /\n    linear_weight_fp32\n\n# statically quantized model\n# weights and activations are in int8\nprevious_layer_int8 -- linear_with_activation_int8 -- next_layer_int8\n                    /\n  linear_weight_int8\n",
        "Question": "How to use Static quantization quantizes the weights and activations of the model.  It\nfuses activations into preceding layers where possible.  It requires\ncalibration with a representative dataset to determine optimal quantization\nparameters for activations. Post Training Quantization is typically used when\nboth memory bandwidth and compute savings are important with CNNs being a\ntypical use case.  Static quantization is also known as Post Training\nQuantization or PTQ.Diagram:, give an example?",
        "Id": 833,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " Diagram:"
    },
    {
        "Answer": "import torch\n\n# define a floating point model where some layers could be statically quantized\nclass M(torch.nn.Module):\n    def __init__(self):\n        super(M, self).__init__()\n        # QuantStub converts tensors from floating point to quantized\n        self.quant = torch.quantization.QuantStub()\n        self.conv = torch.nn.Conv2d(1, 1, 1)\n        self.relu = torch.nn.ReLU()\n        # DeQuantStub converts tensors from quantized to floating point\n        self.dequant = torch.quantization.DeQuantStub()\n\n    def forward(self, x):\n        # manually specify where tensors will be converted from floating\n        # point to quantized in the quantized model\n        x = self.quant(x)\n        x = self.conv(x)\n        x = self.relu(x)\n        # manually specify where tensors will be converted from quantized\n        # to floating point in the quantized model\n        x = self.dequant(x)\n        return x\n\n# create a model instance\nmodel_fp32 = M()\n\n# model must be set to eval mode for static quantization logic to work\nmodel_fp32.eval()\n\n# attach a global qconfig, which contains information about what kind\n# of observers to attach. Use 'fbgemm' for server inference and\n# 'qnnpack' for mobile inference. Other quantization configurations such\n# as selecting symmetric or assymetric quantization and MinMax or L2Norm\n# calibration techniques can be specified here.\nmodel_fp32.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n\n# Fuse the activations to preceding layers, where applicable.\n# This needs to be done manually depending on the model architecture.\n# Common fusions include `conv + relu` and `conv + batchnorm + relu`\nmodel_fp32_fused = torch.quantization.fuse_modules(model_fp32, [['conv', 'relu']])\n\n# Prepare the model for static quantization. This inserts observers in\n# the model that will observe activation tensors during calibration.\nmodel_fp32_prepared = torch.quantization.prepare(model_fp32_fused)\n\n# calibrate the prepared model to determine quantization parameters for activations\n# in a real world setting, the calibration would be done with a representative dataset\ninput_fp32 = torch.randn(4, 1, 4, 4)\nmodel_fp32_prepared(input_fp32)\n\n# Convert the observed model to a quantized model. This does several things:\n# quantizes the weights, computes and stores the scale and bias value to be\n# used with each activation tensor, and replaces key operators with quantized\n# implementations.\nmodel_int8 = torch.quantization.convert(model_fp32_prepared)\n\n# run the model, relevant calculations will happen in int8\nres = model_int8(input_fp32)\n",
        "Question": "How to use Diagram:, give an example?",
        "Id": 834,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " Diagram:"
    },
    {
        "Answer": "# original model\n# all tensors and computations are in floating point\nprevious_layer_fp32 -- linear_fp32 -- activation_fp32 -- next_layer_fp32\n                      /\n    linear_weight_fp32\n\n# model with fake_quants for modeling quantization numerics during training\nprevious_layer_fp32 -- fq -- linear_fp32 -- activation_fp32 -- fq -- next_layer_fp32\n                           /\n   linear_weight_fp32 -- fq\n\n# quantized model\n# weights and activations are in int8\nprevious_layer_int8 -- linear_with_activation_int8 -- next_layer_int8\n                     /\n   linear_weight_int8\n",
        "Question": "How to use Quantization Aware Training models the effects of quantization during training\nallowing for higher accuracy compared to other quantization methods.  During\ntraining, all calculations are done in floating point, with fake_quant modules\nmodeling the effects of quantization by clamping and rounding to simulate the\neffects of INT8.  After model conversion, weights and\nactivations are quantized, and activations are fused into the preceding layer\nwhere possible.  It is commonly used with CNNs and yields a higher accuracy\ncompared to static quantization.  Quantization Aware Training is also known as\nQAT.Diagram:, give an example?",
        "Id": 835,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " Diagram:"
    },
    {
        "Answer": "import torch\n\n# define a floating point model where some layers could benefit from QAT\nclass M(torch.nn.Module):\n    def __init__(self):\n        super(M, self).__init__()\n        # QuantStub converts tensors from floating point to quantized\n        self.quant = torch.quantization.QuantStub()\n        self.conv = torch.nn.Conv2d(1, 1, 1)\n        self.bn = torch.nn.BatchNorm2d(1)\n        self.relu = torch.nn.ReLU()\n        # DeQuantStub converts tensors from quantized to floating point\n        self.dequant = torch.quantization.DeQuantStub()\n\n    def forward(self, x):\n        x = self.quant(x)\n        x = self.conv(x)\n        x = self.bn(x)\n        x = self.relu(x)\n        x = self.dequant(x)\n        return x\n\n# create a model instance\nmodel_fp32 = M()\n\n# model must be set to train mode for QAT logic to work\nmodel_fp32.train()\n\n# attach a global qconfig, which contains information about what kind\n# of observers to attach. Use 'fbgemm' for server inference and\n# 'qnnpack' for mobile inference. Other quantization configurations such\n# as selecting symmetric or assymetric quantization and MinMax or L2Norm\n# calibration techniques can be specified here.\nmodel_fp32.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n\n# fuse the activations to preceding layers, where applicable\n# this needs to be done manually depending on the model architecture\nmodel_fp32_fused = torch.quantization.fuse_modules(model_fp32,\n    [['conv', 'bn', 'relu']])\n\n# Prepare the model for QAT. This inserts observers and fake_quants in\n# the model that will observe weight and activation tensors during calibration.\nmodel_fp32_prepared = torch.quantization.prepare_qat(model_fp32_fused)\n\n# run the training loop (not shown)\ntraining_loop(model_fp32_prepared)\n\n# Convert the observed model to a quantized model. This does several things:\n# quantizes the weights, computes and stores the scale and bias value to be\n# used with each activation tensor, fuses modules where appropriate,\n# and replaces key operators with quantized implementations.\nmodel_fp32_prepared.eval()\nmodel_int8 = torch.quantization.convert(model_fp32_prepared)\n\n# run the model, relevant calculations will happen in int8\nres = model_int8(input_fp32)\n",
        "Question": "How  Diagram:, give an example?",
        "Id": 836,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " Diagram:"
    },
    {
        "Answer": "import torch.quantization.quantize_fx as quantize_fx\nimport copy\n\nmodel_fp = UserModel(...)\n\n#\n# post training dynamic/weight_only quantization\n#\n\n# we need to deepcopy if we still want to keep model_fp unchanged after quantization since quantization apis change the input model\nmodel_to_quantize = copy.deepcopy(model_fp)\nmodel_to_quantize.eval()\nqconfig_dict = {\"\": torch.quantization.default_dynamic_qconfig}\n# prepare\nmodel_prepared = quantize_fx.prepare_fx(model_to_quantize, qconfig_dict)\n# no calibration needed when we only have dynamici/weight_only quantization\n# quantize\nmodel_quantized = quantize_fx.convert_fx(model_prepared)\n\n#\n# post training static quantization\n#\n\nmodel_to_quantize = copy.deepcopy(model_fp)\nqconfig_dict = {\"\": torch.quantization.get_default_qconfig('qnnpack')}\nmodel_to_quantize.eval()\n# prepare\nmodel_prepared = quantize_fx.prepare_fx(model_to_quantize, qconfig_dict)\n# calibrate (not shown)\n# quantize\nmodel_quantized = quantize_fx.convert_fx(model_prepared)\n\n#\n# quantization aware training for static quantization\n#\n\nmodel_to_quantize = copy.deepcopy(model_fp)\nqconfig_dict = {\"\": torch.quantization.get_default_qat_qconfig('qnnpack')}\nmodel_to_quantize.train()\n# prepare\nmodel_prepared = quantize_fx.prepare_qat_fx(model_to_qunatize, qconfig_dict)\n# training loop (not shown)\n# quantize\nmodel_quantized = quantize_fx.convert_fx(model_prepared)\n\n#\n# fusion\n#\nmodel_to_quantize = copy.deepcopy(model_fp)\nmodel_fused = quantize_fx.fuse_fx(model_to_quantize)\n",
        "Question": "How to use There are multiple quantization types in post training quantization (weight only, dynamic and static) and the configuration is done throughqconfig_dict(an argument of theprepare_fxfunction)., give an example?",
        "Id": 837,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " There are multiple quantization types in post training quantization (weight only, dynamic and static) and the configuration is done throughqconfig_dict(an argument of theprepare_fxfunction)."
    },
    {
        "Answer": "RuntimeError: Could not run 'quantized::some_operator' with arguments from the 'CPU' backend...\n",
        "Question": "How to use If you see an error similar to:, give an example?",
        "Id": 838,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " If you see an error similar to:"
    },
    {
        "Answer": "class M(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.quant = torch.quantization.QuantStub()\n        self.conv = torch.nn.Conv2d(1, 1, 1)\n\n    def forward(self, x):\n        # during the convert step, this will be replaced with a\n        # `quantize_per_tensor` call\n        x = self.quant(x)\n        x = self.conv(x)\n        return x\n",
        "Question": "How to use If you see an error similar to:This means that you are trying to pass a non-quantized Tensor to a quantized\nkernel. A common workaround is to usetorch.quantization.QuantStubto\nquantize the tensor.  This needs to be done manually in Eager mode quantization.\nAn e2e example:, give an example?",
        "Id": 839,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " This means that you are trying to pass a non-quantized Tensor to a quantized\nkernel. A common workaround is to usetorch.quantization.QuantStubto\nquantize the tensor.  This needs to be done manually in Eager mode quantization.\nAn e2e example:"
    },
    {
        "Answer": "RuntimeError: Could not run 'aten::thnn_conv2d_forward' with arguments from the 'QuantizedCPU' backend.\n",
        "Question": "How  If you see an error similar to:, give an example?",
        "Id": 840,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " If you see an error similar to:"
    },
    {
        "Answer": "class M(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.quant = torch.quantization.QuantStub()\n        self.conv1 = torch.nn.Conv2d(1, 1, 1)\n        # this module will not be quantized (see `qconfig = None` logic below)\n        self.conv2 = torch.nn.Conv2d(1, 1, 1)\n        self.dequant = torch.quantization.DeQuantStub()\n\n    def forward(self, x):\n        # during the convert step, this will be replaced with a\n        # `quantize_per_tensor` call\n        x = self.quant(x)\n        x = self.conv1(x)\n        # during the convert step, this will be replaced with a\n        # `dequantize` call\n        x = self.dequant(x)\n        x = self.conv2(x)\n        return x\n\nm = M()\nm.qconfig = some_qconfig\n# turn off quantization for conv2\nm.conv2.qconfig = None\n",
        "Question": "How to use If you see an error similar to:This means that you are trying to pass a quantized Tensor to a non-quantized\nkernel. A common workaround is to usetorch.quantization.DeQuantStubto\ndequantize the tensor.  This needs to be done manually in Eager mode quantization.\nAn e2e example:, give an example?",
        "Id": 841,
        "source": "https://pytorch.org/docs/stable/quantization.html",
        "context": " This means that you are trying to pass a quantized Tensor to a non-quantized\nkernel. A common workaround is to usetorch.quantization.DeQuantStubto\ndequantize the tensor.  This needs to be done manually in Eager mode quantization.\nAn e2e example:"
    },
    {
        "Answer": ">>> x = torch.randn(4)\n>>> x\ntensor([ 0.0552,  0.9730,  0.3973, -1.0780])\n>>> torch.fake_quantize_per_tensor_affine(x, 0.1, 0, 0, 255)\ntensor([0.1000, 1.0000, 0.4000, 0.0000])\n",
        "Question": "How to use torch.fake_quantize_per_tensor_affine, give an example?",
        "Id": 842,
        "source": "https://pytorch.org/docs/stable/generated/torch.fake_quantize_per_tensor_affine.html#torch.fake_quantize_per_tensor_affine",
        "context": " "
    },
    {
        "Answer": ">>> M = torch.randn(10, 3, 5)\n>>> batch1 = torch.randn(10, 3, 4)\n>>> batch2 = torch.randn(10, 4, 5)\n>>> torch.baddbmm(M, batch1, batch2).size()\ntorch.Size([10, 3, 5])\n",
        "Question": "How to use torch.baddbmm, give an example?",
        "Id": 843,
        "source": "https://pytorch.org/docs/stable/generated/torch.baddbmm.html#torch.baddbmm",
        "context": " This operator supportsTensorFloat32."
    },
    {
        "Answer": ">>> torch.ge(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[True, True], [False, True]])\n",
        "Question": "How to use torch.ge, give an example?",
        "Id": 844,
        "source": "https://pytorch.org/docs/stable/generated/torch.ge.html#torch.ge",
        "context": " The second argument can be a number or a tensor whose shape isbroadcastablewith the first argument."
    },
    {
        "Answer": ">>> a = torch.rand(1, 2).bool()\n>>> a\ntensor([[False, True]], dtype=torch.bool)\n>>> torch.all(a)\ntensor(False, dtype=torch.bool)\n>>> a = torch.arange(0, 3)\n>>> a\ntensor([0, 1, 2])\n>>> torch.all(a)\ntensor(False)\n",
        "Question": "How to use torch.all, give an example?",
        "Id": 845,
        "source": "https://pytorch.org/docs/stable/generated/torch.all.html#torch.all",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.rand(4, 2).bool()\n>>> a\ntensor([[True, True],\n        [True, False],\n        [True, True],\n        [True, True]], dtype=torch.bool)\n>>> torch.all(a, dim=1)\ntensor([ True, False,  True,  True], dtype=torch.bool)\n>>> torch.all(a, dim=0)\ntensor([ True, False], dtype=torch.bool)\n",
        "Question": "How  IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput., give an example?",
        "Id": 846,
        "source": "https://pytorch.org/docs/stable/generated/torch.all.html#torch.all",
        "context": " IfkeepdimisTrue, the output tensor is of the same size\nasinputexcept in the dimensiondimwhere it is of size 1.\nOtherwise,dimis squeezed (seetorch.squeeze()), resulting in\nthe output tensor having 1 fewer dimension thaninput."
    },
    {
        "Answer": ">>> torch.dot(torch.tensor([2, 3]), torch.tensor([2, 1]))\ntensor(7)\n",
        "Question": "How to use torch.dot, give an example?",
        "Id": 847,
        "source": "https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot",
        "context": " "
    },
    {
        "Answer": "import torch\nimport torchvision\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision import datasets, transforms\n\n# Writer will output to ./runs/ directory by default\nwriter = SummaryWriter()\n\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\ntrainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\nmodel = torchvision.models.resnet50(False)\n# Have ResNet model take in grayscale rather than RGB\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\nimages, labels = next(iter(trainloader))\n\ngrid = torchvision.utils.make_grid(images)\nwriter.add_image('images', grid, 0)\nwriter.add_graph(model, images)\nwriter.close()\n",
        "Question": "How to use Once you\u2019ve installed TensorBoard, these utilities let you log PyTorch models\nand metrics into a directory for visualization within the TensorBoard UI.\nScalars, images, histograms, graphs, and embedding visualizations are all\nsupported for PyTorch models and tensors as well as Caffe2 nets and blobs.The SummaryWriter class is your main entry to log data for consumption\nand visualization by TensorBoard. For example:, give an example?",
        "Id": 848,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " Once you\u2019ve installed TensorBoard, these utilities let you log PyTorch models\nand metrics into a directory for visualization within the TensorBoard UI.\nScalars, images, histograms, graphs, and embedding visualizations are all\nsupported for PyTorch models and tensors as well as Caffe2 nets and blobs.The SummaryWriter class is your main entry to log data for consumption\nand visualization by TensorBoard. For example:"
    },
    {
        "Answer": "pip install tensorboard\ntensorboard --logdir=runs\n",
        "Question": "How to use The SummaryWriter class is your main entry to log data for consumption\nand visualization by TensorBoard. For example:This can then be visualized with TensorBoard, which should be installable\nand runnable with:, give an example?",
        "Id": 849,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " The SummaryWriter class is your main entry to log data for consumption\nand visualization by TensorBoard. For example:This can then be visualized with TensorBoard, which should be installable\nand runnable with:"
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\n\nwriter = SummaryWriter()\n\nfor n_iter in range(100):\n    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)\n",
        "Question": "How to use This can then be visualized with TensorBoard, which should be installable\nand runnable with:Lots of information can be logged for one experiment. To avoid cluttering\nthe UI and have better result clustering, we can group plots by naming them\nhierarchically. For example, \u201cLoss/train\u201d and \u201cLoss/test\u201d will be grouped\ntogether, while \u201cAccuracy/train\u201d and \u201cAccuracy/test\u201d will be grouped separately\nin the TensorBoard interface., give an example?",
        "Id": 850,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " This can then be visualized with TensorBoard, which should be installable\nand runnable with:Lots of information can be logged for one experiment. To avoid cluttering\nthe UI and have better result clustering, we can group plots by naming them\nhierarchically. For example, \u201cLoss/train\u201d and \u201cLoss/test\u201d will be grouped\ntogether, while \u201cAccuracy/train\u201d and \u201cAccuracy/test\u201d will be grouped separately\nin the TensorBoard interface."
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\n\n# create a summary writer with automatically generated folder name.\nwriter = SummaryWriter()\n# folder location: runs/May04_22-14-54_s-MacBook-Pro.local/\n\n# create a summary writer using the specified folder name.\nwriter = SummaryWriter(\"my_experiment\")\n# folder location: my_experiment\n\n# create a summary writer with comment appended.\nwriter = SummaryWriter(comment=\"LR_0.1_BATCH_16\")\n# folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.__init__, give an example?",
        "Id": 851,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\nx = range(100)\nfor i in x:\n    writer.add_scalar('y=2x', i * 2, i)\nwriter.close()\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_scalar, give an example?",
        "Id": 852,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\nr = 5\nfor i in range(100):\n    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n                                    'xcosx':i*np.cos(i/r),\n                                    'tanx': np.tan(i/r)}, i)\nwriter.close()\n# This call adds three values to the same scalar plot with the tag\n# 'run_14h' in TensorBoard's scalar section.\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_scalars, give an example?",
        "Id": 853,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nwriter = SummaryWriter()\nfor i in range(10):\n    x = np.random.random(1000)\n    writer.add_histogram('distribution centers', x + i, i)\nwriter.close()\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_histogram, give an example?",
        "Id": 854,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nimg = np.zeros((3, 100, 100))\nimg[0] = np.arange(0, 10000).reshape(100, 100) / 10000\nimg[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n\nimg_HWC = np.zeros((100, 100, 3))\nimg_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000\nimg_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n\nwriter = SummaryWriter()\nwriter.add_image('my_image', img, 0)\n\n# If you have non-default dimension setting, set the dataformats argument.\nwriter.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC')\nwriter.close()\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_image, give an example?",
        "Id": 855,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " Note that this requires thepillowpackage."
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\n\nimg_batch = np.zeros((16, 3, 100, 100))\nfor i in range(16):\n    img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i\n    img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i\n\nwriter = SummaryWriter()\nwriter.add_images('my_image_batch', img_batch, 0)\nwriter.close()\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_images, give an example?",
        "Id": 856,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " Note that this requires thepillowpackage."
    },
    {
        "Answer": "writer.add_text('lstm', 'This is an lstm', 0)\nwriter.add_text('rnn', 'This is an rnn', 10)\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_text, give an example?",
        "Id": 857,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "import keyword\nimport torch\nmeta = []\nwhile len(meta)<100:\n    meta = meta+keyword.kwlist # get some strings\nmeta = meta[:100]\n\nfor i, v in enumerate(meta):\n    meta[i] = v+str(i)\n\nlabel_img = torch.rand(100, 3, 10, 32)\nfor i in range(100):\n    label_img[i]*=i/100.0\n\nwriter.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\nwriter.add_embedding(torch.randn(100, 5), label_img=label_img)\nwriter.add_embedding(torch.randn(100, 5), metadata=meta)\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_embedding, give an example?",
        "Id": 858,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nlabels = np.random.randint(2, size=100)  # binary label\npredictions = np.random.rand(100)\nwriter = SummaryWriter()\nwriter.add_pr_curve('pr_curve', labels, predictions, 0)\nwriter.close()\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve, give an example?",
        "Id": 859,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "layout = {'Taiwan':{'twse':['Multiline',['twse/0050', 'twse/2330']]},\n             'USA':{ 'dow':['Margin',   ['dow/aaa', 'dow/bbb', 'dow/ccc']],\n                  'nasdaq':['Margin',   ['nasdaq/aaa', 'nasdaq/bbb', 'nasdaq/ccc']]}}\n\nwriter.add_custom_scalars(layout)\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars, give an example?",
        "Id": 860,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nvertices_tensor = torch.as_tensor([\n    [1, 1, 1],\n    [-1, -1, 1],\n    [1, -1, -1],\n    [-1, 1, -1],\n], dtype=torch.float).unsqueeze(0)\ncolors_tensor = torch.as_tensor([\n    [255, 0, 0],\n    [0, 255, 0],\n    [0, 0, 255],\n    [255, 0, 255],\n], dtype=torch.int).unsqueeze(0)\nfaces_tensor = torch.as_tensor([\n    [0, 2, 3],\n    [0, 3, 1],\n    [0, 1, 2],\n    [1, 3, 2],\n], dtype=torch.int).unsqueeze(0)\n\nwriter = SummaryWriter()\nwriter.add_mesh('my_mesh', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor)\n\nwriter.close()\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_mesh, give an example?",
        "Id": 861,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": "from torch.utils.tensorboard import SummaryWriter\nwith SummaryWriter() as w:\n    for i in range(5):\n        w.add_hparams({'lr': 0.1*i, 'bsize': i},\n                      {'hparam/accuracy': 10*i, 'hparam/loss': 10*i})\n",
        "Question": "How to use torch.utils.tensorboard.writer.SummaryWriter.add_hparams, give an example?",
        "Id": 862,
        "source": "https://pytorch.org/docs/stable/tensorboard.html",
        "context": " "
    },
    {
        "Answer": ">>> torch.linspace(3, 10, steps=5)\ntensor([  3.0000,   4.7500,   6.5000,   8.2500,  10.0000])\n>>> torch.linspace(-10, 10, steps=5)\ntensor([-10.,  -5.,   0.,   5.,  10.])\n>>> torch.linspace(start=-10, end=10, steps=5)\ntensor([-10.,  -5.,   0.,   5.,  10.])\n>>> torch.linspace(start=-10, end=10, steps=1)\ntensor([-10.])\n",
        "Question": "How to use torch.linspace, give an example?",
        "Id": 863,
        "source": "https://pytorch.org/docs/stable/generated/torch.linspace.html#torch.linspace",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.tensor([5, 10, 15])\n>>> b = torch.tensor([3, 4, 5])\n>>> torch.lcm(a, b)\ntensor([15, 20, 15])\n>>> c = torch.tensor([3])\n>>> torch.lcm(a, c)\ntensor([15, 30, 15])\n",
        "Question": "How to use torch.lcm, give an example?",
        "Id": 864,
        "source": "https://pytorch.org/docs/stable/generated/torch.lcm.html#torch.lcm",
        "context": " Bothinputandothermust have integer types."
    },
    {
        "Answer": "for iterations...\n    ...\n    for param in model.parameters():\n        param.grad = None\n    loss.backward()\n",
        "Question": "How to use The default behavior (letting.grads beNonebefore the firstbackward(), such that their layout is created according to 1 or 2,\nand retained over time according to 3 or 4) is recommended for best performance.\nCalls tomodel.zero_grad()oroptimizer.zero_grad()will not affect.gradlayouts.In fact, resetting all.grads toNonebefore each\naccumulation phase, e.g.:, give an example?",
        "Id": 865,
        "source": "https://pytorch.org/docs/stable/autograd.html",
        "context": " The default behavior (letting.grads beNonebefore the firstbackward(), such that their layout is created according to 1 or 2,\nand retained over time according to 3 or 4) is recommended for best performance.\nCalls tomodel.zero_grad()oroptimizer.zero_grad()will not affect.gradlayouts.In fact, resetting all.grads toNonebefore each\naccumulation phase, e.g.:"
    },
    {
        "Answer": ">>> class Exp(Function):\n>>>\n>>>     @staticmethod\n>>>     def forward(ctx, i):\n>>>         result = i.exp()\n>>>         ctx.save_for_backward(result)\n>>>         return result\n>>>\n>>>     @staticmethod\n>>>     def backward(ctx, grad_output):\n>>>         result, = ctx.saved_tensors\n>>>         return grad_output * result\n>>>\n>>> #Use it by calling the apply method:\n>>> output = Exp.apply(input)\n",
        "Question": "How to use torch.autograd.Function, give an example?",
        "Id": 866,
        "source": "https://pytorch.org/docs/stable/autograd.html",
        "context": " Normally, the only way users interact with functions is by creating\nsubclasses and defining new operations. This is a recommended way of\nextending torch.autograd."
    },
    {
        "Answer": ">>> x = torch.randn((1, 1), requires_grad=True)\n>>> with torch.autograd.profiler.profile() as prof:\n>>>     for _ in range(100):  # any normal python code, really!\n>>>         y = x ** 2\n>>          y.backward()\n>>> # NOTE: some columns were removed for brevity\n>>> print(prof.key_averages().table(sort_by=\"self_cpu_time_total\"))\n-----------------------------------  ---------------  ---------------  ---------------\nName                                 Self CPU total   CPU time avg     Number of Calls\n-----------------------------------  ---------------  ---------------  ---------------\nmul                                  32.048ms         32.048ms         200\npow                                  27.041ms         27.041ms         200\nPowBackward0                         9.727ms          55.483ms         100\ntorch::autograd::AccumulateGrad      9.148ms          9.148ms          100\ntorch::autograd::GraphRoot           691.816us        691.816us        100\n-----------------------------------  ---------------  ---------------  ---------------\n",
        "Question": "How to use torch.autograd.profiler.profile, give an example?",
        "Id": 867,
        "source": "https://pytorch.org/docs/stable/autograd.html",
        "context": " "
    },
    {
        "Answer": "nvprof --profile-from-start off -o trace_name.prof -- <regular command here>\n",
        "Question": "How to use It is useful when running the program under nvprof:, give an example?",
        "Id": 868,
        "source": "https://pytorch.org/docs/stable/autograd.html",
        "context": " It is useful when running the program under nvprof:"
    },
    {
        "Answer": ">>> with torch.cuda.profiler.profile():\n...     model(x) # Warmup CUDA memory allocator and profiler\n...     with torch.autograd.profiler.emit_nvtx():\n...         model(x)\n",
        "Question": "How to use torch.autograd.profiler.emit_nvtx, give an example?",
        "Id": 869,
        "source": "https://pytorch.org/docs/stable/autograd.html",
        "context": " Unfortunately, there\u2019s no way to force nvprof to flush the data it collected\nto disk, so for CUDA profiling one has to use this context manager to annotate\nnvprof traces and wait for the process to exit before inspecting them.\nThen, either NVIDIA Visual Profiler (nvvp) can be used to visualize the timeline, ortorch.autograd.profiler.load_nvprof()can load the results for inspection\ne.g. in Python REPL."
    },
    {
        "Answer": ">>> import torch\n>>> from torch import autograd\n>>> class MyFunc(autograd.Function):\n...     @staticmethod\n...     def forward(ctx, inp):\n...         return inp.clone()\n...     @staticmethod\n...     def backward(ctx, gO):\n...         # Error during the backward pass\n...         raise RuntimeError(\"Some error in backward\")\n...         return gO.clone()\n>>> def run_fn(a):\n...     out = MyFunc.apply(a)\n...     return out.sum()\n>>> inp = torch.rand(10, 10, requires_grad=True)\n>>> out = run_fn(inp)\n>>> out.backward()\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in <module>\n      File \"/your/pytorch/install/torch/_tensor.py\", line 93, in backward\n        torch.autograd.backward(self, gradient, retain_graph, create_graph)\n      File \"/your/pytorch/install/torch/autograd/__init__.py\", line 90, in backward\n        allow_unreachable=True)  # allow_unreachable flag\n      File \"/your/pytorch/install/torch/autograd/function.py\", line 76, in apply\n        return self._forward_cls.backward(self, *args)\n      File \"<stdin>\", line 8, in backward\n    RuntimeError: Some error in backward\n>>> with autograd.detect_anomaly():\n...     inp = torch.rand(10, 10, requires_grad=True)\n...     out = run_fn(inp)\n...     out.backward()\n    Traceback of forward call that caused the error:\n      File \"tmp.py\", line 53, in <module>\n        out = run_fn(inp)\n      File \"tmp.py\", line 44, in run_fn\n        out = MyFunc.apply(a)\n    Traceback (most recent call last):\n      File \"<stdin>\", line 4, in <module>\n      File \"/your/pytorch/install/torch/_tensor.py\", line 93, in backward\n        torch.autograd.backward(self, gradient, retain_graph, create_graph)\n      File \"/your/pytorch/install/torch/autograd/__init__.py\", line 90, in backward\n        allow_unreachable=True)  # allow_unreachable flag\n      File \"/your/pytorch/install/torch/autograd/function.py\", line 76, in apply\n        return self._forward_cls.backward(self, *args)\n      File \"<stdin>\", line 8, in backward\n    RuntimeError: Some error in backward\n",
        "Question": "How to use torch.autograd.detect_anomaly, give an example?",
        "Id": 870,
        "source": "https://pytorch.org/docs/stable/autograd.html",
        "context": " This does two things:"
    },
    {
        "Answer": ">>> a = torch.randn(3, 4)\n>>> b = torch.randn(4, 5)\n>>> c = torch.randn(5, 6)\n>>> d = torch.randn(6, 7)\n>>> torch.chain_matmul(a, b, c, d)\ntensor([[ -2.3375,  -3.9790,  -4.1119,  -6.6577,   9.5609, -11.5095,  -3.2614],\n        [ 21.4038,   3.3378,  -8.4982,  -5.2457, -10.2561,  -2.4684,   2.7163],\n        [ -0.9647,  -5.8917,  -2.3213,  -5.2284,  12.8615, -12.2816,  -2.5095]])\n",
        "Question": "How to use torch.chain_matmul, give an example?",
        "Id": 871,
        "source": "https://pytorch.org/docs/stable/generated/torch.chain_matmul.html#torch.chain_matmul",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.8986, -0.7279,  1.1745,  0.2611])\n>>> torch.tanh(a)\ntensor([ 0.7156, -0.6218,  0.8257,  0.2553])\n",
        "Question": "How to use torch.tanh, give an example?",
        "Id": 872,
        "source": "https://pytorch.org/docs/stable/generated/torch.tanh.html#torch.tanh",
        "context": " "
    },
    {
        "Answer": ">>> a = torch.randn(4)\n>>> a\ntensor([ 0.9041,  0.0196, -0.3108, -2.4423])\n>>> torch.atan2(a, torch.randn(4))\ntensor([ 0.9833,  0.0811, -1.9743, -1.4151])\n",
        "Question": "How to use torch.atan2, give an example?",
        "Id": 873,
        "source": "https://pytorch.org/docs/stable/generated/torch.atan2.html#torch.atan2",
        "context": " The shapes ofinputandothermust bebroadcastable."
    },
    {
        "Answer": ">>> x = torch.zeros(1, requires_grad=True)\n>>> with torch.no_grad():\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> is_train = False\n>>> with torch.set_grad_enabled(is_train):\n...     y = x * 2\n>>> y.requires_grad\nFalse\n\n>>> torch.set_grad_enabled(True)  # this can also be used as a function\n>>> y = x * 2\n>>> y.requires_grad\nTrue\n\n>>> torch.set_grad_enabled(False)\n>>> y = x * 2\n>>> y.requires_grad\nFalse\n",
        "Question": "How  , give an example?",
        "Id": 874,
        "source": "https://pytorch.org/docs/stable/torch.html#reduction-ops",
        "context": " "
    },
    {
        "Answer": ">>> torch.ne(torch.tensor([[1, 2], [3, 4]]), torch.tensor([[1, 1], [4, 4]]))\ntensor([[False, True], [True, False]])\n",
        "Question": "How to use torch.ne, give an example?",
        "Id": 875,
        "source": "https://pytorch.org/docs/stable/generated/torch.ne.html#torch.ne",
        "context": " The second argument can be a number or a tensor whose shape isbroadcastablewith the first argument."
    },
    {
        "Answer": ">>> t = torch.randn(3, 4)\n>>> t\ntensor([[-0.1321,  0.4370, -1.2631, -1.1289],\n        [-2.0527, -1.1250,  0.2275,  0.3077],\n        [-0.0881, -0.1259, -0.5495,  1.0284]])\n>>> torch.msort(t)\ntensor([[-2.0527, -1.1250, -1.2631, -1.1289],\n        [-0.1321, -0.1259, -0.5495,  0.3077],\n        [-0.0881,  0.4370,  0.2275,  1.0284]])\n",
        "Question": "How to use torch.msort, give an example?",
        "Id": 876,
        "source": "https://pytorch.org/docs/stable/generated/torch.msort.html#torch.msort",
        "context": " "
    },
    {
        "Answer": "python -m torch.utils.bottleneck /path/to/source/script.py [args]\n",
        "Question": "How to use torch.utils.bottleneckis a tool that can be used as an initial step for\ndebugging bottlenecks in your program. It summarizes runs of your script with\nthe Python profiler and PyTorch\u2019s autograd profiler.Run it on the command line with, give an example?",
        "Id": 877,
        "source": "https://pytorch.org/docs/stable/bottleneck.html",
        "context": " Run it on the command line with"
    },
    {
        "Answer": ">>> model = nn.Sequential(...)\n>>> input_var = checkpoint_sequential(model, chunks, input_var)\n",
        "Question": "How to use torch.utils.checkpoint.checkpoint_sequential, give an example?",
        "Id": 878,
        "source": "https://pytorch.org/docs/stable/checkpoint.html",
        "context": " Seecheckpoint()on how checkpointing works."
    },
    {
        "Answer": ">>> torch.unbind(torch.tensor([[1, 2, 3],\n>>>                            [4, 5, 6],\n>>>                            [7, 8, 9]]))\n(tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([7, 8, 9]))\n",
        "Question": "How to use torch.unbind, give an example?",
        "Id": 879,
        "source": "https://pytorch.org/docs/stable/generated/torch.unbind.html#torch.unbind",
        "context": " Returns a tuple of all slices along a given dimension, already without it."
    },
    {
        "Answer": ">>> a = torch.randn(3, 3)\n>>> a = torch.mm(a, a.t()) + 1e-05 * torch.eye(3) # make symmetric positive definite\n>>> u = torch.cholesky(a)\n>>> a\ntensor([[  0.9935,  -0.6353,   1.5806],\n        [ -0.6353,   0.8769,  -1.7183],\n        [  1.5806,  -1.7183,  10.6618]])\n>>> torch.cholesky_inverse(u)\ntensor([[ 1.9314,  1.2251, -0.0889],\n        [ 1.2251,  2.4439,  0.2122],\n        [-0.0889,  0.2122,  0.1412]])\n>>> a.inverse()\ntensor([[ 1.9314,  1.2251, -0.0889],\n        [ 1.2251,  2.4439,  0.2122],\n        [-0.0889,  0.2122,  0.1412]])\n",
        "Question": "How to use torch.cholesky_inverse, give an example?",
        "Id": 880,
        "source": "https://pytorch.org/docs/stable/generated/torch.cholesky_inverse.html#torch.cholesky_inverse",
        "context": " IfupperisTrueor not provided,uuuis upper\ntriangular such that the returned tensor is"
    },
    {
        "Answer": ">>> A = torch.randn(2, 3, 3)\n>>> A_LU, pivots = torch.lu(A)\n>>> A_LU\ntensor([[[ 1.3506,  2.5558, -0.0816],\n         [ 0.1684,  1.1551,  0.1940],\n         [ 0.1193,  0.6189, -0.5497]],\n\n        [[ 0.4526,  1.2526, -0.3285],\n         [-0.7988,  0.7175, -0.9701],\n         [ 0.2634, -0.9255, -0.3459]]])\n>>> pivots\ntensor([[ 3,  3,  3],\n        [ 3,  3,  3]], dtype=torch.int32)\n>>> A_LU, pivots, info = torch.lu(A, get_infos=True)\n>>> if info.nonzero().size(0) == 0:\n...   print('LU factorization succeeded for all samples!')\nLU factorization succeeded for all samples!\n",
        "Question": "How to use torch.lu, give an example?",
        "Id": 881,
        "source": "https://pytorch.org/docs/stable/generated/torch.lu.html#torch.lu",
        "context": " "
    },
    {
        "Answer": ">>> a1 = torch.tensor([4.0])\n>>> a2 = torch.tensor([3.0, 4.0, 5.0])\n>>> a = torch.igammac(a1, a2)\ntensor([0.3528, 0.5665, 0.7350])\ntensor([0.3528, 0.5665, 0.7350])\n>>> b = torch.igamma(a1, a2) + torch.igammac(a1, a2)\ntensor([1., 1., 1.])\n",
        "Question": "How to use torch.igamma, give an example?",
        "Id": 882,
        "source": "https://pytorch.org/docs/stable/generated/torch.igamma.html#torch.igamma",
        "context": " Supportsbroadcasting to a common shapeand float inputs."
    },
    {
        "Answer": ">>> torch.load('tensors.pt')\n# Load all tensors onto the CPU\n>>> torch.load('tensors.pt', map_location=torch.device('cpu'))\n# Load all tensors onto the CPU, using a function\n>>> torch.load('tensors.pt', map_location=lambda storage, loc: storage)\n# Load all tensors onto GPU 1\n>>> torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))\n# Map tensors from GPU 1 to GPU 0\n>>> torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})\n# Load tensor from io.BytesIO object\n>>> with open('tensor.pt', 'rb') as f:\n...     buffer = io.BytesIO(f.read())\n>>> torch.load(buffer)\n# Load a module with 'ascii' encoding for unpickling\n>>> torch.load('module.pt', encoding='ascii')\n",
        "Question": "How to use torch.load, give an example?",
        "Id": 883,
        "source": "https://pytorch.org/docs/stable/generated/torch.load.html#torch.load",
        "context": " User extensions can register their own location tags and tagging and\ndeserialization methods usingtorch.serialization.register_package()."
    }
]